nohup: ignoring input
rsr and rsr scat on cora, citeseer, cora_full, pubmed, amazon-computer and amazon photo
Start citeseer



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 872
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 33556.39062 feature_loss= 54.29237 structure_loss= 11542.84766 proj_loss= 3221.96216 pca_loss= 18737.29102 accuracy= 0.59122 accuracy_s= 0.75954 accuracy_f= 0.78840 time= 0.10593
Epoch: 0011 train_loss= 15125.52734 feature_loss= 14.44905 structure_loss= 5428.66846 proj_loss= 3149.20459 pca_loss= 6533.20459 accuracy= 0.60445 accuracy_s= 0.76736 accuracy_f= 0.80884 time= 0.08203
Epoch: 0021 train_loss= 8866.06934 feature_loss= 9.10529 structure_loss= 2666.53857 proj_loss= 3087.43701 pca_loss= 3102.98828 accuracy= 0.60685 accuracy_s= 0.76796 accuracy_f= 0.82387 time= 0.08174
Epoch: 0031 train_loss= 6900.20557 feature_loss= 7.77269 structure_loss= 2031.23474 proj_loss= 3030.21143 pca_loss= 1830.98682 accuracy= 0.59122 accuracy_s= 0.75954 accuracy_f= 0.82507 time= 0.08141
Epoch: 0041 train_loss= 6116.04736 feature_loss= 7.09789 structure_loss= 1814.91394 proj_loss= 2972.11670 pca_loss= 1321.91882 accuracy= 0.58942 accuracy_s= 0.75954 accuracy_f= 0.82627 time= 0.08154
Epoch: 0051 train_loss= 5704.77100 feature_loss= 6.87460 structure_loss= 1709.98389 proj_loss= 2913.24194 pca_loss= 1074.67041 accuracy= 0.59483 accuracy_s= 0.75954 accuracy_f= 0.82627 time= 0.08157
Epoch: 0061 train_loss= 5391.52344 feature_loss= 6.71805 structure_loss= 1639.63538 proj_loss= 2854.24927 pca_loss= 890.92065 accuracy= 0.63030 accuracy_s= 0.76014 accuracy_f= 0.82567 time= 0.08103
Epoch: 0071 train_loss= 5162.80273 feature_loss= 6.59936 structure_loss= 1577.26074 proj_loss= 2795.74902 pca_loss= 783.19360 accuracy= 0.66096 accuracy_s= 0.78118 accuracy_f= 0.82627 time= 0.08056
Epoch: 0081 train_loss= 4943.51660 feature_loss= 6.52231 structure_loss= 1517.57947 proj_loss= 2737.74414 pca_loss= 681.67065 accuracy= 0.63871 accuracy_s= 0.75954 accuracy_f= 0.82567 time= 0.08120
Epoch: 0091 train_loss= 4739.82666 feature_loss= 6.49530 structure_loss= 1451.34692 proj_loss= 2680.40796 pca_loss= 601.57648 accuracy= 0.64172 accuracy_s= 0.76014 accuracy_f= 0.82627 time= 0.08246
Epoch: 0101 train_loss= 4547.66016 feature_loss= 6.48840 structure_loss= 1376.81482 proj_loss= 2624.00415 pca_loss= 540.35303 accuracy= 0.66035 accuracy_s= 0.76315 accuracy_f= 0.82687 time= 0.08116
Epoch: 0111 train_loss= 4229.46289 feature_loss= 6.51621 structure_loss= 1162.37000 proj_loss= 2568.77612 pca_loss= 491.80063 accuracy= 0.67238 accuracy_s= 0.76916 accuracy_f= 0.82627 time= 0.08085
Epoch: 0121 train_loss= 3973.93164 feature_loss= 6.69514 structure_loss= 994.37097 proj_loss= 2515.03418 pca_loss= 457.83130 accuracy= 0.66096 accuracy_s= 0.75954 accuracy_f= 0.82627 time= 0.08104
Epoch: 0131 train_loss= 3602.66602 feature_loss= 6.47644 structure_loss= 703.22662 proj_loss= 2462.82886 pca_loss= 430.13412 accuracy= 0.67238 accuracy_s= 0.76375 accuracy_f= 0.82687 time= 0.08174
Epoch: 0141 train_loss= 3349.69995 feature_loss= 6.48641 structure_loss= 532.80072 proj_loss= 2412.05103 pca_loss= 398.36176 accuracy= 0.67298 accuracy_s= 0.76014 accuracy_f= 0.82687 time= 0.08122
Epoch: 0151 train_loss= 3155.65186 feature_loss= 6.48684 structure_loss= 423.34412 proj_loss= 2362.54590 pca_loss= 363.27502 accuracy= 0.67298 accuracy_s= 0.75954 accuracy_f= 0.82687 time= 0.08218
Epoch: 0161 train_loss= 2882.70264 feature_loss= 5.89712 structure_loss= 224.21519 proj_loss= 2314.55273 pca_loss= 338.03772 accuracy= 0.66877 accuracy_s= 0.76014 accuracy_f= 0.82567 time= 0.08159
Epoch: 0171 train_loss= 14278.73047 feature_loss= 8.81236 structure_loss= 9555.15234 proj_loss= 2274.07227 pca_loss= 2440.69336 accuracy= 0.60565 accuracy_s= 0.76495 accuracy_f= 0.82326 time= 0.08231
Epoch: 0181 train_loss= 8252.84473 feature_loss= 7.90224 structure_loss= 3437.57544 proj_loss= 2242.77539 pca_loss= 2564.59180 accuracy= 0.60144 accuracy_s= 0.76014 accuracy_f= 0.82627 time= 0.08176
Epoch: 0191 train_loss= 6995.62402 feature_loss= 7.80467 structure_loss= 3097.29321 proj_loss= 2211.95483 pca_loss= 1678.57153 accuracy= 0.62188 accuracy_s= 0.77096 accuracy_f= 0.82627 time= 0.08228
Epoch: 0201 train_loss= 5881.53076 feature_loss= 7.55512 structure_loss= 2474.13037 proj_loss= 2181.62500 pca_loss= 1218.22021 accuracy= 0.60806 accuracy_s= 0.76856 accuracy_f= 0.82567 time= 0.08119
Epoch: 0211 train_loss= 5153.56299 feature_loss= 7.09006 structure_loss= 2020.19238 proj_loss= 2151.79126 pca_loss= 974.48932 accuracy= 0.62609 accuracy_s= 0.77818 accuracy_f= 0.82687 time= 0.08120
Epoch: 0221 train_loss= 4670.46240 feature_loss= 6.86867 structure_loss= 1713.08362 proj_loss= 2122.53467 pca_loss= 827.97577 accuracy= 0.62128 accuracy_s= 0.77517 accuracy_f= 0.82687 time= 0.08110
Epoch: 0231 train_loss= 4412.01318 feature_loss= 6.78926 structure_loss= 1580.65100 proj_loss= 2093.87549 pca_loss= 730.69733 accuracy= 0.62128 accuracy_s= 0.77217 accuracy_f= 0.82687 time= 0.08159
Epoch: 0241 train_loss= 4245.00342 feature_loss= 10.54315 structure_loss= 1509.37781 proj_loss= 2065.81836 pca_loss= 659.26404 accuracy= 0.62609 accuracy_s= 0.77517 accuracy_f= 0.79261 time= 0.08155
Epoch: 0251 train_loss= 4048.60889 feature_loss= 10.09898 structure_loss= 1391.92310 proj_loss= 2038.39197 pca_loss= 608.19470 accuracy= 0.64232 accuracy_s= 0.79561 accuracy_f= 0.79621 time= 0.08159
Epoch: 0261 train_loss= 3849.46899 feature_loss= 9.50170 structure_loss= 1257.54663 proj_loss= 2011.60925 pca_loss= 570.81128 accuracy= 0.63691 accuracy_s= 0.79802 accuracy_f= 0.79621 time= 0.08099
Epoch: 0271 train_loss= 3095.74756 feature_loss= 9.00763 structure_loss= 554.22144 proj_loss= 1985.51233 pca_loss= 547.00623 accuracy= 0.62068 accuracy_s= 0.75954 accuracy_f= 0.79561 time= 0.08127
Epoch: 0281 train_loss= 2916.81763 feature_loss= 8.50380 structure_loss= 423.90015 proj_loss= 1960.16589 pca_loss= 524.24774 accuracy= 0.61948 accuracy_s= 0.76135 accuracy_f= 0.79501 time= 0.08133
Epoch: 0291 train_loss= 2784.36426 feature_loss= 8.20556 structure_loss= 340.91516 proj_loss= 1935.32153 pca_loss= 499.92178 accuracy= 0.62729 accuracy_s= 0.76195 accuracy_f= 0.79621 time= 0.08127

accuracy 0.63571
accuracy_s 0.76315
accuracy_f 0.79561
auc 0.51373
f1_score 0.24250
Job finished!



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 444
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 33135.34375 feature_loss= 54.30304 structure_loss= 13555.84766 proj_loss= 12243.51074 pca_loss= 7281.68213 accuracy= 0.57980 accuracy_s= 0.75954 accuracy_f= 0.78900 time= 0.10160
Epoch: 0011 train_loss= 20046.99414 feature_loss= 10.95862 structure_loss= 5418.93555 proj_loss= 11743.49316 pca_loss= 2873.60815 accuracy= 0.60926 accuracy_s= 0.76916 accuracy_f= 0.80884 time= 0.08022
Epoch: 0021 train_loss= 15368.23633 feature_loss= 7.77457 structure_loss= 2699.59302 proj_loss= 11262.38965 pca_loss= 1398.47888 accuracy= 0.59062 accuracy_s= 0.76435 accuracy_f= 0.82387 time= 0.08050
Epoch: 0031 train_loss= 13757.09375 feature_loss= 7.38981 structure_loss= 2085.21655 proj_loss= 10786.18555 pca_loss= 878.30206 accuracy= 0.58521 accuracy_s= 0.76014 accuracy_f= 0.82507 time= 0.07925
Epoch: 0041 train_loss= 12849.99316 feature_loss= 7.24862 structure_loss= 1860.06750 proj_loss= 10312.87988 pca_loss= 669.79700 accuracy= 0.58100 accuracy_s= 0.75954 accuracy_f= 0.82687 time= 0.07929
Epoch: 0051 train_loss= 12174.27441 feature_loss= 7.11953 structure_loss= 1764.63306 proj_loss= 9853.24609 pca_loss= 549.27502 accuracy= 0.63270 accuracy_s= 0.76796 accuracy_f= 0.82627 time= 0.07813
Epoch: 0061 train_loss= 11598.88184 feature_loss= 7.04805 structure_loss= 1708.21680 proj_loss= 9410.20898 pca_loss= 473.40842 accuracy= 0.64653 accuracy_s= 0.76375 accuracy_f= 0.82567 time= 0.07881
Epoch: 0071 train_loss= 11058.09277 feature_loss= 6.93976 structure_loss= 1649.78577 proj_loss= 8985.83496 pca_loss= 415.53238 accuracy= 0.65134 accuracy_s= 0.76736 accuracy_f= 0.82627 time= 0.08539
Epoch: 0081 train_loss= 10558.37207 feature_loss= 6.85504 structure_loss= 1601.72571 proj_loss= 8580.84473 pca_loss= 368.94617 accuracy= 0.67118 accuracy_s= 0.78479 accuracy_f= 0.82567 time= 0.09067
Epoch: 0091 train_loss= 10086.44727 feature_loss= 6.75317 structure_loss= 1548.47437 proj_loss= 8195.39648 pca_loss= 335.82330 accuracy= 0.66336 accuracy_s= 0.78179 accuracy_f= 0.82687 time= 0.09268
Epoch: 0101 train_loss= 9632.77539 feature_loss= 6.65449 structure_loss= 1490.82361 proj_loss= 7829.11133 pca_loss= 306.18527 accuracy= 0.66877 accuracy_s= 0.77938 accuracy_f= 0.82687 time= 0.07873
Epoch: 0111 train_loss= 9170.40723 feature_loss= 6.54215 structure_loss= 1401.98413 proj_loss= 7481.58545 pca_loss= 280.29617 accuracy= 0.66216 accuracy_s= 0.77337 accuracy_f= 0.82687 time= 0.07907
Epoch: 0121 train_loss= 8779.86230 feature_loss= 6.47631 structure_loss= 1353.07385 proj_loss= 7152.31934 pca_loss= 267.99271 accuracy= 0.66516 accuracy_s= 0.77577 accuracy_f= 0.82687 time= 0.07875
Epoch: 0131 train_loss= 8376.37793 feature_loss= 6.46960 structure_loss= 1285.10767 proj_loss= 6840.35889 pca_loss= 244.44170 accuracy= 0.64953 accuracy_s= 0.76375 accuracy_f= 0.82687 time= 0.07870
Epoch: 0141 train_loss= 7975.20264 feature_loss= 6.46323 structure_loss= 1195.79089 proj_loss= 6545.14404 pca_loss= 227.80418 accuracy= 0.64833 accuracy_s= 0.76555 accuracy_f= 0.82687 time= 0.07837
Epoch: 0151 train_loss= 11196.36230 feature_loss= 6.63103 structure_loss= 3963.66772 proj_loss= 6284.56689 pca_loss= 941.49707 accuracy= 0.65134 accuracy_s= 0.76736 accuracy_f= 0.82747 time= 0.07905
Epoch: 0161 train_loss= 9050.91797 feature_loss= 6.44995 structure_loss= 1971.04993 proj_loss= 6076.22998 pca_loss= 997.18787 accuracy= 0.59122 accuracy_s= 0.76255 accuracy_f= 0.82687 time= 0.07911
Epoch: 0171 train_loss= 8191.39355 feature_loss= 6.44148 structure_loss= 1683.70020 proj_loss= 5873.41455 pca_loss= 627.83752 accuracy= 0.63511 accuracy_s= 0.76195 accuracy_f= 0.82687 time= 0.08092
Epoch: 0181 train_loss= 7546.16113 feature_loss= 6.43399 structure_loss= 1415.19116 proj_loss= 5677.60596 pca_loss= 446.93042 accuracy= 0.66456 accuracy_s= 0.77096 accuracy_f= 0.82687 time= 0.07837
Epoch: 0191 train_loss= 7086.14014 feature_loss= 6.42762 structure_loss= 1238.25684 proj_loss= 5490.29688 pca_loss= 351.15866 accuracy= 0.64172 accuracy_s= 0.76616 accuracy_f= 0.82687 time= 0.07874
Epoch: 0201 train_loss= 6785.77246 feature_loss= 6.42004 structure_loss= 1162.60242 proj_loss= 5311.01562 pca_loss= 305.73431 accuracy= 0.65735 accuracy_s= 0.77397 accuracy_f= 0.82687 time= 0.07913
Epoch: 0211 train_loss= 6517.89453 feature_loss= 6.41240 structure_loss= 1110.41516 proj_loss= 5139.27686 pca_loss= 261.78983 accuracy= 0.66877 accuracy_s= 0.77517 accuracy_f= 0.82687 time= 0.07890
Epoch: 0221 train_loss= 6265.56348 feature_loss= 6.41211 structure_loss= 1053.22729 proj_loss= 4974.64844 pca_loss= 231.27538 accuracy= 0.66877 accuracy_s= 0.77036 accuracy_f= 0.82627 time= 0.07879
Epoch: 0231 train_loss= 5933.68555 feature_loss= 6.39917 structure_loss= 902.15497 proj_loss= 4816.74316 pca_loss= 208.38799 accuracy= 0.67899 accuracy_s= 0.77878 accuracy_f= 0.82687 time= 0.07951
Epoch: 0241 train_loss= 5685.30713 feature_loss= 6.38952 structure_loss= 823.97491 proj_loss= 4665.28418 pca_loss= 189.65887 accuracy= 0.67238 accuracy_s= 0.77698 accuracy_f= 0.82627 time= 0.07907
Epoch: 0251 train_loss= 5383.22070 feature_loss= 6.38139 structure_loss= 681.81238 proj_loss= 4519.95801 pca_loss= 175.06891 accuracy= 0.67839 accuracy_s= 0.77938 accuracy_f= 0.82627 time= 0.07860
Epoch: 0261 train_loss= 5121.19141 feature_loss= 6.37309 structure_loss= 572.15039 proj_loss= 4380.58447 pca_loss= 162.08356 accuracy= 0.68320 accuracy_s= 0.77938 accuracy_f= 0.82567 time= 0.07959
Epoch: 0271 train_loss= 4944.32324 feature_loss= 6.36495 structure_loss= 534.06525 proj_loss= 4246.62256 pca_loss= 157.27039 accuracy= 0.67839 accuracy_s= 0.77698 accuracy_f= 0.82567 time= 0.07996
Epoch: 0281 train_loss= 4770.01123 feature_loss= 6.35774 structure_loss= 496.60364 proj_loss= 4117.83301 pca_loss= 149.21678 accuracy= 0.67478 accuracy_s= 0.77096 accuracy_f= 0.82627 time= 0.07967
Epoch: 0291 train_loss= 4599.51904 feature_loss= 6.35785 structure_loss= 458.30380 proj_loss= 3994.03418 pca_loss= 140.82327 accuracy= 0.67719 accuracy_s= 0.78179 accuracy_f= 0.82627 time= 0.09041

accuracy 0.67538
accuracy_s 0.76555
accuracy_f 0.82807
auc 0.59142
f1_score 0.32500
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 260
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 22227.44336 reconstruction_loss= 54.40616 proj_loss= 3223.84058 pca_loss= 18949.19727 accuracy= 0.58161 time= 0.07876
Epoch: 0011 train_loss= 6238.86426 reconstruction_loss= 10.05299 proj_loss= 3104.38940 pca_loss= 3124.42163 accuracy= 0.68320 time= 0.06183
Epoch: 0021 train_loss= 4310.50977 reconstruction_loss= 8.95503 proj_loss= 3012.24170 pca_loss= 1289.31323 accuracy= 0.68500 time= 0.06113
Epoch: 0031 train_loss= 3656.60181 reconstruction_loss= 8.63200 proj_loss= 2922.99341 pca_loss= 724.97632 accuracy= 0.68440 time= 0.06074
Epoch: 0041 train_loss= 3320.31421 reconstruction_loss= 8.24904 proj_loss= 2833.18530 pca_loss= 478.87997 accuracy= 0.68560 time= 0.06083
Epoch: 0051 train_loss= 3103.15503 reconstruction_loss= 8.13681 proj_loss= 2743.32812 pca_loss= 351.69016 accuracy= 0.68440 time= 0.06098
Epoch: 0061 train_loss= 2927.96436 reconstruction_loss= 7.90484 proj_loss= 2653.96069 pca_loss= 266.09894 accuracy= 0.68380 time= 0.06107
Epoch: 0071 train_loss= 2782.02344 reconstruction_loss= 7.25189 proj_loss= 2565.73535 pca_loss= 209.03610 accuracy= 0.68320 time= 0.06110
Epoch: 0081 train_loss= 2654.47461 reconstruction_loss= 7.10833 proj_loss= 2479.73218 pca_loss= 167.63406 accuracy= 0.68801 time= 0.06079
Epoch: 0091 train_loss= 2541.97510 reconstruction_loss= 7.08197 proj_loss= 2396.59229 pca_loss= 138.30070 accuracy= 0.68500 time= 0.06072
Epoch: 0101 train_loss= 2439.35938 reconstruction_loss= 6.65505 proj_loss= 2316.50342 pca_loss= 116.20087 accuracy= 0.66937 time= 0.06058
Epoch: 0111 train_loss= 2345.93677 reconstruction_loss= 5.99244 proj_loss= 2239.66821 pca_loss= 100.27605 accuracy= 0.68560 time= 0.06099
Epoch: 0121 train_loss= 2254.26245 reconstruction_loss= 7.83158 proj_loss= 2165.93823 pca_loss= 80.49256 accuracy= 0.68500 time= 0.06075
Epoch: 0131 train_loss= 2172.78955 reconstruction_loss= 5.76792 proj_loss= 2095.84204 pca_loss= 71.17972 accuracy= 0.68440 time= 0.06099
Epoch: 0141 train_loss= 2094.81543 reconstruction_loss= 5.79489 proj_loss= 2029.18628 pca_loss= 59.83428 accuracy= 0.68380 time= 0.06065
Epoch: 0151 train_loss= 2023.79407 reconstruction_loss= 5.69526 proj_loss= 1965.67627 pca_loss= 52.42251 accuracy= 0.68500 time= 0.06081
Epoch: 0161 train_loss= 1967.19580 reconstruction_loss= 5.75728 proj_loss= 1905.32410 pca_loss= 56.11443 accuracy= 0.68320 time= 0.06102
Epoch: 0171 train_loss= 1899.91968 reconstruction_loss= 5.56211 proj_loss= 1847.75940 pca_loss= 46.59811 accuracy= 0.68440 time= 0.06101
Epoch: 0181 train_loss= 1838.28162 reconstruction_loss= 5.64162 proj_loss= 1792.72864 pca_loss= 39.91143 accuracy= 0.68500 time= 0.06087
Epoch: 0191 train_loss= 1781.03296 reconstruction_loss= 5.65482 proj_loss= 1740.03992 pca_loss= 35.33829 accuracy= 0.68440 time= 0.06081
Epoch: 0201 train_loss= 1730.19409 reconstruction_loss= 5.53088 proj_loss= 1689.61426 pca_loss= 35.04893 accuracy= 0.68440 time= 0.06026
Epoch: 0211 train_loss= 1677.08716 reconstruction_loss= 5.66308 proj_loss= 1641.30444 pca_loss= 30.11959 accuracy= 0.68440 time= 0.06058
Epoch: 0221 train_loss= 1630.53259 reconstruction_loss= 6.49808 proj_loss= 1594.98828 pca_loss= 29.04623 accuracy= 0.68500 time= 0.06435
Epoch: 0231 train_loss= 1598.72144 reconstruction_loss= 5.52740 proj_loss= 1550.67212 pca_loss= 42.52200 accuracy= 0.68440 time= 0.06460
Epoch: 0241 train_loss= 1545.16699 reconstruction_loss= 5.54378 proj_loss= 1508.24011 pca_loss= 31.38302 accuracy= 0.68380 time= 0.07077
Epoch: 0251 train_loss= 1498.69031 reconstruction_loss= 5.66968 proj_loss= 1467.45642 pca_loss= 25.56427 accuracy= 0.68440 time= 0.06130
Epoch: 0261 train_loss= 1456.50037 reconstruction_loss= 5.52542 proj_loss= 1428.17615 pca_loss= 22.79878 accuracy= 0.68440 time= 0.06158
Epoch: 0271 train_loss= 1424.64111 reconstruction_loss= 5.52589 proj_loss= 1390.41858 pca_loss= 28.69671 accuracy= 0.68440 time= 0.06124
Epoch: 0281 train_loss= 1382.22742 reconstruction_loss= 5.55508 proj_loss= 1354.13123 pca_loss= 22.54111 accuracy= 0.68380 time= 0.06125
Epoch: 0291 train_loss= 1344.46143 reconstruction_loss= 5.61165 proj_loss= 1319.18005 pca_loss= 19.66971 accuracy= 0.68139 time= 0.06062

accuracy 0.68200
auc 0.60003
f1_score 0.33875
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 570
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 33657.75781 reconstruction_loss= 11686.94434 proj_loss= 3224.41968 pca_loss= 18746.39258 accuracy= 0.58762 time= 0.06162
Epoch: 0011 train_loss= 14865.53516 reconstruction_loss= 5205.06543 proj_loss= 3146.94092 pca_loss= 6513.52930 accuracy= 0.59904 time= 0.04717
Epoch: 0021 train_loss= 9019.82227 reconstruction_loss= 2743.35229 proj_loss= 3081.75488 pca_loss= 3194.71509 accuracy= 0.60204 time= 0.04704
Epoch: 0031 train_loss= 7025.30176 reconstruction_loss= 2092.09326 proj_loss= 3021.05933 pca_loss= 1912.14941 accuracy= 0.59423 time= 0.04715
Epoch: 0041 train_loss= 6227.68896 reconstruction_loss= 1889.83923 proj_loss= 2959.44458 pca_loss= 1378.40540 accuracy= 0.59182 time= 0.04686
Epoch: 0051 train_loss= 5752.00879 reconstruction_loss= 1762.39465 proj_loss= 2897.13306 pca_loss= 1092.48120 accuracy= 0.60745 time= 0.04678
Epoch: 0061 train_loss= 5403.53809 reconstruction_loss= 1648.62292 proj_loss= 2835.09033 pca_loss= 919.82477 accuracy= 0.59062 time= 0.04679
Epoch: 0071 train_loss= 5067.59961 reconstruction_loss= 1511.18347 proj_loss= 2773.74585 pca_loss= 782.67041 accuracy= 0.60625 time= 0.04654
Epoch: 0081 train_loss= 4849.61865 reconstruction_loss= 1449.18518 proj_loss= 2713.23926 pca_loss= 687.19446 accuracy= 0.60625 time= 0.04735
Epoch: 0091 train_loss= 4676.55371 reconstruction_loss= 1412.77869 proj_loss= 2653.55981 pca_loss= 610.21527 accuracy= 0.63150 time= 0.04648
Epoch: 0101 train_loss= 4510.21387 reconstruction_loss= 1363.26440 proj_loss= 2594.87671 pca_loss= 552.07257 accuracy= 0.62970 time= 0.04710
Epoch: 0111 train_loss= 4344.44141 reconstruction_loss= 1301.88354 proj_loss= 2537.12988 pca_loss= 505.42786 accuracy= 0.62369 time= 0.04695
Epoch: 0121 train_loss= 4176.25049 reconstruction_loss= 1235.54651 proj_loss= 2480.26489 pca_loss= 460.43884 accuracy= 0.62910 time= 0.04717
Epoch: 0131 train_loss= 3978.66846 reconstruction_loss= 1126.09229 proj_loss= 2424.46704 pca_loss= 428.10919 accuracy= 0.60986 time= 0.04736
Epoch: 0141 train_loss= 3817.60254 reconstruction_loss= 1054.58887 proj_loss= 2369.82202 pca_loss= 393.19162 accuracy= 0.61948 time= 0.04733
Epoch: 0151 train_loss= 3661.13794 reconstruction_loss= 980.98914 proj_loss= 2316.47729 pca_loss= 363.67163 accuracy= 0.62609 time= 0.04622
Epoch: 0161 train_loss= 3500.51807 reconstruction_loss= 888.51550 proj_loss= 2264.61768 pca_loss= 347.38474 accuracy= 0.60685 time= 0.04682
Epoch: 0171 train_loss= 3380.56812 reconstruction_loss= 843.62408 proj_loss= 2214.05713 pca_loss= 322.88705 accuracy= 0.61467 time= 0.04815
Epoch: 0181 train_loss= 9509.20703 reconstruction_loss= 6846.70215 proj_loss= 2165.81592 pca_loss= 496.68921 accuracy= 0.61888 time= 0.05176
Epoch: 0191 train_loss= 5365.99414 reconstruction_loss= 1960.22986 proj_loss= 2135.61865 pca_loss= 1270.14551 accuracy= 0.59423 time= 0.05126
Epoch: 0201 train_loss= 4625.32666 reconstruction_loss= 1617.23389 proj_loss= 2104.59033 pca_loss= 903.50226 accuracy= 0.67959 time= 0.05270
Epoch: 0211 train_loss= 4016.40723 reconstruction_loss= 1229.10864 proj_loss= 2073.89941 pca_loss= 713.39917 accuracy= 0.57680 time= 0.04739
Epoch: 0221 train_loss= 3784.97290 reconstruction_loss= 1124.74548 proj_loss= 2043.98950 pca_loss= 616.23804 accuracy= 0.57379 time= 0.04761
Epoch: 0231 train_loss= 3607.43311 reconstruction_loss= 1047.15979 proj_loss= 2014.91492 pca_loss= 545.35828 accuracy= 0.59303 time= 0.04615
Epoch: 0241 train_loss= 3464.38623 reconstruction_loss= 985.95630 proj_loss= 1986.61560 pca_loss= 491.81454 accuracy= 0.58641 time= 0.04638
Epoch: 0251 train_loss= 3339.80542 reconstruction_loss= 933.19507 proj_loss= 1959.06372 pca_loss= 447.54666 accuracy= 0.60565 time= 0.04676
Epoch: 0261 train_loss= 3208.09302 reconstruction_loss= 858.82806 proj_loss= 1932.27112 pca_loss= 416.99396 accuracy= 0.60445 time= 0.04654
Epoch: 0271 train_loss= 3090.09717 reconstruction_loss= 796.12195 proj_loss= 1906.12561 pca_loss= 387.84949 accuracy= 0.61767 time= 0.04578
Epoch: 0281 train_loss= 2971.67188 reconstruction_loss= 729.28583 proj_loss= 1880.60706 pca_loss= 361.77902 accuracy= 0.62549 time= 0.04697
Epoch: 0291 train_loss= 2841.99243 reconstruction_loss= 643.07330 proj_loss= 1855.74524 pca_loss= 343.17374 accuracy= 0.63571 time= 0.04673

accuracy 0.61226
auc 0.42719
f1_score 0.19375
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 188
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 20154.20703 reconstruction_loss= 54.25158 proj_loss= 12640.35449 pca_loss= 7459.59961 accuracy= 0.58221 time= 0.07731
Epoch: 0011 train_loss= 13067.78027 reconstruction_loss= 18.55726 proj_loss= 11911.51074 pca_loss= 1137.71204 accuracy= 0.64412 time= 0.05980
Epoch: 0021 train_loss= 11715.34375 reconstruction_loss= 7.83891 proj_loss= 11229.53027 pca_loss= 477.97482 accuracy= 0.66516 time= 0.06069
Epoch: 0031 train_loss= 10856.28320 reconstruction_loss= 6.92773 proj_loss= 10588.28027 pca_loss= 261.07520 accuracy= 0.67719 time= 0.05965
Epoch: 0041 train_loss= 10162.50195 reconstruction_loss= 6.75297 proj_loss= 9988.84375 pca_loss= 166.90564 accuracy= 0.67899 time= 0.05961
Epoch: 0051 train_loss= 9563.90332 reconstruction_loss= 6.61941 proj_loss= 9431.84375 pca_loss= 125.44083 accuracy= 0.68019 time= 0.06022
Epoch: 0061 train_loss= 9027.45410 reconstruction_loss= 6.73349 proj_loss= 8915.52148 pca_loss= 105.19939 accuracy= 0.68079 time= 0.06092
Epoch: 0071 train_loss= 8531.51465 reconstruction_loss= 6.57237 proj_loss= 8436.71289 pca_loss= 88.22954 accuracy= 0.68200 time= 0.06063
Epoch: 0081 train_loss= 8077.50781 reconstruction_loss= 6.52125 proj_loss= 7992.28662 pca_loss= 78.69955 accuracy= 0.68440 time= 0.06043
Epoch: 0091 train_loss= 7657.25439 reconstruction_loss= 6.50112 proj_loss= 7578.94824 pca_loss= 71.80496 accuracy= 0.68500 time= 0.06085
Epoch: 0101 train_loss= 7266.18018 reconstruction_loss= 6.52901 proj_loss= 7193.97266 pca_loss= 65.67861 accuracy= 0.68560 time= 0.06344
Epoch: 0111 train_loss= 6906.42773 reconstruction_loss= 6.49769 proj_loss= 6834.89209 pca_loss= 65.03786 accuracy= 0.68560 time= 0.06361
Epoch: 0121 train_loss= 6563.70459 reconstruction_loss= 6.71908 proj_loss= 6499.70215 pca_loss= 57.28320 accuracy= 0.68380 time= 0.06131
Epoch: 0131 train_loss= 6258.63281 reconstruction_loss= 6.21689 proj_loss= 6186.33057 pca_loss= 66.08547 accuracy= 0.68139 time= 0.06209
Epoch: 0141 train_loss= 5954.23877 reconstruction_loss= 6.52597 proj_loss= 5892.93506 pca_loss= 54.77767 accuracy= 0.65314 time= 0.05972
Epoch: 0151 train_loss= 5688.65527 reconstruction_loss= 6.05893 proj_loss= 5618.16455 pca_loss= 64.43180 accuracy= 0.68440 time= 0.06182
Epoch: 0161 train_loss= 5441.55908 reconstruction_loss= 6.11769 proj_loss= 5361.64307 pca_loss= 73.79835 accuracy= 0.68200 time= 0.06009
Epoch: 0171 train_loss= 5178.51270 reconstruction_loss= 6.12550 proj_loss= 5120.97803 pca_loss= 51.40929 accuracy= 0.67899 time= 0.06027
Epoch: 0181 train_loss= 4942.19531 reconstruction_loss= 6.02059 proj_loss= 4894.52148 pca_loss= 41.65349 accuracy= 0.68019 time= 0.05948
Epoch: 0191 train_loss= 4723.66553 reconstruction_loss= 5.99019 proj_loss= 4681.01172 pca_loss= 36.66351 accuracy= 0.68560 time= 0.05978
Epoch: 0201 train_loss= 4526.35645 reconstruction_loss= 5.95922 proj_loss= 4479.61133 pca_loss= 40.78622 accuracy= 0.68801 time= 0.05935
Epoch: 0211 train_loss= 4457.16016 reconstruction_loss= 5.96728 proj_loss= 4290.47656 pca_loss= 160.71637 accuracy= 0.69342 time= 0.05962
Epoch: 0221 train_loss= 4232.01367 reconstruction_loss= 6.11272 proj_loss= 4114.66943 pca_loss= 111.23133 accuracy= 0.68200 time= 0.05966
Epoch: 0231 train_loss= 4010.58765 reconstruction_loss= 5.71756 proj_loss= 3948.04980 pca_loss= 56.82039 accuracy= 0.67719 time= 0.05942
Epoch: 0241 train_loss= 3835.35449 reconstruction_loss= 5.60143 proj_loss= 3790.35229 pca_loss= 39.40076 accuracy= 0.68440 time= 0.05949
Epoch: 0251 train_loss= 3678.86157 reconstruction_loss= 5.59970 proj_loss= 3640.81250 pca_loss= 32.44950 accuracy= 0.68440 time= 0.05970
Epoch: 0261 train_loss= 3534.05298 reconstruction_loss= 5.60080 proj_loss= 3498.85156 pca_loss= 29.60057 accuracy= 0.68560 time= 0.05922
Epoch: 0271 train_loss= 3396.75928 reconstruction_loss= 5.59615 proj_loss= 3363.92310 pca_loss= 27.23995 accuracy= 0.68440 time= 0.05947
Epoch: 0281 train_loss= 3266.44214 reconstruction_loss= 5.59205 proj_loss= 3235.61255 pca_loss= 25.23759 accuracy= 0.68440 time= 0.05984
Epoch: 0291 train_loss= 3143.28198 reconstruction_loss= 5.59059 proj_loss= 3113.49243 pca_loss= 24.19909 accuracy= 0.68440 time= 0.05912

accuracy 0.68440
auc 0.60811
f1_score 0.34375
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 273
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
Epoch: 0001 train_loss= 33906.01172 reconstruction_loss= 13945.44336 proj_loss= 12544.57910 pca_loss= 7415.98682 accuracy= 0.58581 time= 0.06481
Epoch: 0011 train_loss= 21585.63086 reconstruction_loss= 6623.60205 proj_loss= 12033.64941 pca_loss= 2928.37964 accuracy= 0.68680 time= 0.04980
Epoch: 0021 train_loss= 15936.36035 reconstruction_loss= 2905.98047 proj_loss= 11561.82910 pca_loss= 1468.55054 accuracy= 0.60445 time= 0.04697
Epoch: 0031 train_loss= 14276.58984 reconstruction_loss= 2265.51025 proj_loss= 11093.00586 pca_loss= 918.07458 accuracy= 0.59243 time= 0.04515
Epoch: 0041 train_loss= 13294.34570 reconstruction_loss= 1979.42749 proj_loss= 10624.10254 pca_loss= 690.81592 accuracy= 0.58702 time= 0.04515
Epoch: 0051 train_loss= 12571.45605 reconstruction_loss= 1837.80737 proj_loss= 10167.61523 pca_loss= 566.03339 accuracy= 0.58822 time= 0.04549
Epoch: 0061 train_loss= 11956.61328 reconstruction_loss= 1744.28357 proj_loss= 9726.29004 pca_loss= 486.04022 accuracy= 0.59243 time= 0.04532
Epoch: 0071 train_loss= 11423.59180 reconstruction_loss= 1690.90552 proj_loss= 9302.40039 pca_loss= 430.28629 accuracy= 0.59844 time= 0.04468
Epoch: 0081 train_loss= 10879.82324 reconstruction_loss= 1594.37354 proj_loss= 8896.71875 pca_loss= 388.73190 accuracy= 0.62308 time= 0.04479
Epoch: 0091 train_loss= 10386.58203 reconstruction_loss= 1519.81982 proj_loss= 8509.52051 pca_loss= 357.24219 accuracy= 0.62128 time= 0.04529
Epoch: 0101 train_loss= 9916.07324 reconstruction_loss= 1448.01599 proj_loss= 8140.46631 pca_loss= 327.59085 accuracy= 0.64292 time= 0.04505
Epoch: 0111 train_loss= 9483.43066 reconstruction_loss= 1388.87939 proj_loss= 7789.22461 pca_loss= 305.32721 accuracy= 0.63030 time= 0.04506
Epoch: 0121 train_loss= 9093.57715 reconstruction_loss= 1357.93384 proj_loss= 7455.12061 pca_loss= 280.52271 accuracy= 0.62489 time= 0.04484
Epoch: 0131 train_loss= 8709.52734 reconstruction_loss= 1312.46167 proj_loss= 7137.66797 pca_loss= 259.39728 accuracy= 0.62489 time= 0.04456
Epoch: 0141 train_loss= 8356.87207 reconstruction_loss= 1278.39136 proj_loss= 6836.27637 pca_loss= 242.20415 accuracy= 0.62128 time= 0.04461
Epoch: 0151 train_loss= 8009.58350 reconstruction_loss= 1234.23047 proj_loss= 6550.28223 pca_loss= 225.07097 accuracy= 0.62729 time= 0.04460
Epoch: 0161 train_loss= 7690.68408 reconstruction_loss= 1201.14954 proj_loss= 6278.84814 pca_loss= 210.68675 accuracy= 0.62188 time= 0.04490
Epoch: 0171 train_loss= 7390.05762 reconstruction_loss= 1172.72034 proj_loss= 6021.11963 pca_loss= 196.21770 accuracy= 0.62849 time= 0.04535
Epoch: 0181 train_loss= 7100.91895 reconstruction_loss= 1139.75720 proj_loss= 5776.34131 pca_loss= 184.82030 accuracy= 0.63150 time= 0.04511
Epoch: 0191 train_loss= 6831.56201 reconstruction_loss= 1111.19617 proj_loss= 5543.89209 pca_loss= 176.47368 accuracy= 0.62549 time= 0.04465
Epoch: 0201 train_loss= 6564.61279 reconstruction_loss= 1074.81677 proj_loss= 5323.25195 pca_loss= 166.54390 accuracy= 0.61647 time= 0.04479
Epoch: 0211 train_loss= 6299.05225 reconstruction_loss= 1032.41577 proj_loss= 5113.64941 pca_loss= 152.98660 accuracy= 0.62188 time= 0.04488
Epoch: 0221 train_loss= 6048.75195 reconstruction_loss= 992.92944 proj_loss= 4914.46240 pca_loss= 141.36058 accuracy= 0.62729 time= 0.04536
Epoch: 0231 train_loss= 5811.36182 reconstruction_loss= 951.87738 proj_loss= 4725.08057 pca_loss= 134.40358 accuracy= 0.61888 time= 0.04569
Epoch: 0241 train_loss= 5513.68213 reconstruction_loss= 836.49121 proj_loss= 4545.24561 pca_loss= 131.94522 accuracy= 0.62248 time= 0.04529
Epoch: 0251 train_loss= 11022.49805 reconstruction_loss= 5728.03076 proj_loss= 4396.38477 pca_loss= 898.08185 accuracy= 0.61647 time= 0.04610
Epoch: 0261 train_loss= 7164.94434 reconstruction_loss= 1780.79163 proj_loss= 4296.21973 pca_loss= 1087.93286 accuracy= 0.57619 time= 0.04594
Epoch: 0271 train_loss= 6484.76660 reconstruction_loss= 1501.17920 proj_loss= 4194.82861 pca_loss= 788.75885 accuracy= 0.59122 time= 0.04538
Epoch: 0281 train_loss= 5910.05273 reconstruction_loss= 1279.85864 proj_loss= 4094.74023 pca_loss= 535.45386 accuracy= 0.60806 time= 0.04568
Epoch: 0291 train_loss= 5429.82178 reconstruction_loss= 1085.65784 proj_loss= 3997.37427 pca_loss= 346.78958 accuracy= 0.60986 time= 0.04529

accuracy 0.63210
auc 0.51639
f1_score 0.23500
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 81
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 32961.32031 feature_loss= 59.66185 structure_loss= 8679.60840 proj_loss= 3229.69189 pca_loss= 20992.35547 accuracy= 0.79080 accuracy_s= 0.89300 accuracy_f= 0.79621 time= 0.08156
Epoch: 0011 train_loss= 28877.39648 feature_loss= 30.89679 structure_loss= 5677.43945 proj_loss= 3049.81421 pca_loss= 20119.24609 accuracy= 0.59603 accuracy_s= 0.76075 accuracy_f= 0.79862 time= 0.06286
Epoch: 0021 train_loss= 27096.96094 feature_loss= 18.72193 structure_loss= 4906.29443 proj_loss= 2875.11084 pca_loss= 19296.83398 accuracy= 0.58581 accuracy_s= 0.76014 accuracy_f= 0.81244 time= 0.06260
Epoch: 0031 train_loss= 25634.72266 feature_loss= 13.57193 structure_loss= 4386.60010 proj_loss= 2708.55591 pca_loss= 18525.99609 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.82447 time= 0.06249
Epoch: 0041 train_loss= 24316.88672 feature_loss= 10.39740 structure_loss= 3951.97241 proj_loss= 2551.03491 pca_loss= 17803.48242 accuracy= 0.58100 accuracy_s= 0.75954 accuracy_f= 0.83228 time= 0.06243
Epoch: 0051 train_loss= 23091.62891 feature_loss= 9.21054 structure_loss= 3554.35596 proj_loss= 2402.81689 pca_loss= 17125.24609 accuracy= 0.57920 accuracy_s= 0.75954 accuracy_f= 0.84310 time= 0.06287
Epoch: 0061 train_loss= 21948.01758 feature_loss= 8.33041 structure_loss= 3188.45386 proj_loss= 2263.78442 pca_loss= 16487.44922 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.06297
Epoch: 0071 train_loss= 20892.20703 feature_loss= 7.74106 structure_loss= 2864.97412 proj_loss= 2133.57153 pca_loss= 15885.91992 accuracy= 0.58040 accuracy_s= 0.75954 accuracy_f= 0.85573 time= 0.06194
Epoch: 0081 train_loss= 19923.76562 feature_loss= 7.12849 structure_loss= 2588.60107 proj_loss= 2011.64246 pca_loss= 15316.39258 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.85933 time= 0.06215
Epoch: 0091 train_loss= 19030.09375 feature_loss= 6.43329 structure_loss= 2350.83838 proj_loss= 1897.39026 pca_loss= 14775.43262 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.85512 time= 0.06200
Epoch: 0101 train_loss= 18185.20703 feature_loss= 6.25121 structure_loss= 2128.07007 proj_loss= 1790.28784 pca_loss= 14260.59863 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.86234 time= 0.06270
Epoch: 0111 train_loss= 17352.15820 feature_loss= 6.22156 structure_loss= 1885.99622 proj_loss= 1689.81750 pca_loss= 13770.12305 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.85212 time= 0.06256
Epoch: 0121 train_loss= 16475.66016 feature_loss= 6.20310 structure_loss= 1571.55322 proj_loss= 1595.46997 pca_loss= 13302.43457 accuracy= 0.57920 accuracy_s= 0.75954 accuracy_f= 0.84971 time= 0.06166
Epoch: 0131 train_loss= 15736.60352 feature_loss= 6.12298 structure_loss= 1367.88684 proj_loss= 1506.82263 pca_loss= 12855.77148 accuracy= 0.58822 accuracy_s= 0.75954 accuracy_f= 0.85873 time= 0.06178
Epoch: 0141 train_loss= 15083.83398 feature_loss= 6.13183 structure_loss= 1225.47449 proj_loss= 1423.60510 pca_loss= 12428.62207 accuracy= 0.63451 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.06270
Epoch: 0151 train_loss= 14463.06152 feature_loss= 6.08691 structure_loss= 1091.57532 proj_loss= 1345.47131 pca_loss= 12019.92773 accuracy= 0.66276 accuracy_s= 0.75954 accuracy_f= 0.85392 time= 0.06286
Epoch: 0161 train_loss= 13875.90430 feature_loss= 6.02636 structure_loss= 969.15045 proj_loss= 1272.07666 pca_loss= 11628.65039 accuracy= 0.66937 accuracy_s= 0.75954 accuracy_f= 0.85873 time= 0.06329
Epoch: 0171 train_loss= 13300.50488 feature_loss= 5.97093 structure_loss= 837.51398 proj_loss= 1203.08508 pca_loss= 11253.93457 accuracy= 0.68200 accuracy_s= 0.75954 accuracy_f= 0.85873 time= 0.06790
Epoch: 0181 train_loss= 12744.01758 feature_loss= 5.93290 structure_loss= 704.99939 proj_loss= 1138.20325 pca_loss= 10894.88184 accuracy= 0.69222 accuracy_s= 0.75954 accuracy_f= 0.85933 time= 0.06249
Epoch: 0191 train_loss= 12207.54688 feature_loss= 5.92008 structure_loss= 573.81769 proj_loss= 1077.17932 pca_loss= 10550.62988 accuracy= 0.70304 accuracy_s= 0.75954 accuracy_f= 0.85573 time= 0.06263
Epoch: 0201 train_loss= 11687.83398 feature_loss= 5.89380 structure_loss= 441.78952 proj_loss= 1019.75104 pca_loss= 10220.39941 accuracy= 0.70724 accuracy_s= 0.75954 accuracy_f= 0.85212 time= 0.06247
Epoch: 0211 train_loss= 11186.40039 feature_loss= 5.85923 structure_loss= 311.45801 proj_loss= 965.68372 pca_loss= 9903.39941 accuracy= 0.72468 accuracy_s= 0.75954 accuracy_f= 0.85332 time= 0.06296
Epoch: 0221 train_loss= 10724.01074 feature_loss= 5.85208 structure_loss= 204.82417 proj_loss= 914.77551 pca_loss= 9598.55859 accuracy= 0.72107 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.06169
Epoch: 0231 train_loss= 10311.17871 feature_loss= 5.79689 structure_loss= 133.64326 proj_loss= 866.80457 pca_loss= 9304.93359 accuracy= 0.72708 accuracy_s= 0.75954 accuracy_f= 0.85392 time= 0.06171
Epoch: 0241 train_loss= 9933.68262 feature_loss= 5.87561 structure_loss= 84.38893 proj_loss= 821.56714 pca_loss= 9021.85059 accuracy= 0.73249 accuracy_s= 0.75954 accuracy_f= 0.84911 time= 0.06245
Epoch: 0251 train_loss= 9586.68848 feature_loss= 5.75460 structure_loss= 53.05835 proj_loss= 778.88940 pca_loss= 8748.98633 accuracy= 0.73069 accuracy_s= 0.75954 accuracy_f= 0.85212 time= 0.06088
Epoch: 0261 train_loss= 9264.68652 feature_loss= 5.78073 structure_loss= 34.36871 proj_loss= 738.60767 pca_loss= 8485.92969 accuracy= 0.72708 accuracy_s= 0.75954 accuracy_f= 0.85032 time= 0.06227
Epoch: 0271 train_loss= 8958.41504 feature_loss= 5.75204 structure_loss= 19.70328 proj_loss= 700.56952 pca_loss= 8232.39062 accuracy= 0.72227 accuracy_s= 0.75954 accuracy_f= 0.84791 time= 0.06232
Epoch: 0281 train_loss= 8669.97266 feature_loss= 5.71902 structure_loss= 11.66185 proj_loss= 664.63586 pca_loss= 7987.95605 accuracy= 0.72468 accuracy_s= 0.75954 accuracy_f= 0.84731 time= 0.06379
Epoch: 0291 train_loss= 8395.63867 feature_loss= 5.69761 structure_loss= 7.05584 proj_loss= 630.67700 pca_loss= 7752.20850 accuracy= 0.72588 accuracy_s= 0.75954 accuracy_f= 0.85092 time= 0.06172

accuracy 0.72768
accuracy_s 0.75954
accuracy_f 0.85092
auc 0.69255
f1_score 0.43375
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 272
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6342078.00000 feature_loss= 57.52158 structure_loss= 9880.06445 proj_loss= 6311857.00000 pca_loss= 20283.47070 accuracy= 0.64833 accuracy_s= 0.76616 accuracy_f= 0.79321 time= 0.14780
Epoch: 0011 train_loss= 5944992.50000 feature_loss= 15.90133 structure_loss= 5992.44238 proj_loss= 5919995.50000 pca_loss= 18988.47852 accuracy= 0.59002 accuracy_s= 0.76075 accuracy_f= 0.79140 time= 0.12508
Epoch: 0021 train_loss= 5576642.00000 feature_loss= 9.59528 structure_loss= 5168.77393 proj_loss= 5553591.00000 pca_loss= 17872.53711 accuracy= 0.58822 accuracy_s= 0.76014 accuracy_f= 0.80703 time= 0.12548
Epoch: 0031 train_loss= 5234953.50000 feature_loss= 8.38743 structure_loss= 4658.41748 proj_loss= 5213354.50000 pca_loss= 16931.97656 accuracy= 0.58762 accuracy_s= 0.76014 accuracy_f= 0.83228 time= 0.12561
Epoch: 0041 train_loss= 4919115.50000 feature_loss= 8.09827 structure_loss= 4287.57861 proj_loss= 4898683.00000 pca_loss= 16136.88281 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.83288 time= 0.12545
Epoch: 0051 train_loss= 4627559.00000 feature_loss= 7.93264 structure_loss= 3994.57764 proj_loss= 4608106.50000 pca_loss= 15449.75098 accuracy= 0.57860 accuracy_s= 0.76014 accuracy_f= 0.84190 time= 0.12529
Epoch: 0061 train_loss= 4358350.00000 feature_loss= 7.79836 structure_loss= 3737.90503 proj_loss= 4339764.00000 pca_loss= 14840.70703 accuracy= 0.57740 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.12558
Epoch: 0071 train_loss= 4109536.25000 feature_loss= 7.68362 structure_loss= 3515.97632 proj_loss= 4091722.50000 pca_loss= 14289.98633 accuracy= 0.57680 accuracy_s= 0.75954 accuracy_f= 0.84911 time= 0.12592
Epoch: 0081 train_loss= 3879260.00000 feature_loss= 7.57889 structure_loss= 3324.90601 proj_loss= 3862142.75000 pca_loss= 13784.70605 accuracy= 0.57559 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.12527
Epoch: 0091 train_loss= 3665809.25000 feature_loss= 7.47293 structure_loss= 3145.48975 proj_loss= 3649340.00000 pca_loss= 13316.15430 accuracy= 0.57559 accuracy_s= 0.75954 accuracy_f= 0.85032 time= 0.12594
Epoch: 0101 train_loss= 3467672.00000 feature_loss= 7.37635 structure_loss= 2987.05054 proj_loss= 3451798.25000 pca_loss= 12879.19434 accuracy= 0.57800 accuracy_s= 0.75954 accuracy_f= 0.85032 time= 0.12621
Epoch: 0111 train_loss= 3283472.50000 feature_loss= 7.28469 structure_loss= 2834.93066 proj_loss= 3268161.00000 pca_loss= 12469.29785 accuracy= 0.57680 accuracy_s= 0.75954 accuracy_f= 0.85272 time= 0.12586
Epoch: 0121 train_loss= 3111999.25000 feature_loss= 7.19327 structure_loss= 2692.47192 proj_loss= 3097216.50000 pca_loss= 12082.91406 accuracy= 0.57920 accuracy_s= 0.75954 accuracy_f= 0.85032 time= 0.12549
Epoch: 0131 train_loss= 2952161.50000 feature_loss= 7.05824 structure_loss= 2559.13647 proj_loss= 2937877.50000 pca_loss= 11717.87500 accuracy= 0.57920 accuracy_s= 0.75954 accuracy_f= 0.85272 time= 0.12536
Epoch: 0141 train_loss= 2802981.25000 feature_loss= 6.64135 structure_loss= 2431.41968 proj_loss= 2789171.50000 pca_loss= 11371.74121 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.84070 time= 0.12585
Epoch: 0151 train_loss= 2663569.25000 feature_loss= 6.29033 structure_loss= 2299.04346 proj_loss= 2650221.00000 pca_loss= 11042.97949 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.84370 time= 0.12600
Epoch: 0161 train_loss= 2533154.50000 feature_loss= 6.10590 structure_loss= 2181.08276 proj_loss= 2520237.75000 pca_loss= 10729.55078 accuracy= 0.58341 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.12525
Epoch: 0171 train_loss= 2411001.50000 feature_loss= 5.96957 structure_loss= 2056.10547 proj_loss= 2398509.00000 pca_loss= 10430.50586 accuracy= 0.58521 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.12515
Epoch: 0181 train_loss= 2296486.75000 feature_loss= 5.87552 structure_loss= 1947.14282 proj_loss= 2284388.75000 pca_loss= 10145.02930 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.84551 time= 0.12526
Epoch: 0191 train_loss= 2189001.50000 feature_loss= 5.84622 structure_loss= 1832.29065 proj_loss= 2177291.50000 pca_loss= 9871.74805 accuracy= 0.58521 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.12667
Epoch: 0201 train_loss= 2088032.50000 feature_loss= 5.81904 structure_loss= 1729.67090 proj_loss= 2076686.87500 pca_loss= 9610.07129 accuracy= 0.58281 accuracy_s= 0.75954 accuracy_f= 0.84911 time= 0.12684
Epoch: 0211 train_loss= 1993086.37500 feature_loss= 5.81139 structure_loss= 1631.06873 proj_loss= 1982090.25000 pca_loss= 9359.18945 accuracy= 0.58581 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.12642
Epoch: 0221 train_loss= 1903720.87500 feature_loss= 5.78450 structure_loss= 1535.86536 proj_loss= 1893060.62500 pca_loss= 9118.59473 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.12590
Epoch: 0231 train_loss= 1819538.75000 feature_loss= 5.75296 structure_loss= 1449.50513 proj_loss= 1809196.12500 pca_loss= 8887.31934 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.84911 time= 0.12565
Epoch: 0241 train_loss= 1740167.37500 feature_loss= 5.81748 structure_loss= 1368.05566 proj_loss= 1730128.37500 pca_loss= 8665.10352 accuracy= 0.58521 accuracy_s= 0.75954 accuracy_f= 0.84250 time= 0.12626
Epoch: 0251 train_loss= 1665267.75000 feature_loss= 5.73361 structure_loss= 1289.71899 proj_loss= 1655520.87500 pca_loss= 8451.34570 accuracy= 0.58581 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.12599
Epoch: 0261 train_loss= 1594534.50000 feature_loss= 5.76355 structure_loss= 1218.38989 proj_loss= 1585064.87500 pca_loss= 8245.48145 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.84971 time= 0.12684
Epoch: 0271 train_loss= 1527678.25000 feature_loss= 5.71954 structure_loss= 1149.22375 proj_loss= 1518476.12500 pca_loss= 8047.07617 accuracy= 0.58341 accuracy_s= 0.75954 accuracy_f= 0.84911 time= 0.12616
Epoch: 0281 train_loss= 1464442.87500 feature_loss= 5.77517 structure_loss= 1086.00854 proj_loss= 1455495.12500 pca_loss= 7855.95801 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.84370 time= 0.12607
Epoch: 0291 train_loss= 1404584.12500 feature_loss= 5.83910 structure_loss= 1025.49951 proj_loss= 1395881.25000 pca_loss= 7671.52979 accuracy= 0.58581 accuracy_s= 0.75954 accuracy_f= 0.83228 time= 0.12661

accuracy 0.58461
accuracy_s 0.75954
accuracy_f 0.84551
auc 0.29626
f1_score 0.13625
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 202
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 32271.81055 feature_loss= 59.55117 structure_loss= 11592.03418 proj_loss= 12484.07617 pca_loss= 8136.15039 accuracy= 0.73550 accuracy_s= 0.86054 accuracy_f= 0.79321 time= 0.08040
Epoch: 0011 train_loss= 28612.30469 feature_loss= 33.66486 structure_loss= 9011.01270 proj_loss= 11711.13184 pca_loss= 7856.49658 accuracy= 0.58762 accuracy_s= 0.76014 accuracy_f= 0.79441 time= 0.05998
Epoch: 0021 train_loss= 26856.43359 feature_loss= 24.99616 structure_loss= 8260.25000 proj_loss= 10979.56348 pca_loss= 7591.62500 accuracy= 0.58581 accuracy_s= 0.76014 accuracy_f= 0.80102 time= 0.06035
Epoch: 0031 train_loss= 25290.77734 feature_loss= 16.66752 structure_loss= 7637.49756 proj_loss= 10298.07227 pca_loss= 7338.53857 accuracy= 0.58641 accuracy_s= 0.76014 accuracy_f= 0.81725 time= 0.06053
Epoch: 0041 train_loss= 23868.28906 feature_loss= 10.30922 structure_loss= 7094.50098 proj_loss= 9667.08594 pca_loss= 7096.39307 accuracy= 0.59002 accuracy_s= 0.76014 accuracy_f= 0.83108 time= 0.06064
Epoch: 0051 train_loss= 22511.80664 feature_loss= 8.74925 structure_loss= 6552.99463 proj_loss= 9084.49512 pca_loss= 6865.56787 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.83889 time= 0.06049
Epoch: 0061 train_loss= 21163.28711 feature_loss= 7.92334 structure_loss= 5960.66602 proj_loss= 8547.82324 pca_loss= 6646.87500 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.83408 time= 0.06053
Epoch: 0071 train_loss= 19712.82031 feature_loss= 7.22884 structure_loss= 5209.08838 proj_loss= 8054.99658 pca_loss= 6441.50586 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.83469 time= 0.06051
Epoch: 0081 train_loss= 18003.66992 feature_loss= 6.98068 structure_loss= 4142.39990 proj_loss= 7603.53076 pca_loss= 6250.75928 accuracy= 0.57920 accuracy_s= 0.75954 accuracy_f= 0.82988 time= 0.06020
Epoch: 0091 train_loss= 16046.44727 feature_loss= 6.80733 structure_loss= 2781.40283 proj_loss= 7186.20898 pca_loss= 6072.02881 accuracy= 0.57800 accuracy_s= 0.75954 accuracy_f= 0.83408 time= 0.06059
Epoch: 0101 train_loss= 13858.32812 feature_loss= 6.78939 structure_loss= 1158.61670 proj_loss= 6792.69336 pca_loss= 5900.22852 accuracy= 0.58341 accuracy_s= 0.75954 accuracy_f= 0.83048 time= 0.05956
Epoch: 0111 train_loss= 12424.14258 feature_loss= 6.75637 structure_loss= 268.68326 proj_loss= 6418.31787 pca_loss= 5730.38525 accuracy= 0.59182 accuracy_s= 0.75954 accuracy_f= 0.83288 time= 0.06003
Epoch: 0121 train_loss= 11655.12695 feature_loss= 6.83053 structure_loss= 23.16074 proj_loss= 6064.90967 pca_loss= 5560.22559 accuracy= 0.67659 accuracy_s= 0.75954 accuracy_f= 0.83108 time= 0.05922
Epoch: 0131 train_loss= 11136.77344 feature_loss= 7.01232 structure_loss= 2.24105 proj_loss= 5734.78369 pca_loss= 5392.73584 accuracy= 0.68500 accuracy_s= 0.75954 accuracy_f= 0.81725 time= 0.06000
Epoch: 0141 train_loss= 10665.98438 feature_loss= 6.90006 structure_loss= 0.94479 proj_loss= 5427.46631 pca_loss= 5230.67285 accuracy= 0.68079 accuracy_s= 0.75954 accuracy_f= 0.82507 time= 0.05991
Epoch: 0151 train_loss= 10223.79980 feature_loss= 6.78842 structure_loss= 0.61837 proj_loss= 5141.29541 pca_loss= 5075.09766 accuracy= 0.68981 accuracy_s= 0.75954 accuracy_f= 0.83348 time= 0.05939
Epoch: 0161 train_loss= 9807.79297 feature_loss= 6.77957 structure_loss= 0.55099 proj_loss= 4874.38281 pca_loss= 4926.08008 accuracy= 0.66877 accuracy_s= 0.75954 accuracy_f= 0.82747 time= 0.05993
Epoch: 0171 train_loss= 9415.65820 feature_loss= 6.80098 structure_loss= 0.54438 proj_loss= 4625.01270 pca_loss= 4783.30078 accuracy= 0.66877 accuracy_s= 0.75954 accuracy_f= 0.82507 time= 0.05938
Epoch: 0181 train_loss= 9045.26953 feature_loss= 6.74212 structure_loss= 0.53272 proj_loss= 4391.57715 pca_loss= 4646.41748 accuracy= 0.66877 accuracy_s= 0.75954 accuracy_f= 0.82807 time= 0.06006
Epoch: 0191 train_loss= 8695.18066 feature_loss= 6.65306 structure_loss= 0.71685 proj_loss= 4172.75977 pca_loss= 4515.05078 accuracy= 0.68680 accuracy_s= 0.75954 accuracy_f= 0.84310 time= 0.05922
Epoch: 0201 train_loss= 8363.47852 feature_loss= 6.67827 structure_loss= 0.55879 proj_loss= 3967.38428 pca_loss= 4388.85742 accuracy= 0.68921 accuracy_s= 0.75954 accuracy_f= 0.83469 time= 0.06013
Epoch: 0211 train_loss= 8049.33643 feature_loss= 6.84604 structure_loss= 0.55755 proj_loss= 3774.40454 pca_loss= 4267.52832 accuracy= 0.66156 accuracy_s= 0.75954 accuracy_f= 0.82627 time= 0.05986
Epoch: 0221 train_loss= 7750.90186 feature_loss= 6.79352 structure_loss= 0.52535 proj_loss= 3592.85254 pca_loss= 4150.73047 accuracy= 0.66456 accuracy_s= 0.75954 accuracy_f= 0.82747 time= 0.05967
Epoch: 0231 train_loss= 7467.66895 feature_loss= 6.93441 structure_loss= 0.55643 proj_loss= 3421.92969 pca_loss= 4038.24854 accuracy= 0.66035 accuracy_s= 0.75954 accuracy_f= 0.81785 time= 0.06012
Epoch: 0241 train_loss= 7199.23730 feature_loss= 7.19848 structure_loss= 1.19889 proj_loss= 3260.91162 pca_loss= 3929.92847 accuracy= 0.64893 accuracy_s= 0.75954 accuracy_f= 0.80824 time= 0.05988
Epoch: 0251 train_loss= 6942.43652 feature_loss= 7.16520 structure_loss= 0.66452 proj_loss= 3109.08521 pca_loss= 3825.52148 accuracy= 0.65855 accuracy_s= 0.75954 accuracy_f= 0.81184 time= 0.06010
Epoch: 0261 train_loss= 6698.14893 feature_loss= 7.24540 structure_loss= 0.52866 proj_loss= 2965.68091 pca_loss= 3724.69385 accuracy= 0.64893 accuracy_s= 0.75954 accuracy_f= 0.80343 time= 0.05915
Epoch: 0271 train_loss= 6466.21582 feature_loss= 7.32958 structure_loss= 0.93318 proj_loss= 2830.40234 pca_loss= 3627.55103 accuracy= 0.65374 accuracy_s= 0.75954 accuracy_f= 0.80763 time= 0.06026
Epoch: 0281 train_loss= 6244.20898 feature_loss= 7.21509 structure_loss= 0.67165 proj_loss= 2702.59790 pca_loss= 3533.72412 accuracy= 0.65915 accuracy_s= 0.75954 accuracy_f= 0.80403 time= 0.05946
Epoch: 0291 train_loss= 6032.46289 feature_loss= 7.12186 structure_loss= 0.84766 proj_loss= 2581.53979 pca_loss= 3442.95386 accuracy= 0.69282 accuracy_s= 0.75954 accuracy_f= 0.80523 time= 0.06024

accuracy 0.68861
accuracy_s 0.75954
accuracy_f 0.82026
auc 0.61631
f1_score 0.35250
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 300
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 31353918.00000 feature_loss= 57.42075 structure_loss= 12391.09277 proj_loss= 31332598.00000 pca_loss= 8872.06152 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.78960 time= 0.10630
Epoch: 0011 train_loss= 29409136.00000 feature_loss= 32.00977 structure_loss= 9726.10645 proj_loss= 29390814.00000 pca_loss= 8564.90039 accuracy= 0.59122 accuracy_s= 0.76014 accuracy_f= 0.79862 time= 0.08794
Epoch: 0021 train_loss= 27592114.00000 feature_loss= 21.39998 structure_loss= 8908.04492 proj_loss= 27574914.00000 pca_loss= 8269.67188 accuracy= 0.58762 accuracy_s= 0.76014 accuracy_f= 0.79982 time= 0.08837
Epoch: 0031 train_loss= 25904846.00000 feature_loss= 13.81005 structure_loss= 8330.74512 proj_loss= 25888516.00000 pca_loss= 7985.59326 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.81304 time= 0.08723
Epoch: 0041 train_loss= 24344194.00000 feature_loss= 8.91679 structure_loss= 7844.22803 proj_loss= 24328624.00000 pca_loss= 7715.15674 accuracy= 0.58702 accuracy_s= 0.75954 accuracy_f= 0.81665 time= 0.08661
Epoch: 0051 train_loss= 22902806.00000 feature_loss= 7.80193 structure_loss= 7407.09717 proj_loss= 22887934.00000 pca_loss= 7457.77686 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.84130 time= 0.08670
Epoch: 0061 train_loss= 21571472.00000 feature_loss= 7.36016 structure_loss= 7009.70996 proj_loss= 21557240.00000 pca_loss= 7213.15771 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.84310 time= 0.08667
Epoch: 0071 train_loss= 20340602.00000 feature_loss= 7.09222 structure_loss= 6630.70020 proj_loss= 20326984.00000 pca_loss= 6980.78223 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.84791 time= 0.08722
Epoch: 0081 train_loss= 19201082.00000 feature_loss= 6.97546 structure_loss= 6227.39404 proj_loss= 19188088.00000 pca_loss= 6759.63184 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.84611 time= 0.08701
Epoch: 0091 train_loss= 18144578.00000 feature_loss= 6.94028 structure_loss= 5780.77246 proj_loss= 18132242.00000 pca_loss= 6548.96631 accuracy= 0.58341 accuracy_s= 0.75954 accuracy_f= 0.84671 time= 0.08687
Epoch: 0101 train_loss= 17163524.00000 feature_loss= 6.93017 structure_loss= 5205.67725 proj_loss= 17151964.00000 pca_loss= 6348.16016 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.84851 time= 0.08645
Epoch: 0111 train_loss= 16251195.00000 feature_loss= 6.97409 structure_loss= 4473.58057 proj_loss= 16240557.00000 pca_loss= 6156.55029 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.84070 time= 0.08635
Epoch: 0121 train_loss= 15401646.00000 feature_loss= 7.03223 structure_loss= 3631.34839 proj_loss= 15392034.00000 pca_loss= 5973.86426 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.84250 time= 0.08692
Epoch: 0131 train_loss= 14609575.00000 feature_loss= 7.05529 structure_loss= 2741.08203 proj_loss= 14601027.00000 pca_loss= 5799.52637 accuracy= 0.57800 accuracy_s= 0.75954 accuracy_f= 0.84130 time= 0.08671
Epoch: 0141 train_loss= 13870177.00000 feature_loss= 6.97486 structure_loss= 1812.99219 proj_loss= 13862724.00000 pca_loss= 5633.20166 accuracy= 0.58100 accuracy_s= 0.75954 accuracy_f= 0.84070 time= 0.08666
Epoch: 0151 train_loss= 13179465.00000 feature_loss= 7.03815 structure_loss= 1191.00989 proj_loss= 13172793.00000 pca_loss= 5473.61768 accuracy= 0.58581 accuracy_s= 0.75954 accuracy_f= 0.83469 time= 0.08621
Epoch: 0161 train_loss= 12533469.00000 feature_loss= 6.87419 structure_loss= 813.20056 proj_loss= 12527328.00000 pca_loss= 5320.58984 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.84731 time= 0.08687
Epoch: 0171 train_loss= 11928562.00000 feature_loss= 6.94618 structure_loss= 580.09875 proj_loss= 11922801.00000 pca_loss= 5174.10645 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.83950 time= 0.08689
Epoch: 0181 train_loss= 11361492.00000 feature_loss= 6.95593 structure_loss= 432.66705 proj_loss= 11356018.00000 pca_loss= 5033.80664 accuracy= 0.58161 accuracy_s= 0.75954 accuracy_f= 0.83829 time= 0.08697
Epoch: 0191 train_loss= 10829318.00000 feature_loss= 6.83887 structure_loss= 331.69687 proj_loss= 10824080.00000 pca_loss= 4899.42920 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.84370 time= 0.08747
Epoch: 0201 train_loss= 10329396.00000 feature_loss= 6.87183 structure_loss= 263.98792 proj_loss= 10324354.00000 pca_loss= 4770.59424 accuracy= 0.58942 accuracy_s= 0.75954 accuracy_f= 0.84370 time= 0.08708
Epoch: 0211 train_loss= 9859316.00000 feature_loss= 6.87745 structure_loss= 217.10208 proj_loss= 9854445.00000 pca_loss= 4647.04248 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.84070 time= 0.08765
Epoch: 0221 train_loss= 9416887.00000 feature_loss= 6.86781 structure_loss= 184.86621 proj_loss= 9412166.00000 pca_loss= 4528.50781 accuracy= 0.58221 accuracy_s= 0.75954 accuracy_f= 0.83950 time= 0.08740
Epoch: 0231 train_loss= 9000110.00000 feature_loss= 6.75613 structure_loss= 164.02512 proj_loss= 8995524.00000 pca_loss= 4414.68945 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.84491 time= 0.09328
Epoch: 0241 train_loss= 8607152.00000 feature_loss= 6.78019 structure_loss= 146.64014 proj_loss= 8602694.00000 pca_loss= 4305.36572 accuracy= 0.58641 accuracy_s= 0.75954 accuracy_f= 0.83889 time= 0.08779
Epoch: 0251 train_loss= 8236346.00000 feature_loss= 6.88502 structure_loss= 132.45844 proj_loss= 8232006.00000 pca_loss= 4200.31445 accuracy= 0.58461 accuracy_s= 0.75954 accuracy_f= 0.83529 time= 0.08785
Epoch: 0261 train_loss= 7886155.50000 feature_loss= 6.99109 structure_loss= 120.88565 proj_loss= 7881928.00000 pca_loss= 4099.31396 accuracy= 0.58401 accuracy_s= 0.75954 accuracy_f= 0.82928 time= 0.08737
Epoch: 0271 train_loss= 7555174.00000 feature_loss= 6.91634 structure_loss= 109.76492 proj_loss= 7551055.50000 pca_loss= 4002.15723 accuracy= 0.58521 accuracy_s= 0.75954 accuracy_f= 0.83529 time= 0.08761
Epoch: 0281 train_loss= 7242111.00000 feature_loss= 7.35949 structure_loss= 100.47784 proj_loss= 7238094.50000 pca_loss= 3908.65430 accuracy= 0.58702 accuracy_s= 0.75954 accuracy_f= 0.81425 time= 0.08686
Epoch: 0291 train_loss= 6945775.50000 feature_loss= 7.87503 structure_loss= 91.97756 proj_loss= 6941857.00000 pca_loss= 3818.62354 accuracy= 0.58762 accuracy_s= 0.75954 accuracy_f= 0.80824 time= 0.08773

accuracy 0.58882
accuracy_s 0.75954
accuracy_f 0.80523
auc 0.28012
f1_score 0.14500
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 508
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 24321.54883 reconstruction_loss= 59.71041 proj_loss= 3240.22339 pca_loss= 21021.61523 accuracy= 0.62609 time= 0.05622
Epoch: 0011 train_loss= 23205.85156 reconstruction_loss= 29.17346 proj_loss= 3050.39722 pca_loss= 20126.28125 accuracy= 0.62789 time= 0.04177
Epoch: 0021 train_loss= 22175.02344 reconstruction_loss= 18.24511 proj_loss= 2871.47583 pca_loss= 19285.30273 accuracy= 0.63931 time= 0.04181
Epoch: 0031 train_loss= 21214.30078 reconstruction_loss= 13.14213 proj_loss= 2702.80200 pca_loss= 18498.35742 accuracy= 0.65915 time= 0.04181
Epoch: 0041 train_loss= 20316.16406 reconstruction_loss= 10.22973 proj_loss= 2544.02490 pca_loss= 17761.91016 accuracy= 0.69402 time= 0.04159
Epoch: 0051 train_loss= 19474.98438 reconstruction_loss= 8.79299 proj_loss= 2394.89087 pca_loss= 17071.30078 accuracy= 0.71085 time= 0.04153
Epoch: 0061 train_loss= 18685.19531 reconstruction_loss= 8.22930 proj_loss= 2255.05493 pca_loss= 16421.91211 accuracy= 0.73430 time= 0.04107
Epoch: 0071 train_loss= 17941.12109 reconstruction_loss= 7.43744 proj_loss= 2124.08179 pca_loss= 15809.60156 accuracy= 0.73910 time= 0.04123
Epoch: 0081 train_loss= 17239.13477 reconstruction_loss= 6.85369 proj_loss= 2001.47815 pca_loss= 15230.80273 accuracy= 0.74872 time= 0.04119
Epoch: 0091 train_loss= 16575.56836 reconstruction_loss= 6.36951 proj_loss= 1886.71155 pca_loss= 14682.48730 accuracy= 0.75233 time= 0.04100
Epoch: 0101 train_loss= 15947.48340 reconstruction_loss= 6.15577 proj_loss= 1779.25793 pca_loss= 14162.06934 accuracy= 0.74992 time= 0.04221
Epoch: 0111 train_loss= 15352.04199 reconstruction_loss= 6.11383 proj_loss= 1678.61328 pca_loss= 13667.31445 accuracy= 0.75534 time= 0.04133
Epoch: 0121 train_loss= 14786.70117 reconstruction_loss= 6.12428 proj_loss= 1584.29883 pca_loss= 13196.27832 accuracy= 0.74512 time= 0.04095
Epoch: 0131 train_loss= 14249.32812 reconstruction_loss= 6.21401 proj_loss= 1495.87122 pca_loss= 12747.24316 accuracy= 0.77397 time= 0.04085
Epoch: 0141 train_loss= 13737.57324 reconstruction_loss= 5.97088 proj_loss= 1412.91797 pca_loss= 12318.68457 accuracy= 0.74992 time= 0.04130
Epoch: 0151 train_loss= 13250.28809 reconstruction_loss= 5.98997 proj_loss= 1335.05847 pca_loss= 11909.23926 accuracy= 0.75654 time= 0.04104
Epoch: 0161 train_loss= 12785.66992 reconstruction_loss= 6.05154 proj_loss= 1261.94116 pca_loss= 11517.67773 accuracy= 0.78118 time= 0.04101
Epoch: 0171 train_loss= 12342.18262 reconstruction_loss= 6.06044 proj_loss= 1193.24146 pca_loss= 11142.88086 accuracy= 0.76976 time= 0.04278
Epoch: 0181 train_loss= 11918.45703 reconstruction_loss= 5.95774 proj_loss= 1128.65991 pca_loss= 10783.83887 accuracy= 0.76075 time= 0.04159
Epoch: 0191 train_loss= 11513.43848 reconstruction_loss= 5.89470 proj_loss= 1067.91943 pca_loss= 10439.62402 accuracy= 0.75954 time= 0.04217
Epoch: 0201 train_loss= 11125.96680 reconstruction_loss= 5.81645 proj_loss= 1010.76392 pca_loss= 10109.38672 accuracy= 0.75714 time= 0.04127
Epoch: 0211 train_loss= 10755.12305 reconstruction_loss= 5.82014 proj_loss= 956.95624 pca_loss= 9792.34668 accuracy= 0.76075 time= 0.04105
Epoch: 0221 train_loss= 10399.91211 reconstruction_loss= 5.85115 proj_loss= 906.27728 pca_loss= 9487.78418 accuracy= 0.79020 time= 0.04106
Epoch: 0231 train_loss= 10059.31641 reconstruction_loss= 5.75975 proj_loss= 858.52362 pca_loss= 9195.03320 accuracy= 0.75774 time= 0.04106
Epoch: 0241 train_loss= 9732.74023 reconstruction_loss= 5.75617 proj_loss= 813.50696 pca_loss= 8913.47754 accuracy= 0.75534 time= 0.04157
Epoch: 0251 train_loss= 9419.39648 reconstruction_loss= 5.79982 proj_loss= 771.05261 pca_loss= 8642.54395 accuracy= 0.77938 time= 0.04162
Epoch: 0261 train_loss= 9118.41113 reconstruction_loss= 5.71342 proj_loss= 730.99860 pca_loss= 8381.69922 accuracy= 0.75954 time= 0.04146
Epoch: 0271 train_loss= 8829.32715 reconstruction_loss= 5.68831 proj_loss= 693.19391 pca_loss= 8130.44482 accuracy= 0.76495 time= 0.04151
Epoch: 0281 train_loss= 8551.49805 reconstruction_loss= 5.68225 proj_loss= 657.49872 pca_loss= 7888.31738 accuracy= 0.75714 time= 0.04188
Epoch: 0291 train_loss= 8284.35449 reconstruction_loss= 5.68993 proj_loss= 623.78290 pca_loss= 7654.88184 accuracy= 0.75473 time= 0.04179

accuracy 0.74752
auc 0.71673
f1_score 0.47500
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 214
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6332166.50000 reconstruction_loss= 57.49339 proj_loss= 6312249.00000 pca_loss= 19859.75586 accuracy= 0.58942 time= 0.12422
Epoch: 0011 train_loss= 5938871.00000 reconstruction_loss= 21.84753 proj_loss= 5920203.50000 pca_loss= 18645.33789 accuracy= 0.60986 time= 0.10533
Epoch: 0021 train_loss= 5571262.50000 reconstruction_loss= 11.92624 proj_loss= 5553652.50000 pca_loss= 17598.07031 accuracy= 0.65915 time= 0.10424
Epoch: 0031 train_loss= 5230030.50000 reconstruction_loss= 8.45244 proj_loss= 5213312.50000 pca_loss= 16709.35938 accuracy= 0.68019 time= 0.10479
Epoch: 0041 train_loss= 4914521.50000 reconstruction_loss= 7.64702 proj_loss= 4898563.00000 pca_loss= 15950.85840 accuracy= 0.70304 time= 0.10467
Epoch: 0051 train_loss= 4623224.00000 reconstruction_loss= 7.39745 proj_loss= 4607926.00000 pca_loss= 15290.42676 accuracy= 0.72468 time= 0.10491
Epoch: 0061 train_loss= 4354243.00000 reconstruction_loss= 7.22609 proj_loss= 4339534.00000 pca_loss= 14701.93848 accuracy= 0.73430 time= 0.10510
Epoch: 0071 train_loss= 4105625.75000 reconstruction_loss= 7.11107 proj_loss= 4091451.50000 pca_loss= 14167.26953 accuracy= 0.73971 time= 0.10428
Epoch: 0081 train_loss= 3875518.00000 reconstruction_loss= 7.00907 proj_loss= 3861836.25000 pca_loss= 13674.79590 accuracy= 0.73850 time= 0.10424
Epoch: 0091 train_loss= 3662227.50000 reconstruction_loss= 6.90735 proj_loss= 3649003.50000 pca_loss= 13216.97363 accuracy= 0.74151 time= 0.10516
Epoch: 0101 train_loss= 3464231.00000 reconstruction_loss= 6.81362 proj_loss= 3451435.75000 pca_loss= 12788.59570 accuracy= 0.74692 time= 0.10472
Epoch: 0111 train_loss= 3280168.75000 reconstruction_loss= 6.72930 proj_loss= 3267776.25000 pca_loss= 12385.80273 accuracy= 0.74391 time= 0.10582
Epoch: 0121 train_loss= 3108824.25000 reconstruction_loss= 6.65878 proj_loss= 3096812.00000 pca_loss= 12005.59277 accuracy= 0.74331 time= 0.11273
Epoch: 0131 train_loss= 2949108.50000 reconstruction_loss= 6.60492 proj_loss= 2937456.50000 pca_loss= 11645.57910 accuracy= 0.74211 time= 0.11159
Epoch: 0141 train_loss= 2800046.25000 reconstruction_loss= 6.59941 proj_loss= 2788736.00000 pca_loss= 11303.79590 accuracy= 0.74451 time= 0.11508
Epoch: 0151 train_loss= 2660759.50000 reconstruction_loss= 6.55310 proj_loss= 2649774.50000 pca_loss= 10978.62109 accuracy= 0.74572 time= 0.11359
Epoch: 0161 train_loss= 2530457.00000 reconstruction_loss= 6.53434 proj_loss= 2519781.75000 pca_loss= 10668.66992 accuracy= 0.74451 time= 0.10816
Epoch: 0171 train_loss= 2408424.25000 reconstruction_loss= 6.50599 proj_loss= 2398045.00000 pca_loss= 10372.76367 accuracy= 0.74992 time= 0.11279
Epoch: 0181 train_loss= 2294014.50000 reconstruction_loss= 6.45235 proj_loss= 2283918.25000 pca_loss= 10089.87012 accuracy= 0.74632 time= 0.10501
Epoch: 0191 train_loss= 2186642.50000 reconstruction_loss= 6.42989 proj_loss= 2176817.00000 pca_loss= 9819.07910 accuracy= 0.75053 time= 0.10856
Epoch: 0201 train_loss= 2085774.62500 reconstruction_loss= 6.40470 proj_loss= 2076208.62500 pca_loss= 9559.58789 accuracy= 0.74932 time= 0.10530
Epoch: 0211 train_loss= 1990926.62500 reconstruction_loss= 6.38980 proj_loss= 1981609.62500 pca_loss= 9310.67383 accuracy= 0.74692 time= 0.10573
Epoch: 0221 train_loss= 1901657.12500 reconstruction_loss= 6.36607 proj_loss= 1892579.12500 pca_loss= 9071.68555 accuracy= 0.75113 time= 0.11519
Epoch: 0231 train_loss= 1817562.75000 reconstruction_loss= 6.35666 proj_loss= 1808714.37500 pca_loss= 8842.03223 accuracy= 0.74992 time= 0.10679
Epoch: 0241 train_loss= 1738275.12500 reconstruction_loss= 6.33519 proj_loss= 1729647.62500 pca_loss= 8621.17773 accuracy= 0.74692 time= 0.11557
Epoch: 0251 train_loss= 1663456.00000 reconstruction_loss= 6.31098 proj_loss= 1655041.12500 pca_loss= 8408.62793 accuracy= 0.75173 time= 0.11176
Epoch: 0261 train_loss= 1592797.12500 reconstruction_loss= 6.27429 proj_loss= 1584587.00000 pca_loss= 8203.92871 accuracy= 0.74872 time= 0.10918
Epoch: 0271 train_loss= 1526013.87500 reconstruction_loss= 6.25479 proj_loss= 1518001.00000 pca_loss= 8006.66602 accuracy= 0.74872 time= 0.10574
Epoch: 0281 train_loss= 1462845.62500 reconstruction_loss= 6.27733 proj_loss= 1455022.87500 pca_loss= 7816.45117 accuracy= 0.76616 time= 0.10781
Epoch: 0291 train_loss= 1403051.62500 reconstruction_loss= 6.21303 proj_loss= 1395412.50000 pca_loss= 7632.92529 accuracy= 0.74692 time= 0.11071

accuracy 0.75413
auc 0.71887
f1_score 0.48875
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 765
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 32657.85547 reconstruction_loss= 8494.59277 proj_loss= 3230.97656 pca_loss= 20932.28516 accuracy= 0.79080 time= 0.03754
Epoch: 0011 train_loss= 28693.33594 reconstruction_loss= 5581.71973 proj_loss= 3049.35547 pca_loss= 20062.25977 accuracy= 0.58702 time= 0.02626
Epoch: 0021 train_loss= 26951.93750 reconstruction_loss= 4836.07520 proj_loss= 2873.54102 pca_loss= 19242.32031 accuracy= 0.58581 time= 0.02626
Epoch: 0031 train_loss= 25506.52344 reconstruction_loss= 4327.25146 proj_loss= 2706.39355 pca_loss= 18472.87891 accuracy= 0.58461 time= 0.04670
Epoch: 0041 train_loss= 24202.51172 reconstruction_loss= 3902.85059 proj_loss= 2548.62354 pca_loss= 17751.03711 accuracy= 0.58221 time= 0.02632
Epoch: 0051 train_loss= 22983.64258 reconstruction_loss= 3510.14673 proj_loss= 2400.37280 pca_loss= 17073.12305 accuracy= 0.58100 time= 0.02654
Epoch: 0061 train_loss= 21842.48633 reconstruction_loss= 3145.54126 proj_loss= 2261.44067 pca_loss= 16435.50391 accuracy= 0.57499 time= 0.02628
Epoch: 0071 train_loss= 20796.23828 reconstruction_loss= 2830.65698 proj_loss= 2131.46484 pca_loss= 15834.11621 accuracy= 0.58100 time= 0.02628
Epoch: 0081 train_loss= 19836.31445 reconstruction_loss= 2561.55469 proj_loss= 2009.86035 pca_loss= 15264.89941 accuracy= 0.58281 time= 0.02629
Epoch: 0091 train_loss= 18941.78320 reconstruction_loss= 2321.13672 proj_loss= 1896.05969 pca_loss= 14724.58691 accuracy= 0.58221 time= 0.02632
Epoch: 0101 train_loss= 18092.53125 reconstruction_loss= 2092.71631 proj_loss= 1789.34619 pca_loss= 14210.46875 accuracy= 0.58221 time= 0.02592
Epoch: 0111 train_loss= 17244.76953 reconstruction_loss= 1834.94006 proj_loss= 1689.18665 pca_loss= 13720.64258 accuracy= 0.58161 time= 0.02692
Epoch: 0121 train_loss= 16377.49414 reconstruction_loss= 1528.87939 proj_loss= 1595.06055 pca_loss= 13253.55469 accuracy= 0.58100 time= 0.02681
Epoch: 0131 train_loss= 15677.22559 reconstruction_loss= 1363.20471 proj_loss= 1506.61658 pca_loss= 12807.40430 accuracy= 0.58461 time= 0.02630
Epoch: 0141 train_loss= 15054.94629 reconstruction_loss= 1250.65845 proj_loss= 1423.58057 pca_loss= 12380.70703 accuracy= 0.58461 time= 0.02570
Epoch: 0151 train_loss= 14462.27441 reconstruction_loss= 1144.29761 proj_loss= 1345.58606 pca_loss= 11972.39062 accuracy= 0.58882 time= 0.02569
Epoch: 0161 train_loss= 13882.28516 reconstruction_loss= 1028.42529 proj_loss= 1272.27466 pca_loss= 11581.58496 accuracy= 0.59543 time= 0.02587
Epoch: 0171 train_loss= 13323.41797 reconstruction_loss= 912.72168 proj_loss= 1203.34326 pca_loss= 11207.35352 accuracy= 0.59303 time= 0.02618
Epoch: 0181 train_loss= 12790.95117 reconstruction_loss= 803.71161 proj_loss= 1138.49792 pca_loss= 10848.74219 accuracy= 0.58762 time= 0.02606
Epoch: 0191 train_loss= 12266.59766 reconstruction_loss= 684.26782 proj_loss= 1077.47327 pca_loss= 10504.85645 accuracy= 0.58942 time= 0.02603
Epoch: 0201 train_loss= 11764.63672 reconstruction_loss= 569.65253 proj_loss= 1020.02100 pca_loss= 10174.96289 accuracy= 0.58461 time= 0.02618
Epoch: 0211 train_loss= 11267.32520 reconstruction_loss= 443.10721 proj_loss= 965.91583 pca_loss= 9858.30176 accuracy= 0.58882 time= 0.02629
Epoch: 0221 train_loss= 10797.99121 reconstruction_loss= 328.98346 proj_loss= 914.95679 pca_loss= 9554.05078 accuracy= 0.58702 time= 0.02627
Epoch: 0231 train_loss= 10353.56641 reconstruction_loss= 225.11975 proj_loss= 866.95789 pca_loss= 9261.48828 accuracy= 0.58581 time= 0.02660
Epoch: 0241 train_loss= 9949.76562 reconstruction_loss= 148.19780 proj_loss= 821.71735 pca_loss= 8979.85059 accuracy= 0.58521 time= 0.02627
Epoch: 0251 train_loss= 9580.36133 reconstruction_loss= 93.15467 proj_loss= 779.01971 pca_loss= 8708.18652 accuracy= 0.58762 time= 0.02568
Epoch: 0261 train_loss= 9242.03320 reconstruction_loss= 57.25308 proj_loss= 738.71112 pca_loss= 8446.06934 accuracy= 0.58581 time= 0.02569
Epoch: 0271 train_loss= 8929.22949 reconstruction_loss= 35.39552 proj_loss= 700.64746 pca_loss= 8193.18652 accuracy= 0.58702 time= 0.02579
Epoch: 0281 train_loss= 8638.46680 reconstruction_loss= 24.48932 proj_loss= 664.69781 pca_loss= 7949.27979 accuracy= 0.58822 time= 0.02600
Epoch: 0291 train_loss= 8362.44336 reconstruction_loss= 17.65979 proj_loss= 630.73022 pca_loss= 7714.05371 accuracy= 0.58641 time= 0.02628

accuracy 0.58581
auc 0.25674
f1_score 0.13875
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.1, weight_decay=0.0005)
random seed: 235
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 370 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6346128.50000 reconstruction_loss= 9876.12988 proj_loss= 6316171.50000 pca_loss= 20080.75195 accuracy= 0.64472 time= 0.11233
Epoch: 0011 train_loss= 5948876.00000 reconstruction_loss= 5981.43555 proj_loss= 5924076.50000 pca_loss= 18818.08398 accuracy= 0.58702 time= 0.09767
Epoch: 0021 train_loss= 5580356.00000 reconstruction_loss= 5173.31641 proj_loss= 5557451.00000 pca_loss= 17731.56055 accuracy= 0.58221 time= 0.09700
Epoch: 0031 train_loss= 5238487.00000 reconstruction_loss= 4663.07715 proj_loss= 5217008.00000 pca_loss= 16816.00195 accuracy= 0.58641 time= 0.09201
Epoch: 0041 train_loss= 4922475.00000 reconstruction_loss= 4290.86621 proj_loss= 4902142.50000 pca_loss= 16041.56543 accuracy= 0.58521 time= 0.09739
Epoch: 0051 train_loss= 4630751.50000 reconstruction_loss= 3995.12891 proj_loss= 4611386.00000 pca_loss= 15370.25781 accuracy= 0.58401 time= 0.09186
Epoch: 0061 train_loss= 4361391.00000 reconstruction_loss= 3742.64575 proj_loss= 4342875.00000 pca_loss= 14773.31641 accuracy= 0.58281 time= 0.10110
Epoch: 0071 train_loss= 4112431.75000 reconstruction_loss= 3523.36377 proj_loss= 4094676.75000 pca_loss= 14231.68555 accuracy= 0.58100 time= 0.09028
Epoch: 0081 train_loss= 3882011.75000 reconstruction_loss= 3329.59644 proj_loss= 3864949.00000 pca_loss= 13733.31348 accuracy= 0.58341 time= 0.09029
Epoch: 0091 train_loss= 3668427.50000 reconstruction_loss= 3149.25195 proj_loss= 3652007.75000 pca_loss= 13270.43750 accuracy= 0.58161 time= 0.09028
Epoch: 0101 train_loss= 3470165.50000 reconstruction_loss= 2991.06860 proj_loss= 3454336.25000 pca_loss= 12838.16797 accuracy= 0.58221 time= 0.09022
Epoch: 0111 train_loss= 3285850.25000 reconstruction_loss= 2842.12891 proj_loss= 3270576.00000 pca_loss= 12432.06250 accuracy= 0.58100 time= 0.10080
Epoch: 0121 train_loss= 3114250.50000 reconstruction_loss= 2686.35718 proj_loss= 3099515.25000 pca_loss= 12048.95020 accuracy= 0.58221 time= 0.10029
Epoch: 0131 train_loss= 2954306.25000 reconstruction_loss= 2552.93994 proj_loss= 2940066.75000 pca_loss= 11686.52930 accuracy= 0.57980 time= 0.09790
Epoch: 0141 train_loss= 2805021.75000 reconstruction_loss= 2421.49121 proj_loss= 2791257.50000 pca_loss= 11342.67969 accuracy= 0.58161 time= 0.10022
Epoch: 0151 train_loss= 2665512.50000 reconstruction_loss= 2287.67163 proj_loss= 2652209.25000 pca_loss= 11015.50684 accuracy= 0.58221 time= 0.09713
Epoch: 0161 train_loss= 2534995.50000 reconstruction_loss= 2157.43091 proj_loss= 2522134.25000 pca_loss= 10703.77539 accuracy= 0.58221 time= 0.08958
Epoch: 0171 train_loss= 2412757.25000 reconstruction_loss= 2033.52332 proj_loss= 2400317.75000 pca_loss= 10406.11816 accuracy= 0.58461 time= 0.08851
Epoch: 0181 train_loss= 2298153.50000 reconstruction_loss= 1917.05298 proj_loss= 2286114.75000 pca_loss= 10121.75293 accuracy= 0.58521 time= 0.09068
Epoch: 0191 train_loss= 2190595.50000 reconstruction_loss= 1806.16943 proj_loss= 2178939.50000 pca_loss= 9849.67383 accuracy= 0.58461 time= 0.09002
Epoch: 0201 train_loss= 2089550.62500 reconstruction_loss= 1701.37036 proj_loss= 2078260.37500 pca_loss= 9588.86328 accuracy= 0.58281 time= 0.08963
Epoch: 0211 train_loss= 1994532.12500 reconstruction_loss= 1599.64563 proj_loss= 1983593.62500 pca_loss= 9338.85645 accuracy= 0.58281 time= 0.08984
Epoch: 0221 train_loss= 1905103.62500 reconstruction_loss= 1506.97021 proj_loss= 1894497.75000 pca_loss= 9098.83984 accuracy= 0.58581 time= 0.08975
Epoch: 0231 train_loss= 1820857.62500 reconstruction_loss= 1419.30164 proj_loss= 1810570.12500 pca_loss= 8868.24902 accuracy= 0.58161 time= 0.09005
Epoch: 0241 train_loss= 1741426.75000 reconstruction_loss= 1337.51343 proj_loss= 1731442.75000 pca_loss= 8646.54785 accuracy= 0.58401 time= 0.09039
Epoch: 0251 train_loss= 1666475.37500 reconstruction_loss= 1263.67529 proj_loss= 1656778.62500 pca_loss= 8433.12207 accuracy= 0.58221 time= 0.09004
Epoch: 0261 train_loss= 1595689.62500 reconstruction_loss= 1193.63367 proj_loss= 1586268.25000 pca_loss= 8227.71191 accuracy= 0.58281 time= 0.09013
Epoch: 0271 train_loss= 1528784.62500 reconstruction_loss= 1126.05786 proj_loss= 1519628.87500 pca_loss= 8029.71143 accuracy= 0.58221 time= 0.09040
Epoch: 0281 train_loss= 1465504.25000 reconstruction_loss= 1066.20471 proj_loss= 1456599.12500 pca_loss= 7838.86279 accuracy= 0.58100 time= 0.09193
Epoch: 0291 train_loss= 1405604.37500 reconstruction_loss= 1010.68530 proj_loss= 1396939.12500 pca_loss= 7654.62061 accuracy= 0.57980 time= 0.08999

accuracy 0.57980
auc 0.28991
f1_score 0.12625
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 67
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 20678.30664 reconstruction_loss= 59.53041 proj_loss= 12409.88770 pca_loss= 8208.88867 accuracy= 0.62248 time= 0.07734
Epoch: 0011 train_loss= 19578.30859 reconstruction_loss= 34.26347 proj_loss= 11623.67285 pca_loss= 7920.37305 accuracy= 0.63270 time= 0.04439
Epoch: 0021 train_loss= 18559.12500 reconstruction_loss= 25.30861 proj_loss= 10890.49609 pca_loss= 7643.32031 accuracy= 0.62609 time= 0.04968
Epoch: 0031 train_loss= 17606.44922 reconstruction_loss= 16.81849 proj_loss= 10210.76270 pca_loss= 7378.86768 accuracy= 0.65915 time= 0.04136
Epoch: 0041 train_loss= 16719.74609 reconstruction_loss= 10.00628 proj_loss= 9582.50781 pca_loss= 7127.23193 accuracy= 0.67478 time= 0.04139
Epoch: 0051 train_loss= 15898.89941 reconstruction_loss= 8.53162 proj_loss= 9002.41797 pca_loss= 6887.95020 accuracy= 0.72227 time= 0.05439
Epoch: 0061 train_loss= 15135.16016 reconstruction_loss= 8.25261 proj_loss= 8466.52930 pca_loss= 6660.37744 accuracy= 0.73009 time= 0.05251
Epoch: 0071 train_loss= 14422.54297 reconstruction_loss= 7.89968 proj_loss= 7970.91553 pca_loss= 6443.72705 accuracy= 0.72347 time= 0.04386
Epoch: 0081 train_loss= 13756.98242 reconstruction_loss= 7.85383 proj_loss= 7511.88037 pca_loss= 6237.24756 accuracy= 0.71326 time= 0.05048
Epoch: 0091 train_loss= 13134.02539 reconstruction_loss= 7.70806 proj_loss= 7086.05566 pca_loss= 6040.26221 accuracy= 0.73129 time= 0.05131
Epoch: 0101 train_loss= 12550.22461 reconstruction_loss= 7.64297 proj_loss= 6690.45020 pca_loss= 5852.13135 accuracy= 0.72047 time= 0.07309
Epoch: 0111 train_loss= 12002.87988 reconstruction_loss= 8.20323 proj_loss= 6322.39307 pca_loss= 5672.28369 accuracy= 0.69823 time= 0.05331
Epoch: 0121 train_loss= 11487.52344 reconstruction_loss= 7.82447 proj_loss= 5979.50049 pca_loss= 5500.19824 accuracy= 0.71746 time= 0.03963
Epoch: 0131 train_loss= 11002.64453 reconstruction_loss= 7.60142 proj_loss= 5659.64893 pca_loss= 5335.39453 accuracy= 0.72528 time= 0.04779
Epoch: 0141 train_loss= 10546.40625 reconstruction_loss= 8.03672 proj_loss= 5360.93066 pca_loss= 5177.43945 accuracy= 0.72828 time= 0.05469
Epoch: 0151 train_loss= 10115.36328 reconstruction_loss= 7.79951 proj_loss= 5081.63037 pca_loss= 5025.93311 accuracy= 0.73369 time= 0.05780
Epoch: 0161 train_loss= 9708.28125 reconstruction_loss= 7.56683 proj_loss= 4820.20312 pca_loss= 4880.51074 accuracy= 0.73009 time= 0.05271
Epoch: 0171 train_loss= 9323.71094 reconstruction_loss= 7.62498 proj_loss= 4575.25488 pca_loss= 4740.83057 accuracy= 0.70604 time= 0.04043
Epoch: 0181 train_loss= 8959.43750 reconstruction_loss= 7.33615 proj_loss= 4345.52002 pca_loss= 4606.58203 accuracy= 0.69883 time= 0.05876
Epoch: 0191 train_loss= 8614.49023 reconstruction_loss= 7.16468 proj_loss= 4129.84961 pca_loss= 4477.47656 accuracy= 0.66997 time= 0.04851
Epoch: 0201 train_loss= 8287.22168 reconstruction_loss= 6.77668 proj_loss= 3927.19995 pca_loss= 4353.24512 accuracy= 0.68139 time= 0.07853
Epoch: 0211 train_loss= 7976.50000 reconstruction_loss= 6.23956 proj_loss= 3736.61328 pca_loss= 4233.64697 accuracy= 0.66637 time= 0.03993
Epoch: 0221 train_loss= 7681.27148 reconstruction_loss= 5.60306 proj_loss= 3557.22656 pca_loss= 4118.44189 accuracy= 0.68440 time= 0.04825
Epoch: 0231 train_loss= 7401.20312 reconstruction_loss= 5.54283 proj_loss= 3388.25806 pca_loss= 4007.40259 accuracy= 0.68440 time= 0.05620
Epoch: 0241 train_loss= 7134.82520 reconstruction_loss= 5.52282 proj_loss= 3228.98047 pca_loss= 3900.32178 accuracy= 0.68500 time= 0.05321
Epoch: 0251 train_loss= 6881.25195 reconstruction_loss= 5.51368 proj_loss= 3078.71387 pca_loss= 3797.02441 accuracy= 0.68500 time= 0.03977
Epoch: 0261 train_loss= 6639.69727 reconstruction_loss= 5.51730 proj_loss= 2936.85522 pca_loss= 3697.32446 accuracy= 0.68440 time= 0.05462
Epoch: 0271 train_loss= 6409.41309 reconstruction_loss= 5.51735 proj_loss= 2802.83203 pca_loss= 3601.06396 accuracy= 0.68440 time= 0.05294
Epoch: 0281 train_loss= 6189.72559 reconstruction_loss= 5.51296 proj_loss= 2676.13232 pca_loss= 3508.08057 accuracy= 0.68440 time= 0.04542
Epoch: 0291 train_loss= 5980.01562 reconstruction_loss= 5.51328 proj_loss= 2556.27905 pca_loss= 3418.22363 accuracy= 0.68440 time= 0.04586

accuracy 0.68440
auc 0.60812
f1_score 0.34375
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 738
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 31443604.00000 reconstruction_loss= 57.46510 proj_loss= 31434356.00000 pca_loss= 9190.42676 accuracy= 0.58581 time= 0.08403
Epoch: 0011 train_loss= 29496192.00000 reconstruction_loss= 28.98082 proj_loss= 29487288.00000 pca_loss= 8875.14844 accuracy= 0.61286 time= 0.06622
Epoch: 0021 train_loss= 27674924.00000 reconstruction_loss= 17.36524 proj_loss= 27666336.00000 pca_loss= 8570.19434 accuracy= 0.62609 time= 0.07331
Epoch: 0031 train_loss= 25983446.00000 reconstruction_loss= 10.90289 proj_loss= 25975158.00000 pca_loss= 8277.19629 accuracy= 0.68801 time= 0.06579
Epoch: 0041 train_loss= 24418754.00000 reconstruction_loss= 8.97267 proj_loss= 24410748.00000 pca_loss= 7997.04590 accuracy= 0.71265 time= 0.07092
Epoch: 0051 train_loss= 22973552.00000 reconstruction_loss= 8.11069 proj_loss= 22965814.00000 pca_loss= 7729.64307 accuracy= 0.72588 time= 0.06962
Epoch: 0061 train_loss= 21638604.00000 reconstruction_loss= 7.81493 proj_loss= 21631122.00000 pca_loss= 7474.65137 accuracy= 0.73249 time= 0.06577
Epoch: 0071 train_loss= 20404358.00000 reconstruction_loss= 7.55696 proj_loss= 20397118.00000 pca_loss= 7231.60059 accuracy= 0.73610 time= 0.06563
Epoch: 0081 train_loss= 19261704.00000 reconstruction_loss= 6.95596 proj_loss= 19254698.00000 pca_loss= 6999.81738 accuracy= 0.73369 time= 0.07143
Epoch: 0091 train_loss= 18202326.00000 reconstruction_loss= 6.75166 proj_loss= 18195542.00000 pca_loss= 6778.69141 accuracy= 0.72588 time= 0.07176
Epoch: 0101 train_loss= 17218730.00000 reconstruction_loss= 6.82820 proj_loss= 17212156.00000 pca_loss= 6567.66602 accuracy= 0.72167 time= 0.07813
Epoch: 0111 train_loss= 16304204.00000 reconstruction_loss= 6.68969 proj_loss= 16297831.00000 pca_loss= 6366.19385 accuracy= 0.71927 time= 0.07791
Epoch: 0121 train_loss= 15452741.00000 reconstruction_loss= 6.62054 proj_loss= 15446560.00000 pca_loss= 6173.72607 accuracy= 0.72347 time= 0.06600
Epoch: 0131 train_loss= 14658969.00000 reconstruction_loss= 6.61159 proj_loss= 14652972.00000 pca_loss= 5989.74756 accuracy= 0.72167 time= 0.06558
Epoch: 0141 train_loss= 13918061.00000 reconstruction_loss= 6.68848 proj_loss= 13912240.00000 pca_loss= 5813.78467 accuracy= 0.72287 time= 0.07001
Epoch: 0151 train_loss= 13225674.00000 reconstruction_loss= 6.90304 proj_loss= 13220022.00000 pca_loss= 5645.39600 accuracy= 0.72708 time= 0.06936
Epoch: 0161 train_loss= 12577891.00000 reconstruction_loss= 6.94076 proj_loss= 12572400.00000 pca_loss= 5484.17334 accuracy= 0.72287 time= 0.06946
Epoch: 0171 train_loss= 11971176.00000 reconstruction_loss= 6.79231 proj_loss= 11965839.00000 pca_loss= 5329.73975 accuracy= 0.72408 time= 0.06562
Epoch: 0181 train_loss= 11402327.00000 reconstruction_loss= 6.67514 proj_loss= 11397138.00000 pca_loss= 5181.73877 accuracy= 0.72047 time= 0.07591
Epoch: 0191 train_loss= 10868437.00000 reconstruction_loss= 6.93179 proj_loss= 10863390.00000 pca_loss= 5039.83936 accuracy= 0.71626 time= 0.07173
Epoch: 0201 train_loss= 10366865.00000 reconstruction_loss= 6.67166 proj_loss= 10361954.00000 pca_loss= 4903.73096 accuracy= 0.71566 time= 0.06519
Epoch: 0211 train_loss= 9895208.00000 reconstruction_loss= 6.70615 proj_loss= 9890428.00000 pca_loss= 4773.12256 accuracy= 0.71085 time= 0.07051
Epoch: 0221 train_loss= 9451276.00000 reconstruction_loss= 6.69263 proj_loss= 9446621.00000 pca_loss= 4647.73975 accuracy= 0.73009 time= 0.06947
Epoch: 0231 train_loss= 9033067.00000 reconstruction_loss= 6.76010 proj_loss= 9028533.00000 pca_loss= 4527.32568 accuracy= 0.70604 time= 0.07761
Epoch: 0241 train_loss= 8638753.00000 reconstruction_loss= 7.01229 proj_loss= 8634334.00000 pca_loss= 4411.63721 accuracy= 0.71867 time= 0.07620
Epoch: 0251 train_loss= 8266657.00000 reconstruction_loss= 6.92287 proj_loss= 8262349.50000 pca_loss= 4300.44629 accuracy= 0.70364 time= 0.07722
Epoch: 0261 train_loss= 7915243.50000 reconstruction_loss= 6.93174 proj_loss= 7911043.00000 pca_loss= 4193.53613 accuracy= 0.70123 time= 0.07171
Epoch: 0271 train_loss= 7583102.50000 reconstruction_loss= 6.82953 proj_loss= 7579005.00000 pca_loss= 4090.70288 accuracy= 0.70424 time= 0.07419
Epoch: 0281 train_loss= 7268939.50000 reconstruction_loss= 7.36958 proj_loss= 7264940.00000 pca_loss= 3991.75366 accuracy= 0.72888 time= 0.06912
Epoch: 0291 train_loss= 6971557.00000 reconstruction_loss= 7.77870 proj_loss= 6967652.50000 pca_loss= 3896.50562 accuracy= 0.72648 time= 0.06904

accuracy 0.73610
auc 0.72318
f1_score 0.45125
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 430
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([3327, 925]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 32551.67578 reconstruction_loss= 11839.20410 proj_loss= 12430.51367 pca_loss= 8281.95801 accuracy= 0.75714 time= 0.04026
Epoch: 0011 train_loss= 28724.64844 reconstruction_loss= 9065.19629 proj_loss= 11664.88770 pca_loss= 7994.56348 accuracy= 0.58702 time= 0.02948
Epoch: 0021 train_loss= 26964.35547 reconstruction_loss= 8302.48242 proj_loss= 10939.06738 pca_loss= 7722.80566 accuracy= 0.58641 time= 0.03097
Epoch: 0031 train_loss= 25409.44727 reconstruction_loss= 7683.43848 proj_loss= 10262.15625 pca_loss= 7463.85303 accuracy= 0.58341 time= 0.02953
Epoch: 0041 train_loss= 23990.62500 reconstruction_loss= 7139.16455 proj_loss= 9634.97168 pca_loss= 7216.48926 accuracy= 0.58341 time= 0.02782
Epoch: 0051 train_loss= 22659.55078 reconstruction_loss= 6623.32178 proj_loss= 9055.60840 pca_loss= 6980.62207 accuracy= 0.58401 time= 0.02691
Epoch: 0061 train_loss= 21344.04883 reconstruction_loss= 6065.93701 proj_loss= 8521.41699 pca_loss= 6756.69482 accuracy= 0.58221 time= 0.02527
Epoch: 0071 train_loss= 19951.07031 reconstruction_loss= 5375.04541 proj_loss= 8030.20361 pca_loss= 6545.82080 accuracy= 0.58161 time= 0.02820
Epoch: 0081 train_loss= 18334.41406 reconstruction_loss= 4405.01709 proj_loss= 7579.86865 pca_loss= 6349.52930 accuracy= 0.58641 time= 0.02383
Epoch: 0091 train_loss= 16424.92773 reconstruction_loss= 3093.55884 proj_loss= 7164.65186 pca_loss= 6166.71680 accuracy= 0.58161 time= 0.02395
Epoch: 0101 train_loss= 14257.82324 reconstruction_loss= 1491.88013 proj_loss= 6773.84521 pca_loss= 5992.09766 accuracy= 0.58461 time= 0.02407
Epoch: 0111 train_loss= 12670.46484 reconstruction_loss= 447.85236 proj_loss= 6401.84521 pca_loss= 5820.76709 accuracy= 0.57980 time= 0.02413
Epoch: 0121 train_loss= 11772.64453 reconstruction_loss= 72.69151 proj_loss= 6050.49902 pca_loss= 5649.45410 accuracy= 0.59182 time= 0.02345
Epoch: 0131 train_loss= 11209.60742 reconstruction_loss= 7.20765 proj_loss= 5722.01318 pca_loss= 5480.38623 accuracy= 0.57920 time= 0.02427
Epoch: 0141 train_loss= 10735.23438 reconstruction_loss= 2.77671 proj_loss= 5416.14844 pca_loss= 5316.30957 accuracy= 0.58702 time= 0.02420
Epoch: 0151 train_loss= 10290.58789 reconstruction_loss= 0.64102 proj_loss= 5131.30420 pca_loss= 5158.64258 accuracy= 0.58641 time= 0.02426
Epoch: 0161 train_loss= 9873.69141 reconstruction_loss= 0.53914 proj_loss= 4865.54395 pca_loss= 5007.60840 accuracy= 0.58762 time= 0.02546
Epoch: 0171 train_loss= 9480.59473 reconstruction_loss= 0.52167 proj_loss= 4617.12793 pca_loss= 4862.94531 accuracy= 0.58822 time= 0.02503
Epoch: 0181 train_loss= 9109.34277 reconstruction_loss= 0.53796 proj_loss= 4384.54248 pca_loss= 4724.26221 accuracy= 0.58581 time= 0.02500
Epoch: 0191 train_loss= 8758.15430 reconstruction_loss= 0.51304 proj_loss= 4166.47070 pca_loss= 4591.17041 accuracy= 0.58521 time= 0.02507
Epoch: 0201 train_loss= 8425.59082 reconstruction_loss= 0.52983 proj_loss= 3961.75537 pca_loss= 4463.30566 accuracy= 0.58702 time= 0.02482
Epoch: 0211 train_loss= 8110.27393 reconstruction_loss= 0.55977 proj_loss= 3769.36108 pca_loss= 4340.35303 accuracy= 0.58461 time= 0.02485
Epoch: 0221 train_loss= 7810.99902 reconstruction_loss= 0.61427 proj_loss= 3588.35767 pca_loss= 4222.02734 accuracy= 0.58702 time= 0.02529
Epoch: 0231 train_loss= 7526.79102 reconstruction_loss= 0.80027 proj_loss= 3417.91113 pca_loss= 4108.07959 accuracy= 0.58882 time= 0.02519
Epoch: 0241 train_loss= 7256.13086 reconstruction_loss= 0.59249 proj_loss= 3257.27759 pca_loss= 3998.26099 accuracy= 0.58581 time= 0.02566
Epoch: 0251 train_loss= 6998.71729 reconstruction_loss= 0.58761 proj_loss= 3105.76099 pca_loss= 3892.36865 accuracy= 0.58702 time= 0.02365
Epoch: 0261 train_loss= 6753.48633 reconstruction_loss= 0.57597 proj_loss= 2962.72876 pca_loss= 3790.18164 accuracy= 0.58581 time= 0.02405
Epoch: 0271 train_loss= 6519.71729 reconstruction_loss= 0.55209 proj_loss= 2827.61377 pca_loss= 3691.55151 accuracy= 0.58822 time= 0.02388
Epoch: 0281 train_loss= 6297.06055 reconstruction_loss= 0.83036 proj_loss= 2699.89868 pca_loss= 3596.33179 accuracy= 0.58641 time= 0.02576
Epoch: 0291 train_loss= 6083.93555 reconstruction_loss= 0.53077 proj_loss= 2579.08691 pca_loss= 3504.31787 accuracy= 0.58762 time= 0.02726

accuracy 0.58461
auc 0.25604
f1_score 0.13625
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=20, cuda=False, dataset='citeseer', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=20, rsr_dim=0.02, weight_decay=0.0005)
random seed: 48
Found existing ad data, loading...
feature_dim: 3703 hidden1_dim: 1851 hidden2_dim: 925 rsr_dim: 74 nodes_num: 3327 anomaly_num: 800

Start modeling
using wavelet scattering transform
y_features shape after scatting (3327, 48139) <class 'numpy.ndarray'>
48139
y_features shape after NoReduction torch.Size([3327, 48139]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 31428194.00000 reconstruction_loss= 12447.63086 proj_loss= 31406738.00000 pca_loss= 9007.40723 accuracy= 0.58702 time= 0.06516
Epoch: 0011 train_loss= 29478946.00000 reconstruction_loss= 9786.25684 proj_loss= 29460468.00000 pca_loss= 8691.85059 accuracy= 0.58882 time= 0.05103
Epoch: 0021 train_loss= 27657686.00000 reconstruction_loss= 8979.53223 proj_loss= 27640318.00000 pca_loss= 8387.82617 accuracy= 0.59122 time= 0.05138
Epoch: 0031 train_loss= 25966410.00000 reconstruction_loss= 8389.23633 proj_loss= 25949924.00000 pca_loss= 8095.48682 accuracy= 0.59002 time= 0.05110
Epoch: 0041 train_loss= 24401998.00000 reconstruction_loss= 7901.49414 proj_loss= 24386280.00000 pca_loss= 7816.79834 accuracy= 0.59062 time= 0.05955
Epoch: 0051 train_loss= 22957098.00000 reconstruction_loss= 7455.65967 proj_loss= 22942090.00000 pca_loss= 7552.08887 accuracy= 0.59122 time= 0.05213
Epoch: 0061 train_loss= 21622462.00000 reconstruction_loss= 7041.34424 proj_loss= 21608120.00000 pca_loss= 7300.37646 accuracy= 0.59122 time= 0.05113
Epoch: 0071 train_loss= 20388504.00000 reconstruction_loss= 6633.89453 proj_loss= 20374810.00000 pca_loss= 7060.82324 accuracy= 0.59062 time= 0.05087
Epoch: 0081 train_loss= 19246054.00000 reconstruction_loss= 6159.07324 proj_loss= 19233062.00000 pca_loss= 6832.59521 accuracy= 0.59122 time= 0.05095
Epoch: 0091 train_loss= 18186746.00000 reconstruction_loss= 5578.13672 proj_loss= 18174554.00000 pca_loss= 6614.91211 accuracy= 0.59182 time= 0.05147
Epoch: 0101 train_loss= 17203000.00000 reconstruction_loss= 4799.67627 proj_loss= 17191792.00000 pca_loss= 6407.22803 accuracy= 0.59182 time= 0.05108
Epoch: 0111 train_loss= 16288221.00000 reconstruction_loss= 3943.39722 proj_loss= 16278069.00000 pca_loss= 6209.30322 accuracy= 0.59303 time= 0.05013
Epoch: 0121 train_loss= 15436401.00000 reconstruction_loss= 2999.15454 proj_loss= 15427381.00000 pca_loss= 6020.89258 accuracy= 0.59483 time= 0.05107
Epoch: 0131 train_loss= 14642291.00000 reconstruction_loss= 2097.35913 proj_loss= 14634353.00000 pca_loss= 5841.44482 accuracy= 0.59122 time= 0.05352
Epoch: 0141 train_loss= 13901306.00000 reconstruction_loss= 1471.12817 proj_loss= 13894165.00000 pca_loss= 5669.81934 accuracy= 0.58882 time= 0.05403
Epoch: 0151 train_loss= 13209022.00000 reconstruction_loss= 1044.72571 proj_loss= 13202471.00000 pca_loss= 5505.56299 accuracy= 0.58942 time= 0.05055
Epoch: 0161 train_loss= 12561459.00000 reconstruction_loss= 754.56616 proj_loss= 12555356.00000 pca_loss= 5348.44678 accuracy= 0.59062 time= 0.05507
Epoch: 0171 train_loss= 11955043.00000 reconstruction_loss= 556.24731 proj_loss= 11949289.00000 pca_loss= 5198.13525 accuracy= 0.59062 time= 0.05740
Epoch: 0181 train_loss= 11386546.00000 reconstruction_loss= 426.98468 proj_loss= 11381065.00000 pca_loss= 5054.25195 accuracy= 0.59182 time= 0.05587
Epoch: 0191 train_loss= 10853037.00000 reconstruction_loss= 341.71631 proj_loss= 10847778.00000 pca_loss= 4916.52930 accuracy= 0.59062 time= 0.06231
Epoch: 0201 train_loss= 10351855.00000 reconstruction_loss= 280.51147 proj_loss= 10346789.00000 pca_loss= 4784.56104 accuracy= 0.59002 time= 0.06263
Epoch: 0211 train_loss= 9880590.00000 reconstruction_loss= 236.52739 proj_loss= 9875695.00000 pca_loss= 4658.06396 accuracy= 0.58882 time= 0.06374
Epoch: 0221 train_loss= 9437049.00000 reconstruction_loss= 204.56929 proj_loss= 9432307.00000 pca_loss= 4536.79395 accuracy= 0.59002 time= 0.05678
Epoch: 0231 train_loss= 9019224.00000 reconstruction_loss= 178.75308 proj_loss= 9014625.00000 pca_loss= 4420.44189 accuracy= 0.59303 time= 0.05256
Epoch: 0241 train_loss= 8625286.00000 reconstruction_loss= 158.65224 proj_loss= 8620818.00000 pca_loss= 4308.77051 accuracy= 0.59423 time= 0.05248
Epoch: 0251 train_loss= 8253556.00000 reconstruction_loss= 141.97038 proj_loss= 8249212.50000 pca_loss= 4201.54053 accuracy= 0.59182 time= 0.05225
Epoch: 0261 train_loss= 7902501.00000 reconstruction_loss= 128.71608 proj_loss= 7898274.00000 pca_loss= 4098.52051 accuracy= 0.58822 time= 0.05264
Epoch: 0271 train_loss= 7570707.50000 reconstruction_loss= 116.71268 proj_loss= 7566591.50000 pca_loss= 3999.49927 accuracy= 0.58822 time= 0.05262
Epoch: 0281 train_loss= 7256880.00000 reconstruction_loss= 106.28231 proj_loss= 7252869.00000 pca_loss= 3904.28198 accuracy= 0.58581 time= 0.05257
Epoch: 0291 train_loss= 6959823.50000 reconstruction_loss= 96.05611 proj_loss= 6955915.00000 pca_loss= 3812.67114 accuracy= 0.58641 time= 0.05274

accuracy 0.58641
auc 0.27589
f1_score 0.14000
Job finished!
citeseer job finished!
start amz computer



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 432
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 8304.24512 feature_loss= 24.76503 structure_loss= 6254.26025 proj_loss= 665.89716 pca_loss= 1359.32275 accuracy= 0.62362 accuracy_s= 0.78679 accuracy_f= 0.81574 time= 0.24719
Epoch: 0011 train_loss= 2552.15771 feature_loss= 16.68385 structure_loss= 1209.07898 proj_loss= 657.63605 pca_loss= 668.75873 accuracy= 0.62507 accuracy_s= 0.78374 accuracy_f= 0.82723 time= 0.21993
Epoch: 0021 train_loss= 1955.23816 feature_loss= 15.61346 structure_loss= 760.86829 proj_loss= 646.74103 pca_loss= 532.01538 accuracy= 0.62449 accuracy_s= 0.78214 accuracy_f= 0.82941 time= 0.22158
Epoch: 0031 train_loss= 1614.51624 feature_loss= 15.01204 structure_loss= 534.99860 proj_loss= 633.65338 pca_loss= 430.85217 accuracy= 0.61795 accuracy_s= 0.78214 accuracy_f= 0.83159 time= 0.30042
Epoch: 0041 train_loss= 1415.89331 feature_loss= 14.54636 structure_loss= 433.81506 proj_loss= 619.74359 pca_loss= 347.78836 accuracy= 0.63976 accuracy_s= 0.78403 accuracy_f= 0.83275 time= 0.27627
Epoch: 0051 train_loss= 1299.27039 feature_loss= 14.22136 structure_loss= 397.46417 proj_loss= 605.25891 pca_loss= 282.32593 accuracy= 0.65067 accuracy_s= 0.78549 accuracy_f= 0.83464 time= 0.30247
Epoch: 0061 train_loss= 1209.17090 feature_loss= 13.97998 structure_loss= 375.72025 proj_loss= 590.48468 pca_loss= 228.98598 accuracy= 0.66085 accuracy_s= 0.78301 accuracy_f= 0.83639 time= 0.28070
Epoch: 0071 train_loss= 1133.39746 feature_loss= 13.77546 structure_loss= 356.99628 proj_loss= 575.70013 pca_loss= 186.92564 accuracy= 0.66303 accuracy_s= 0.78316 accuracy_f= 0.83784 time= 0.26451
Epoch: 0081 train_loss= 1076.35803 feature_loss= 13.58821 structure_loss= 347.74533 proj_loss= 560.99939 pca_loss= 154.02519 accuracy= 0.66725 accuracy_s= 0.80017 accuracy_f= 0.83842 time= 0.25781
Epoch: 0091 train_loss= 1029.50684 feature_loss= 13.43386 structure_loss= 341.31406 proj_loss= 546.44128 pca_loss= 128.31758 accuracy= 0.66725 accuracy_s= 0.79567 accuracy_f= 0.83842 time= 0.21175
Epoch: 0101 train_loss= 988.65588 feature_loss= 13.28924 structure_loss= 336.31274 proj_loss= 532.06982 pca_loss= 106.98406 accuracy= 0.66754 accuracy_s= 0.79058 accuracy_f= 0.83813 time= 0.26957
Epoch: 0111 train_loss= 947.38068 feature_loss= 13.16754 structure_loss= 326.78235 proj_loss= 517.91675 pca_loss= 89.51405 accuracy= 0.66827 accuracy_s= 0.79407 accuracy_f= 0.83871 time= 0.21760
Epoch: 0121 train_loss= 911.80200 feature_loss= 13.05584 structure_loss= 319.67102 proj_loss= 504.02747 pca_loss= 75.04768 accuracy= 0.66943 accuracy_s= 0.79552 accuracy_f= 0.83886 time= 0.21187
Epoch: 0131 train_loss= 878.86462 feature_loss= 12.95721 structure_loss= 312.42276 proj_loss= 490.38980 pca_loss= 63.09488 accuracy= 0.67205 accuracy_s= 0.79959 accuracy_f= 0.83959 time= 0.20975
Epoch: 0141 train_loss= 857.19202 feature_loss= 12.86210 structure_loss= 314.32645 proj_loss= 477.03140 pca_loss= 52.97204 accuracy= 0.67321 accuracy_s= 0.80047 accuracy_f= 0.84075 time= 0.20993
Epoch: 0151 train_loss= 829.96997 feature_loss= 12.78143 structure_loss= 306.88953 proj_loss= 464.01956 pca_loss= 46.27942 accuracy= 0.67496 accuracy_s= 0.80221 accuracy_f= 0.84162 time= 0.20969
Epoch: 0161 train_loss= 799.38654 feature_loss= 12.69180 structure_loss= 294.12991 proj_loss= 451.33771 pca_loss= 41.22710 accuracy= 0.67641 accuracy_s= 0.80352 accuracy_f= 0.84119 time= 0.20958
Epoch: 0171 train_loss= 776.82660 feature_loss= 12.73403 structure_loss= 286.44620 proj_loss= 439.05893 pca_loss= 38.58747 accuracy= 0.67510 accuracy_s= 0.80279 accuracy_f= 0.84075 time= 0.23101
Epoch: 0181 train_loss= 760.62299 feature_loss= 12.61196 structure_loss= 283.87234 proj_loss= 427.10629 pca_loss= 37.03240 accuracy= 0.67830 accuracy_s= 0.80105 accuracy_f= 0.84162 time= 0.21191
Epoch: 0191 train_loss= 740.58911 feature_loss= 12.54323 structure_loss= 277.08408 proj_loss= 415.55811 pca_loss= 35.40369 accuracy= 0.67685 accuracy_s= 0.79988 accuracy_f= 0.84366 time= 0.22673
Epoch: 0201 train_loss= 723.27606 feature_loss= 12.45997 structure_loss= 272.44467 proj_loss= 404.38876 pca_loss= 33.98266 accuracy= 0.67961 accuracy_s= 0.80076 accuracy_f= 0.84424 time= 0.23297
Epoch: 0211 train_loss= 705.18768 feature_loss= 12.42314 structure_loss= 266.02136 proj_loss= 393.60526 pca_loss= 33.13795 accuracy= 0.67787 accuracy_s= 0.80308 accuracy_f= 0.84395 time= 0.21028
Epoch: 0221 train_loss= 681.17560 feature_loss= 12.37729 structure_loss= 254.10985 proj_loss= 383.20715 pca_loss= 31.48130 accuracy= 0.68339 accuracy_s= 0.79988 accuracy_f= 0.84511 time= 0.21233
Epoch: 0231 train_loss= 667.46167 feature_loss= 12.32680 structure_loss= 251.28459 proj_loss= 373.17841 pca_loss= 30.67188 accuracy= 0.68092 accuracy_s= 0.79974 accuracy_f= 0.84686 time= 0.21550
Epoch: 0241 train_loss= 642.87097 feature_loss= 12.26521 structure_loss= 237.52072 proj_loss= 363.51678 pca_loss= 29.56827 accuracy= 0.68281 accuracy_s= 0.79930 accuracy_f= 0.84570 time= 0.21412
Epoch: 0251 train_loss= 628.42700 feature_loss= 12.24122 structure_loss= 233.38181 proj_loss= 354.17731 pca_loss= 28.62674 accuracy= 0.67976 accuracy_s= 0.80090 accuracy_f= 0.84773 time= 0.21687
Epoch: 0261 train_loss= 612.47229 feature_loss= 12.21046 structure_loss= 226.87155 proj_loss= 345.14258 pca_loss= 28.24767 accuracy= 0.68296 accuracy_s= 0.80207 accuracy_f= 0.84657 time= 0.21201
Epoch: 0271 train_loss= 592.85260 feature_loss= 12.19754 structure_loss= 217.07805 proj_loss= 336.38153 pca_loss= 27.19548 accuracy= 0.68514 accuracy_s= 0.80163 accuracy_f= 0.84729 time= 0.21819
Epoch: 0281 train_loss= 580.07324 feature_loss= 12.16038 structure_loss= 213.75555 proj_loss= 327.93668 pca_loss= 26.22061 accuracy= 0.68499 accuracy_s= 0.80032 accuracy_f= 0.84802 time= 0.21468
Epoch: 0291 train_loss= 585.94818 feature_loss= 12.28929 structure_loss= 226.56084 proj_loss= 319.79034 pca_loss= 27.30770 accuracy= 0.68732 accuracy_s= 0.79974 accuracy_f= 0.84322 time= 0.21379

accuracy 0.68441
accuracy_s 0.79727
accuracy_f 0.84817
auc 0.56484
f1_score 0.27667
Job finished!



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 576
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 10226.43066 feature_loss= 23.60382 structure_loss= 7019.26660 proj_loss= 2689.38330 pca_loss= 494.17630 accuracy= 0.62740 accuracy_s= 0.78912 accuracy_f= 0.82097 time= 0.23347
Epoch: 0011 train_loss= 4148.59717 feature_loss= 16.33195 structure_loss= 1344.01196 proj_loss= 2591.04468 pca_loss= 197.20842 accuracy= 0.62565 accuracy_s= 0.78505 accuracy_f= 0.82155 time= 0.20891
Epoch: 0021 train_loss= 3473.51807 feature_loss= 15.52381 structure_loss= 821.40955 proj_loss= 2480.07422 pca_loss= 156.51057 accuracy= 0.64252 accuracy_s= 0.78330 accuracy_f= 0.82315 time= 0.21395
Epoch: 0031 train_loss= 3128.46509 feature_loss= 15.06176 structure_loss= 615.59814 proj_loss= 2364.97827 pca_loss= 132.82687 accuracy= 0.61911 accuracy_s= 0.78330 accuracy_f= 0.82432 time= 0.20900
Epoch: 0041 train_loss= 2893.60669 feature_loss= 14.67913 structure_loss= 516.08441 proj_loss= 2253.30688 pca_loss= 109.53640 accuracy= 0.63787 accuracy_s= 0.78534 accuracy_f= 0.82650 time= 0.21182
Epoch: 0051 train_loss= 2704.93262 feature_loss= 14.35069 structure_loss= 456.07367 proj_loss= 2145.11792 pca_loss= 89.39043 accuracy= 0.63060 accuracy_s= 0.78621 accuracy_f= 0.82955 time= 0.21034
Epoch: 0061 train_loss= 2543.07007 feature_loss= 14.07200 structure_loss= 415.49921 proj_loss= 2041.90222 pca_loss= 71.59679 accuracy= 0.64500 accuracy_s= 0.78650 accuracy_f= 0.83115 time= 0.20909
Epoch: 0071 train_loss= 2406.47070 feature_loss= 13.85612 structure_loss= 392.99362 proj_loss= 1943.89771 pca_loss= 55.72314 accuracy= 0.64849 accuracy_s= 0.78636 accuracy_f= 0.83246 time= 0.20936
Epoch: 0081 train_loss= 2279.36743 feature_loss= 13.69870 structure_loss= 372.86606 proj_loss= 1851.18738 pca_loss= 41.61525 accuracy= 0.65430 accuracy_s= 0.78476 accuracy_f= 0.83290 time= 0.21531
Epoch: 0091 train_loss= 2155.39551 feature_loss= 13.58546 structure_loss= 347.99878 proj_loss= 1763.52979 pca_loss= 30.28141 accuracy= 0.65954 accuracy_s= 0.78636 accuracy_f= 0.83188 time= 0.21150
Epoch: 0101 train_loss= 2063.42529 feature_loss= 13.47024 structure_loss= 345.18286 proj_loss= 1680.40454 pca_loss= 24.36769 accuracy= 0.66812 accuracy_s= 0.80556 accuracy_f= 0.83232 time= 0.21023
Epoch: 0111 train_loss= 1962.61633 feature_loss= 13.33725 structure_loss= 325.19962 proj_loss= 1601.31482 pca_loss= 22.76471 accuracy= 0.66798 accuracy_s= 0.79058 accuracy_f= 0.83304 time= 0.21661
Epoch: 0121 train_loss= 1882.74048 feature_loss= 13.23734 structure_loss= 321.71854 proj_loss= 1526.33728 pca_loss= 21.44721 accuracy= 0.66667 accuracy_s= 0.79218 accuracy_f= 0.83348 time= 0.21427
Epoch: 0131 train_loss= 1793.59436 feature_loss= 13.15150 structure_loss= 304.21637 proj_loss= 1455.68445 pca_loss= 20.54217 accuracy= 0.66870 accuracy_s= 0.79232 accuracy_f= 0.83348 time= 0.21463
Epoch: 0141 train_loss= 1725.91516 feature_loss= 13.07644 structure_loss= 304.07455 proj_loss= 1389.21313 pca_loss= 19.55108 accuracy= 0.66768 accuracy_s= 0.79712 accuracy_f= 0.83450 time= 0.23017
Epoch: 0151 train_loss= 1652.16394 feature_loss= 13.01077 structure_loss= 293.92197 proj_loss= 1326.47681 pca_loss= 18.75439 accuracy= 0.66914 accuracy_s= 0.79974 accuracy_f= 0.83479 time= 0.21388
Epoch: 0161 train_loss= 1576.78967 feature_loss= 12.95098 structure_loss= 278.39462 proj_loss= 1267.20618 pca_loss= 18.23793 accuracy= 0.66914 accuracy_s= 0.79828 accuracy_f= 0.83392 time= 0.21125
Epoch: 0171 train_loss= 1518.92529 feature_loss= 12.88820 structure_loss= 277.05048 proj_loss= 1211.17688 pca_loss= 17.80964 accuracy= 0.66943 accuracy_s= 0.80396 accuracy_f= 0.83479 time= 0.21442
Epoch: 0181 train_loss= 1445.25610 feature_loss= 13.16478 structure_loss= 256.57343 proj_loss= 1158.25513 pca_loss= 17.26266 accuracy= 0.66070 accuracy_s= 0.80105 accuracy_f= 0.83784 time= 0.23816
Epoch: 0191 train_loss= 1406.35815 feature_loss= 12.96671 structure_loss= 267.87134 proj_loss= 1108.22009 pca_loss= 17.30004 accuracy= 0.67350 accuracy_s= 0.79988 accuracy_f= 0.82868 time= 0.21651
Epoch: 0201 train_loss= 1335.71436 feature_loss= 12.84604 structure_loss= 245.11058 proj_loss= 1060.85986 pca_loss= 16.89777 accuracy= 0.67263 accuracy_s= 0.80032 accuracy_f= 0.83202 time= 0.21722
Epoch: 0211 train_loss= 1281.79346 feature_loss= 12.82631 structure_loss= 236.37712 proj_loss= 1016.05243 pca_loss= 16.53755 accuracy= 0.67045 accuracy_s= 0.80032 accuracy_f= 0.83508 time= 0.20911
Epoch: 0221 train_loss= 1238.74146 feature_loss= 12.73594 structure_loss= 236.19914 proj_loss= 973.56061 pca_loss= 16.24569 accuracy= 0.67219 accuracy_s= 0.80337 accuracy_f= 0.83362 time= 0.21384
Epoch: 0231 train_loss= 1194.29053 feature_loss= 12.67308 structure_loss= 232.47903 proj_loss= 933.26971 pca_loss= 15.86860 accuracy= 0.67248 accuracy_s= 0.79901 accuracy_f= 0.83581 time= 0.21154
Epoch: 0241 train_loss= 1149.18054 feature_loss= 12.53486 structure_loss= 225.99765 proj_loss= 895.05560 pca_loss= 15.59243 accuracy= 0.67365 accuracy_s= 0.80047 accuracy_f= 0.84061 time= 0.20960
Epoch: 0251 train_loss= 1108.41589 feature_loss= 12.46570 structure_loss= 221.87447 proj_loss= 858.76678 pca_loss= 15.30900 accuracy= 0.67946 accuracy_s= 0.80512 accuracy_f= 0.83973 time= 0.20865
Epoch: 0261 train_loss= 1069.68787 feature_loss= 12.41261 structure_loss= 217.89766 proj_loss= 824.32483 pca_loss= 15.05268 accuracy= 0.67946 accuracy_s= 0.80541 accuracy_f= 0.84075 time= 0.21186
Epoch: 0271 train_loss= 1027.63989 feature_loss= 12.36166 structure_loss= 208.90874 proj_loss= 791.58990 pca_loss= 14.77954 accuracy= 0.67917 accuracy_s= 0.80003 accuracy_f= 0.84177 time= 0.21016
Epoch: 0281 train_loss= 995.29736 feature_loss= 12.32792 structure_loss= 207.97514 proj_loss= 760.44708 pca_loss= 14.54725 accuracy= 0.68179 accuracy_s= 0.79959 accuracy_f= 0.84133 time= 0.21082
Epoch: 0291 train_loss= 960.48401 feature_loss= 12.27625 structure_loss= 203.07600 proj_loss= 730.85565 pca_loss= 14.27612 accuracy= 0.68412 accuracy_s= 0.80294 accuracy_f= 0.84293 time= 0.21312

accuracy 0.67932
accuracy_s 0.80381
accuracy_f 0.84526
auc 0.55018
f1_score 0.26500
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 509
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 2191.08081 reconstruction_loss= 24.10324 proj_loss= 696.87762 pca_loss= 1470.09985 accuracy= 0.66812 time= 0.19416
Epoch: 0011 train_loss= 1130.86963 reconstruction_loss= 21.45307 proj_loss= 670.89966 pca_loss= 438.51688 accuracy= 0.67816 time= 0.15648
Epoch: 0021 train_loss= 973.97638 reconstruction_loss= 15.01892 proj_loss= 648.09058 pca_loss= 310.86688 accuracy= 0.67976 time= 0.17791
Epoch: 0031 train_loss= 858.37439 reconstruction_loss= 14.61144 proj_loss= 625.31506 pca_loss= 218.44791 accuracy= 0.68005 time= 0.16951
Epoch: 0041 train_loss= 769.61255 reconstruction_loss= 14.29922 proj_loss= 602.04926 pca_loss= 153.26401 accuracy= 0.67801 time= 0.15599
Epoch: 0051 train_loss= 699.34753 reconstruction_loss= 14.05598 proj_loss= 578.56964 pca_loss= 106.72194 accuracy= 0.67685 time= 0.14985
Epoch: 0061 train_loss= 641.97632 reconstruction_loss= 13.82953 proj_loss= 555.37006 pca_loss= 72.77672 accuracy= 0.67510 time= 0.17327
Epoch: 0071 train_loss= 594.24951 reconstruction_loss= 13.62569 proj_loss= 532.75018 pca_loss= 47.87363 accuracy= 0.67481 time= 0.17764
Epoch: 0081 train_loss= 554.38513 reconstruction_loss= 13.44286 proj_loss= 510.75491 pca_loss= 30.18736 accuracy= 0.67437 time= 0.17431
Epoch: 0091 train_loss= 520.95715 reconstruction_loss= 13.28823 proj_loss= 489.44717 pca_loss= 18.22174 accuracy= 0.67350 time= 0.21848
Epoch: 0101 train_loss= 494.22440 reconstruction_loss= 13.18519 proj_loss= 468.87976 pca_loss= 12.15944 accuracy= 0.67481 time= 0.14362
Epoch: 0111 train_loss= 473.33167 reconstruction_loss= 13.12535 proj_loss= 448.94769 pca_loss= 11.25865 accuracy= 0.67496 time= 0.13798
Epoch: 0121 train_loss= 453.13980 reconstruction_loss= 12.95847 proj_loss= 429.90222 pca_loss= 10.27910 accuracy= 0.67583 time= 0.15425
Epoch: 0131 train_loss= 434.40344 reconstruction_loss= 12.81295 proj_loss= 411.87567 pca_loss= 9.71481 accuracy= 0.67496 time= 0.13504
Epoch: 0141 train_loss= 416.78329 reconstruction_loss= 12.69998 proj_loss= 394.87506 pca_loss= 9.20824 accuracy= 0.67612 time= 0.14286
Epoch: 0151 train_loss= 400.23889 reconstruction_loss= 12.61794 proj_loss= 378.80353 pca_loss= 8.81743 accuracy= 0.67816 time= 0.13701
Epoch: 0161 train_loss= 384.67773 reconstruction_loss= 12.53148 proj_loss= 363.57471 pca_loss= 8.57155 accuracy= 0.67976 time= 0.14941
Epoch: 0171 train_loss= 369.89124 reconstruction_loss= 12.46095 proj_loss= 349.14972 pca_loss= 8.28057 accuracy= 0.68121 time= 0.14211
Epoch: 0181 train_loss= 355.97821 reconstruction_loss= 12.39989 proj_loss= 335.48416 pca_loss= 8.09414 accuracy= 0.68179 time= 0.14098
Epoch: 0191 train_loss= 342.94864 reconstruction_loss= 12.43815 proj_loss= 322.53400 pca_loss= 7.97651 accuracy= 0.67437 time= 0.13696
Epoch: 0201 train_loss= 330.47739 reconstruction_loss= 12.30893 proj_loss= 310.34851 pca_loss= 7.81995 accuracy= 0.68019 time= 0.15211
Epoch: 0211 train_loss= 318.67120 reconstruction_loss= 12.25678 proj_loss= 298.78989 pca_loss= 7.62454 accuracy= 0.68339 time= 0.14046
Epoch: 0221 train_loss= 307.51794 reconstruction_loss= 12.22617 proj_loss= 287.80319 pca_loss= 7.48859 accuracy= 0.68383 time= 0.16895
Epoch: 0231 train_loss= 297.00687 reconstruction_loss= 12.23673 proj_loss= 277.36371 pca_loss= 7.40643 accuracy= 0.68906 time= 0.13954
Epoch: 0241 train_loss= 286.93686 reconstruction_loss= 12.17986 proj_loss= 267.44666 pca_loss= 7.31034 accuracy= 0.67990 time= 0.13549
Epoch: 0251 train_loss= 277.32758 reconstruction_loss= 12.13248 proj_loss= 258.01328 pca_loss= 7.18182 accuracy= 0.68775 time= 0.13608
Epoch: 0261 train_loss= 268.23068 reconstruction_loss= 12.10017 proj_loss= 249.01917 pca_loss= 7.11135 accuracy= 0.69154 time= 0.14737
Epoch: 0271 train_loss= 259.52814 reconstruction_loss= 12.06736 proj_loss= 240.43814 pca_loss= 7.02265 accuracy= 0.69241 time= 0.15512
Epoch: 0281 train_loss= 251.32567 reconstruction_loss= 12.09024 proj_loss= 232.25835 pca_loss= 6.97708 accuracy= 0.68266 time= 0.13675
Epoch: 0291 train_loss= 243.37900 reconstruction_loss= 12.03789 proj_loss= 224.46333 pca_loss= 6.87778 accuracy= 0.69037 time= 0.14099

accuracy 0.69241
auc 0.56716
f1_score 0.29500
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 803
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 8819.21191 reconstruction_loss= 6618.01074 proj_loss= 696.55219 pca_loss= 1504.64905 accuracy= 0.62609 time= 0.16181
Epoch: 0011 train_loss= 2400.83887 reconstruction_loss= 1117.02551 proj_loss= 687.84869 pca_loss= 595.96466 accuracy= 0.62725 time= 0.13209
Epoch: 0021 train_loss= 1889.39355 reconstruction_loss= 743.33746 proj_loss= 676.09308 pca_loss= 469.96301 accuracy= 0.62638 time= 0.13353
Epoch: 0031 train_loss= 1570.17603 reconstruction_loss= 537.37640 proj_loss= 662.03815 pca_loss= 370.76154 accuracy= 0.62333 time= 0.13547
Epoch: 0041 train_loss= 1388.58813 reconstruction_loss= 449.95419 proj_loss= 647.10803 pca_loss= 291.52588 accuracy= 0.62129 time= 0.13167
Epoch: 0051 train_loss= 1274.21130 reconstruction_loss= 413.04584 proj_loss= 631.48700 pca_loss= 229.67850 accuracy= 0.62667 time= 0.13276
Epoch: 0061 train_loss= 1190.13867 reconstruction_loss= 391.88199 proj_loss= 615.45966 pca_loss= 182.79706 accuracy= 0.64529 time= 0.13437
Epoch: 0071 train_loss= 1120.72095 reconstruction_loss= 375.84546 proj_loss= 599.27472 pca_loss= 145.60071 accuracy= 0.63016 time= 0.13113
Epoch: 0081 train_loss= 1056.46631 reconstruction_loss= 357.95929 proj_loss= 583.10956 pca_loss= 115.39744 accuracy= 0.63016 time= 0.15011
Epoch: 0091 train_loss= 1009.89270 reconstruction_loss= 349.61469 proj_loss= 567.10333 pca_loss= 93.17471 accuracy= 0.64136 time= 0.13134
Epoch: 0101 train_loss= 965.67676 reconstruction_loss= 338.76859 proj_loss= 551.48914 pca_loss= 75.41908 accuracy= 0.65605 time= 0.14357
Epoch: 0111 train_loss= 920.77081 reconstruction_loss= 323.03900 proj_loss= 536.20312 pca_loss= 61.52869 accuracy= 0.64616 time= 0.13022
Epoch: 0121 train_loss= 888.73022 reconstruction_loss= 314.98447 proj_loss= 521.22369 pca_loss= 52.52207 accuracy= 0.65183 time= 0.13224
Epoch: 0131 train_loss= 863.50427 reconstruction_loss= 309.68423 proj_loss= 506.65735 pca_loss= 47.16269 accuracy= 0.65125 time= 0.13213
Epoch: 0141 train_loss= 839.71930 reconstruction_loss= 302.09164 proj_loss= 492.52756 pca_loss= 45.10012 accuracy= 0.65445 time= 0.13159
Epoch: 0151 train_loss= 821.21753 reconstruction_loss= 299.45325 proj_loss= 478.73782 pca_loss= 43.02652 accuracy= 0.65387 time= 0.13491
Epoch: 0161 train_loss= 798.13220 reconstruction_loss= 291.80087 proj_loss= 465.32336 pca_loss= 41.00792 accuracy= 0.64703 time= 0.13224
Epoch: 0171 train_loss= 774.86963 reconstruction_loss= 283.34604 proj_loss= 452.33456 pca_loss= 39.18903 accuracy= 0.65154 time= 0.13097
Epoch: 0181 train_loss= 753.08545 reconstruction_loss= 275.49622 proj_loss= 439.80832 pca_loss= 37.78088 accuracy= 0.65780 time= 0.13011
Epoch: 0191 train_loss= 733.98553 reconstruction_loss= 269.87711 proj_loss= 427.72092 pca_loss= 36.38753 accuracy= 0.65271 time= 0.13162
Epoch: 0201 train_loss= 712.29895 reconstruction_loss= 261.38431 proj_loss= 416.00449 pca_loss= 34.91013 accuracy= 0.65300 time= 0.13195
Epoch: 0211 train_loss= 695.14032 reconstruction_loss= 257.59042 proj_loss= 404.69778 pca_loss= 32.85210 accuracy= 0.65809 time= 0.13078
Epoch: 0221 train_loss= 677.67548 reconstruction_loss= 251.65642 proj_loss= 393.76535 pca_loss= 32.25371 accuracy= 0.66274 time= 0.13100
Epoch: 0231 train_loss= 660.33057 reconstruction_loss= 245.42099 proj_loss= 383.18109 pca_loss= 31.72855 accuracy= 0.64878 time= 0.13159
Epoch: 0241 train_loss= 642.24921 reconstruction_loss= 238.60667 proj_loss= 372.94531 pca_loss= 30.69722 accuracy= 0.65707 time= 0.13186
Epoch: 0251 train_loss= 630.57703 reconstruction_loss= 237.79974 proj_loss= 363.02872 pca_loss= 29.74855 accuracy= 0.65401 time= 0.13155
Epoch: 0261 train_loss= 616.10352 reconstruction_loss= 234.33607 proj_loss= 353.42847 pca_loss= 28.33901 accuracy= 0.65910 time= 0.13159
Epoch: 0271 train_loss= 596.85370 reconstruction_loss= 225.41566 proj_loss= 344.16730 pca_loss= 27.27076 accuracy= 0.65518 time= 0.13301
Epoch: 0281 train_loss= 577.02838 reconstruction_loss= 215.90186 proj_loss= 335.32947 pca_loss= 25.79708 accuracy= 0.65489 time= 0.13112
Epoch: 0291 train_loss= 560.88409 reconstruction_loss= 208.98021 proj_loss= 326.80811 pca_loss= 25.09576 accuracy= 0.65605 time= 0.13074

accuracy 0.65532
auc 0.47924
f1_score 0.21000
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 546
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 3037.40479 reconstruction_loss= 24.64073 proj_loss= 2426.92334 pca_loss= 585.84082 accuracy= 0.66608 time= 0.16895
Epoch: 0011 train_loss= 2361.25879 reconstruction_loss= 17.22576 proj_loss= 2280.07300 pca_loss= 63.95995 accuracy= 0.67888 time= 0.13859
Epoch: 0021 train_loss= 2185.77100 reconstruction_loss= 15.22131 proj_loss= 2145.49292 pca_loss= 25.05682 accuracy= 0.68426 time= 0.13884
Epoch: 0031 train_loss= 2044.58215 reconstruction_loss= 15.06119 proj_loss= 2017.43286 pca_loss= 12.08814 accuracy= 0.67816 time= 0.13677
Epoch: 0041 train_loss= 1921.28418 reconstruction_loss= 14.47461 proj_loss= 1896.31787 pca_loss= 10.49175 accuracy= 0.67903 time= 0.13902
Epoch: 0051 train_loss= 1808.63806 reconstruction_loss= 14.55967 proj_loss= 1784.68982 pca_loss= 9.38856 accuracy= 0.67917 time= 0.13599
Epoch: 0061 train_loss= 1704.47644 reconstruction_loss= 14.05680 proj_loss= 1681.37671 pca_loss= 9.04301 accuracy= 0.67874 time= 0.13693
Epoch: 0071 train_loss= 1608.01489 reconstruction_loss= 13.90034 proj_loss= 1585.50891 pca_loss= 8.60562 accuracy= 0.67932 time= 0.13592
Epoch: 0081 train_loss= 1518.61401 reconstruction_loss= 13.73409 proj_loss= 1496.58398 pca_loss= 8.29589 accuracy= 0.67946 time= 0.13656
Epoch: 0091 train_loss= 1435.62231 reconstruction_loss= 13.48032 proj_loss= 1413.97449 pca_loss= 8.16746 accuracy= 0.68005 time= 0.17756
Epoch: 0101 train_loss= 1358.48572 reconstruction_loss= 13.28877 proj_loss= 1337.20447 pca_loss= 7.99241 accuracy= 0.68150 time= 0.13356
Epoch: 0111 train_loss= 1286.76135 reconstruction_loss= 13.12261 proj_loss= 1265.74280 pca_loss= 7.89599 accuracy= 0.67874 time= 0.16289
Epoch: 0121 train_loss= 1219.92444 reconstruction_loss= 12.97543 proj_loss= 1199.18201 pca_loss= 7.76694 accuracy= 0.67917 time= 0.17208
Epoch: 0131 train_loss= 1157.66089 reconstruction_loss= 12.86276 proj_loss= 1137.10681 pca_loss= 7.69124 accuracy= 0.67976 time= 0.17649
Epoch: 0141 train_loss= 1099.48169 reconstruction_loss= 12.73099 proj_loss= 1079.15674 pca_loss= 7.59398 accuracy= 0.67961 time= 0.18631
Epoch: 0151 train_loss= 1045.16467 reconstruction_loss= 12.65769 proj_loss= 1025.00183 pca_loss= 7.50512 accuracy= 0.68165 time= 0.16459
Epoch: 0161 train_loss= 994.36359 reconstruction_loss= 12.57568 proj_loss= 974.33655 pca_loss= 7.45137 accuracy= 0.68514 time= 0.15887
Epoch: 0171 train_loss= 946.77606 reconstruction_loss= 12.48513 proj_loss= 926.90057 pca_loss= 7.39040 accuracy= 0.68296 time= 0.17504
Epoch: 0181 train_loss= 902.19354 reconstruction_loss= 12.41933 proj_loss= 882.43335 pca_loss= 7.34085 accuracy= 0.68368 time= 0.13687
Epoch: 0191 train_loss= 860.37042 reconstruction_loss= 12.35346 proj_loss= 840.71796 pca_loss= 7.29904 accuracy= 0.68761 time= 0.16364
Epoch: 0201 train_loss= 821.10004 reconstruction_loss= 12.30738 proj_loss= 801.54517 pca_loss= 7.24748 accuracy= 0.68659 time= 0.15676
Epoch: 0211 train_loss= 784.24182 reconstruction_loss= 12.30067 proj_loss= 764.72638 pca_loss= 7.21478 accuracy= 0.68775 time= 0.16292
Epoch: 0221 train_loss= 749.62964 reconstruction_loss= 12.28027 proj_loss= 730.12500 pca_loss= 7.22437 accuracy= 0.67743 time= 0.13347
Epoch: 0231 train_loss= 716.93420 reconstruction_loss= 12.22956 proj_loss= 697.54919 pca_loss= 7.15546 accuracy= 0.68630 time= 0.13624
Epoch: 0241 train_loss= 686.13324 reconstruction_loss= 12.15875 proj_loss= 666.85223 pca_loss= 7.12223 accuracy= 0.68659 time= 0.13680
Epoch: 0251 train_loss= 657.10913 reconstruction_loss= 12.12639 proj_loss= 637.89545 pca_loss= 7.08730 accuracy= 0.68848 time= 0.13619
Epoch: 0261 train_loss= 629.71008 reconstruction_loss= 12.08335 proj_loss= 610.55945 pca_loss= 7.06726 accuracy= 0.68572 time= 0.13573
Epoch: 0271 train_loss= 603.85895 reconstruction_loss= 12.07454 proj_loss= 584.73877 pca_loss= 7.04567 accuracy= 0.68950 time= 0.13901
Epoch: 0281 train_loss= 579.41718 reconstruction_loss= 12.05401 proj_loss= 560.33307 pca_loss= 7.03007 accuracy= 0.68877 time= 0.13441
Epoch: 0291 train_loss= 556.28400 reconstruction_loss= 12.02670 proj_loss= 537.25134 pca_loss= 7.00601 accuracy= 0.68892 time= 0.14840

accuracy 0.69270
auc 0.57010
f1_score 0.29567
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 481
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
Epoch: 0001 train_loss= 10182.90625 reconstruction_loss= 6914.05859 proj_loss= 2730.91504 pca_loss= 537.93219 accuracy= 0.62289 time= 0.17092
Epoch: 0011 train_loss= 4407.18066 reconstruction_loss= 1557.54968 proj_loss= 2632.59351 pca_loss= 217.03743 accuracy= 0.62289 time= 0.12681
Epoch: 0021 train_loss= 3538.88086 reconstruction_loss= 842.81665 proj_loss= 2523.89673 pca_loss= 172.16753 accuracy= 0.64383 time= 0.14086
Epoch: 0031 train_loss= 3158.78101 reconstruction_loss= 605.09259 proj_loss= 2409.49390 pca_loss= 144.19463 accuracy= 0.61707 time= 0.14113
Epoch: 0041 train_loss= 2919.91187 reconstruction_loss= 503.95102 proj_loss= 2299.14648 pca_loss= 116.81441 accuracy= 0.65620 time= 0.12502
Epoch: 0051 train_loss= 2736.98560 reconstruction_loss= 451.05246 proj_loss= 2192.11938 pca_loss= 93.81363 accuracy= 0.62129 time= 0.15184
Epoch: 0061 train_loss= 2577.96582 reconstruction_loss= 414.61359 proj_loss= 2089.45264 pca_loss= 73.89975 accuracy= 0.63118 time= 0.14659
Epoch: 0071 train_loss= 2442.93823 reconstruction_loss= 394.10327 proj_loss= 1992.01001 pca_loss= 56.82488 accuracy= 0.65285 time= 0.13970
Epoch: 0081 train_loss= 2319.82153 reconstruction_loss= 378.23999 proj_loss= 1899.68384 pca_loss= 41.89778 accuracy= 0.61707 time= 0.13390
Epoch: 0091 train_loss= 2213.95483 reconstruction_loss= 370.58026 proj_loss= 1811.93848 pca_loss= 31.43614 accuracy= 0.67234 time= 0.12871
Epoch: 0101 train_loss= 2110.90161 reconstruction_loss= 354.80029 proj_loss= 1727.92419 pca_loss= 28.17697 accuracy= 0.66652 time= 0.12851
Epoch: 0111 train_loss= 2014.68152 reconstruction_loss= 340.86810 proj_loss= 1647.40198 pca_loss= 26.41146 accuracy= 0.68630 time= 0.12918
Epoch: 0121 train_loss= 1937.12646 reconstruction_loss= 340.78201 proj_loss= 1571.23779 pca_loss= 25.10669 accuracy= 0.67946 time= 0.13016
Epoch: 0131 train_loss= 1853.52393 reconstruction_loss= 329.81906 proj_loss= 1499.67310 pca_loss= 24.03172 accuracy= 0.65416 time= 0.13208
Epoch: 0141 train_loss= 1775.07312 reconstruction_loss= 319.65689 proj_loss= 1432.22839 pca_loss= 23.18789 accuracy= 0.65489 time= 0.13045
Epoch: 0151 train_loss= 1707.85889 reconstruction_loss= 316.86203 proj_loss= 1368.44031 pca_loss= 22.55647 accuracy= 0.65241 time= 0.13081
Epoch: 0161 train_loss= 1636.44617 reconstruction_loss= 306.34744 proj_loss= 1308.11243 pca_loss= 21.98628 accuracy= 0.64951 time= 0.15173
Epoch: 0171 train_loss= 1575.23413 reconstruction_loss= 302.69427 proj_loss= 1251.06396 pca_loss= 21.47586 accuracy= 0.65023 time= 0.12910
Epoch: 0181 train_loss= 1520.95239 reconstruction_loss= 302.92801 proj_loss= 1197.08142 pca_loss= 20.94305 accuracy= 0.65489 time= 0.12710
Epoch: 0191 train_loss= 1467.11609 reconstruction_loss= 300.63779 proj_loss= 1145.98328 pca_loss= 20.49503 accuracy= 0.65707 time= 0.12811
Epoch: 0201 train_loss= 1407.08228 reconstruction_loss= 289.43573 proj_loss= 1097.58411 pca_loss= 20.06247 accuracy= 0.66129 time= 0.12892
Epoch: 0211 train_loss= 1353.75452 reconstruction_loss= 282.42352 proj_loss= 1051.72229 pca_loss= 19.60873 accuracy= 0.64994 time= 0.12831
Epoch: 0221 train_loss= 1301.92285 reconstruction_loss= 274.55447 proj_loss= 1008.24426 pca_loss= 19.12416 accuracy= 0.65372 time= 0.12871
Epoch: 0231 train_loss= 1256.52295 reconstruction_loss= 270.82465 proj_loss= 967.00446 pca_loss= 18.69380 accuracy= 0.66129 time= 0.12881
Epoch: 0241 train_loss= 1216.14380 reconstruction_loss= 269.89340 proj_loss= 927.87262 pca_loss= 18.37780 accuracy= 0.65561 time= 0.16817
Epoch: 0251 train_loss= 1169.61633 reconstruction_loss= 260.90881 proj_loss= 890.73059 pca_loss= 17.97696 accuracy= 0.65387 time= 0.13477
Epoch: 0261 train_loss= 1130.14771 reconstruction_loss= 257.18750 proj_loss= 855.42810 pca_loss= 17.53210 accuracy= 0.65969 time= 0.16163
Epoch: 0271 train_loss= 1092.37781 reconstruction_loss= 253.38606 proj_loss= 821.87982 pca_loss= 17.11191 accuracy= 0.65387 time= 0.14564
Epoch: 0281 train_loss= 1059.70605 reconstruction_loss= 253.04210 proj_loss= 789.99426 pca_loss= 16.66963 accuracy= 0.65430 time= 0.14396
Epoch: 0291 train_loss= 1006.25232 reconstruction_loss= 230.35402 proj_loss= 759.66681 pca_loss= 16.23150 accuracy= 0.65678 time= 0.16375

accuracy 0.65241
auc 0.48872
f1_score 0.20333
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 488
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 13405.69922 feature_loss= 28.17134 structure_loss= 10374.14355 proj_loss= 654.18054 pca_loss= 2349.20361 accuracy= 0.63147 accuracy_s= 0.78476 accuracy_f= 0.80672 time= 0.22155
Epoch: 0011 train_loss= 8841.09375 feature_loss= 21.89170 structure_loss= 5999.28369 proj_loss= 644.19196 pca_loss= 2175.72656 accuracy= 0.63249 accuracy_s= 0.78796 accuracy_f= 0.81690 time= 0.18846
Epoch: 0021 train_loss= 7473.84912 feature_loss= 19.80203 structure_loss= 4806.52051 proj_loss= 632.67859 pca_loss= 2014.84766 accuracy= 0.64805 accuracy_s= 0.78927 accuracy_f= 0.82097 time= 0.17367
Epoch: 0031 train_loss= 6590.04199 feature_loss= 17.52155 structure_loss= 4083.35034 proj_loss= 618.58533 pca_loss= 1870.58472 accuracy= 0.65561 accuracy_s= 0.78999 accuracy_f= 0.82388 time= 0.17342
Epoch: 0041 train_loss= 5869.22461 feature_loss= 16.13529 structure_loss= 3508.31567 proj_loss= 602.58246 pca_loss= 1742.19141 accuracy= 0.66289 accuracy_s= 0.79261 accuracy_f= 0.82563 time= 0.17261
Epoch: 0051 train_loss= 5213.46582 feature_loss= 15.13135 structure_loss= 2983.88574 proj_loss= 585.45618 pca_loss= 1628.99268 accuracy= 0.67437 accuracy_s= 0.79465 accuracy_f= 0.82548 time= 0.17130
Epoch: 0061 train_loss= 4578.69434 feature_loss= 14.31232 structure_loss= 2466.95239 proj_loss= 567.76508 pca_loss= 1529.66431 accuracy= 0.68121 accuracy_s= 0.79843 accuracy_f= 0.82446 time= 0.17094
Epoch: 0071 train_loss= 3945.68848 feature_loss= 13.88842 structure_loss= 1939.20337 proj_loss= 549.86206 pca_loss= 1442.73450 accuracy= 0.68208 accuracy_s= 0.80163 accuracy_f= 0.82373 time= 0.17093
Epoch: 0081 train_loss= 3400.33716 feature_loss= 13.72386 structure_loss= 1488.29822 proj_loss= 531.77740 pca_loss= 1366.53760 accuracy= 0.67307 accuracy_s= 0.80076 accuracy_f= 0.82403 time= 0.17076
Epoch: 0091 train_loss= 2965.84082 feature_loss= 13.59118 structure_loss= 1139.54944 proj_loss= 513.66418 pca_loss= 1299.03613 accuracy= 0.66638 accuracy_s= 0.79857 accuracy_f= 0.82563 time= 0.17007
Epoch: 0101 train_loss= 2617.60059 feature_loss= 13.46824 structure_loss= 869.10089 proj_loss= 495.74374 pca_loss= 1239.28772 accuracy= 0.66143 accuracy_s= 0.79479 accuracy_f= 0.82621 time= 0.17061
Epoch: 0111 train_loss= 2340.55957 feature_loss= 13.35447 structure_loss= 662.63483 proj_loss= 478.22983 pca_loss= 1186.34045 accuracy= 0.66158 accuracy_s= 0.79305 accuracy_f= 0.82766 time= 0.17041
Epoch: 0121 train_loss= 2143.78809 feature_loss= 13.24994 structure_loss= 530.56323 proj_loss= 461.15796 pca_loss= 1138.81689 accuracy= 0.65387 accuracy_s= 0.79130 accuracy_f= 0.82781 time= 0.17063
Epoch: 0131 train_loss= 1967.21045 feature_loss= 13.15525 structure_loss= 413.58618 proj_loss= 444.53378 pca_loss= 1095.93530 accuracy= 0.66289 accuracy_s= 0.79232 accuracy_f= 0.82781 time= 0.17144
Epoch: 0141 train_loss= 1820.81799 feature_loss= 13.06429 structure_loss= 322.39413 proj_loss= 428.45343 pca_loss= 1056.90613 accuracy= 0.66812 accuracy_s= 0.78999 accuracy_f= 0.82824 time= 0.17163
Epoch: 0151 train_loss= 1688.24609 feature_loss= 12.97482 structure_loss= 241.38309 proj_loss= 412.94180 pca_loss= 1020.94647 accuracy= 0.67641 accuracy_s= 0.79363 accuracy_f= 0.82810 time= 0.17082
Epoch: 0161 train_loss= 1571.10474 feature_loss= 12.89673 structure_loss= 172.90657 proj_loss= 398.05609 pca_loss= 987.24536 accuracy= 0.68252 accuracy_s= 0.79770 accuracy_f= 0.82882 time= 0.17098
Epoch: 0171 train_loss= 1475.50500 feature_loss= 12.82211 structure_loss= 124.01849 proj_loss= 383.86563 pca_loss= 954.79877 accuracy= 0.68485 accuracy_s= 0.79625 accuracy_f= 0.82926 time= 0.17100
Epoch: 0181 train_loss= 1397.21863 feature_loss= 12.74306 structure_loss= 90.75264 proj_loss= 370.36035 pca_loss= 923.36255 accuracy= 0.68790 accuracy_s= 0.79945 accuracy_f= 0.83057 time= 0.17375
Epoch: 0191 train_loss= 1327.95007 feature_loss= 12.66292 structure_loss= 65.15862 proj_loss= 357.53629 pca_loss= 892.59222 accuracy= 0.68877 accuracy_s= 0.79436 accuracy_f= 0.83115 time= 0.17165
Epoch: 0201 train_loss= 1270.29492 feature_loss= 12.58915 structure_loss= 49.56483 proj_loss= 345.35077 pca_loss= 862.79022 accuracy= 0.69255 accuracy_s= 0.78999 accuracy_f= 0.83261 time= 0.17185
Epoch: 0211 train_loss= 1219.81311 feature_loss= 12.52226 structure_loss= 39.68331 proj_loss= 333.74747 pca_loss= 833.86005 accuracy= 0.69386 accuracy_s= 0.78476 accuracy_f= 0.83362 time= 0.17250
Epoch: 0221 train_loss= 1173.15552 feature_loss= 12.46033 structure_loss= 32.07441 proj_loss= 322.64862 pca_loss= 805.97223 accuracy= 0.69401 accuracy_s= 0.78825 accuracy_f= 0.83668 time= 0.17143
Epoch: 0231 train_loss= 1129.14429 feature_loss= 12.39810 structure_loss= 25.58741 proj_loss= 312.04056 pca_loss= 779.11829 accuracy= 0.69503 accuracy_s= 0.78505 accuracy_f= 0.83813 time= 0.17172
Epoch: 0241 train_loss= 1087.71655 feature_loss= 12.34693 structure_loss= 20.25528 proj_loss= 301.85910 pca_loss= 753.25525 accuracy= 0.69648 accuracy_s= 0.78447 accuracy_f= 0.83930 time= 0.17177
Epoch: 0251 train_loss= 1045.79126 feature_loss= 12.28542 structure_loss= 12.92583 proj_loss= 292.06870 pca_loss= 728.51135 accuracy= 0.69663 accuracy_s= 0.78229 accuracy_f= 0.84031 time= 0.17188
Epoch: 0261 train_loss= 1008.59424 feature_loss= 12.22682 structure_loss= 8.89632 proj_loss= 282.65695 pca_loss= 704.81415 accuracy= 0.69910 accuracy_s= 0.78229 accuracy_f= 0.84351 time= 0.17121
Epoch: 0271 train_loss= 976.09497 feature_loss= 12.17154 structure_loss= 8.32426 proj_loss= 273.63492 pca_loss= 681.96423 accuracy= 0.69968 accuracy_s= 0.78229 accuracy_f= 0.84424 time= 0.17240
Epoch: 0281 train_loss= 945.27527 feature_loss= 12.13675 structure_loss= 8.14642 proj_loss= 264.98157 pca_loss= 660.01050 accuracy= 0.70055 accuracy_s= 0.78229 accuracy_f= 0.84482 time= 0.17186
Epoch: 0291 train_loss= 916.07861 feature_loss= 12.08683 structure_loss= 8.47243 proj_loss= 256.67035 pca_loss= 638.84900 accuracy= 0.70215 accuracy_s= 0.78229 accuracy_f= 0.84686 time= 0.17210

accuracy 0.70390
accuracy_s 0.78258
accuracy_f 0.84773
auc 0.56579
f1_score 0.32133
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 583
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 1331668.75000 feature_loss= 22.29452 structure_loss= 6244.52148 proj_loss= 1316426.25000 pca_loss= 8975.61719 accuracy= 0.61707 accuracy_s= 0.78461 accuracy_f= 0.82272 time= 0.22561
Epoch: 0011 train_loss= 1246027.00000 feature_loss= 17.73555 structure_loss= 3936.41040 proj_loss= 1235571.50000 pca_loss= 6501.32031 accuracy= 0.62216 accuracy_s= 0.78869 accuracy_f= 0.83072 time= 0.18945
Epoch: 0021 train_loss= 1167145.50000 feature_loss= 16.39649 structure_loss= 2988.02173 proj_loss= 1159912.25000 pca_loss= 4228.89746 accuracy= 0.62304 accuracy_s= 0.79072 accuracy_f= 0.82941 time= 0.20463
Epoch: 0031 train_loss= 1094115.62500 feature_loss= 15.48978 structure_loss= 2301.72119 proj_loss= 1089568.37500 pca_loss= 2230.00464 accuracy= 0.62245 accuracy_s= 0.79014 accuracy_f= 0.82693 time= 0.19287
Epoch: 0041 train_loss= 1026892.25000 feature_loss= 14.58262 structure_loss= 1871.03845 proj_loss= 1024258.62500 pca_loss= 748.00195 accuracy= 0.63176 accuracy_s= 0.79014 accuracy_f= 0.82461 time= 0.20635
Epoch: 0051 train_loss= 965718.56250 feature_loss= 14.21108 structure_loss= 1685.07275 proj_loss= 963489.68750 pca_loss= 529.58508 accuracy= 0.63045 accuracy_s= 0.79029 accuracy_f= 0.82504 time= 0.20792
Epoch: 0061 train_loss= 909393.75000 feature_loss= 13.98945 structure_loss= 1466.99158 proj_loss= 907456.31250 pca_loss= 456.46573 accuracy= 0.63583 accuracy_s= 0.79029 accuracy_f= 0.82650 time= 0.19110
Epoch: 0071 train_loss= 857456.62500 feature_loss= 13.79911 structure_loss= 1321.87708 proj_loss= 855689.31250 pca_loss= 431.64877 accuracy= 0.65576 accuracy_s= 0.79014 accuracy_f= 0.82882 time= 0.21130
Epoch: 0081 train_loss= 809409.25000 feature_loss= 13.62324 structure_loss= 1209.83398 proj_loss= 807773.87500 pca_loss= 411.93301 accuracy= 0.66565 accuracy_s= 0.79014 accuracy_f= 0.82984 time= 0.18738
Epoch: 0091 train_loss= 764881.93750 feature_loss= 13.46259 structure_loss= 1118.10205 proj_loss= 763354.37500 pca_loss= 396.02301 accuracy= 0.66419 accuracy_s= 0.79014 accuracy_f= 0.83130 time= 0.21112
Epoch: 0101 train_loss= 723543.75000 feature_loss= 13.32126 structure_loss= 1029.91235 proj_loss= 722110.00000 pca_loss= 390.49872 accuracy= 0.66579 accuracy_s= 0.79043 accuracy_f= 0.83275 time= 0.18903
Epoch: 0111 train_loss= 685122.68750 feature_loss= 13.19365 structure_loss= 959.99860 proj_loss= 683771.43750 pca_loss= 378.04785 accuracy= 0.66667 accuracy_s= 0.79319 accuracy_f= 0.83348 time= 0.21724
Epoch: 0121 train_loss= 649363.37500 feature_loss= 13.08074 structure_loss= 895.62372 proj_loss= 648084.37500 pca_loss= 370.30469 accuracy= 0.66594 accuracy_s= 0.79421 accuracy_f= 0.83551 time= 0.25632
Epoch: 0131 train_loss= 616031.87500 feature_loss= 12.98007 structure_loss= 841.67468 proj_loss= 614816.87500 pca_loss= 360.35733 accuracy= 0.66608 accuracy_s= 0.79218 accuracy_f= 0.83682 time= 0.25891
Epoch: 0141 train_loss= 584910.75000 feature_loss= 12.88618 structure_loss= 787.32739 proj_loss= 583763.93750 pca_loss= 346.61700 accuracy= 0.66739 accuracy_s= 0.79276 accuracy_f= 0.83711 time= 0.25995
Epoch: 0151 train_loss= 555830.00000 feature_loss= 12.80935 structure_loss= 737.43488 proj_loss= 554740.12500 pca_loss= 339.60443 accuracy= 0.66681 accuracy_s= 0.79523 accuracy_f= 0.83842 time= 0.20952
Epoch: 0161 train_loss= 528632.68750 feature_loss= 12.73492 structure_loss= 697.15186 proj_loss= 527587.25000 pca_loss= 335.53970 accuracy= 0.66739 accuracy_s= 0.79348 accuracy_f= 0.83886 time= 0.21189
Epoch: 0171 train_loss= 503157.50000 feature_loss= 12.66924 structure_loss= 657.93762 proj_loss= 502160.87500 pca_loss= 326.01849 accuracy= 0.66914 accuracy_s= 0.79305 accuracy_f= 0.83973 time= 0.19035
Epoch: 0181 train_loss= 479273.15625 feature_loss= 12.60797 structure_loss= 621.78180 proj_loss= 478321.96875 pca_loss= 316.82193 accuracy= 0.67001 accuracy_s= 0.79450 accuracy_f= 0.84031 time= 0.18966
Epoch: 0191 train_loss= 456849.59375 feature_loss= 12.54997 structure_loss= 581.61493 proj_loss= 455947.06250 pca_loss= 308.36569 accuracy= 0.67059 accuracy_s= 0.79523 accuracy_f= 0.84031 time= 0.18973
Epoch: 0201 train_loss= 435789.75000 feature_loss= 12.49906 structure_loss= 550.21417 proj_loss= 434923.81250 pca_loss= 303.21780 accuracy= 0.67132 accuracy_s= 0.79218 accuracy_f= 0.83944 time= 0.21851
Epoch: 0211 train_loss= 415984.96875 feature_loss= 12.45526 structure_loss= 517.54041 proj_loss= 415154.68750 pca_loss= 300.27567 accuracy= 0.67132 accuracy_s= 0.79421 accuracy_f= 0.84191 time= 0.18916
Epoch: 0221 train_loss= 397344.00000 feature_loss= 12.44492 structure_loss= 491.55637 proj_loss= 396548.40625 pca_loss= 291.60413 accuracy= 0.67045 accuracy_s= 0.79567 accuracy_f= 0.83930 time= 0.21634
Epoch: 0231 train_loss= 379787.21875 feature_loss= 12.40320 structure_loss= 468.75092 proj_loss= 379019.18750 pca_loss= 286.87338 accuracy= 0.67088 accuracy_s= 0.79523 accuracy_f= 0.84104 time= 0.19361
Epoch: 0241 train_loss= 363228.96875 feature_loss= 12.36476 structure_loss= 450.26877 proj_loss= 362490.18750 pca_loss= 276.14966 accuracy= 0.67176 accuracy_s= 0.79407 accuracy_f= 0.84206 time= 0.21126
Epoch: 0251 train_loss= 347596.46875 feature_loss= 12.32176 structure_loss= 423.97974 proj_loss= 346890.15625 pca_loss= 270.00143 accuracy= 0.67539 accuracy_s= 0.79334 accuracy_f= 0.84220 time= 0.19168
Epoch: 0261 train_loss= 332836.81250 feature_loss= 12.29778 structure_loss= 405.57111 proj_loss= 332154.81250 pca_loss= 264.12469 accuracy= 0.67525 accuracy_s= 0.79523 accuracy_f= 0.84191 time= 0.21561
Epoch: 0271 train_loss= 318878.28125 feature_loss= 12.27963 structure_loss= 380.71851 proj_loss= 318225.93750 pca_loss= 259.35263 accuracy= 0.67627 accuracy_s= 0.79363 accuracy_f= 0.84351 time= 0.19048
Epoch: 0281 train_loss= 305681.87500 feature_loss= 12.27388 structure_loss= 365.48560 proj_loss= 305049.96875 pca_loss= 254.14803 accuracy= 0.68063 accuracy_s= 0.79407 accuracy_f= 0.84235 time= 0.21823
Epoch: 0291 train_loss= 293186.31250 feature_loss= 12.23778 structure_loss= 348.87979 proj_loss= 292576.81250 pca_loss= 248.37744 accuracy= 0.67670 accuracy_s= 0.79247 accuracy_f= 0.84235 time= 0.20950

accuracy 0.68019
accuracy_s 0.79188
accuracy_f 0.84191
auc 0.53453
f1_score 0.26700
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 540
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 14932.83691 feature_loss= 27.96031 structure_loss= 11310.53320 proj_loss= 2762.30957 pca_loss= 832.03448 accuracy= 0.63002 accuracy_s= 0.78519 accuracy_f= 0.80701 time= 0.22790
Epoch: 0011 train_loss= 11659.41797 feature_loss= 22.05858 structure_loss= 8222.09375 proj_loss= 2619.04932 pca_loss= 796.21643 accuracy= 0.63205 accuracy_s= 0.78679 accuracy_f= 0.81704 time= 0.16680
Epoch: 0021 train_loss= 10246.04395 feature_loss= 19.68122 structure_loss= 6981.94092 proj_loss= 2481.33228 pca_loss= 763.09027 accuracy= 0.63365 accuracy_s= 0.78796 accuracy_f= 0.81748 time= 0.16564
Epoch: 0031 train_loss= 9213.64258 feature_loss= 17.88769 structure_loss= 6115.55371 proj_loss= 2349.38672 pca_loss= 730.81396 accuracy= 0.64354 accuracy_s= 0.78883 accuracy_f= 0.82330 time= 0.17233
Epoch: 0041 train_loss= 8425.19238 feature_loss= 16.64926 structure_loss= 5484.69678 proj_loss= 2222.39990 pca_loss= 701.44623 accuracy= 0.65052 accuracy_s= 0.78985 accuracy_f= 0.82301 time= 0.16596
Epoch: 0051 train_loss= 7761.18066 feature_loss= 15.38729 structure_loss= 4970.24463 proj_loss= 2101.14258 pca_loss= 674.40613 accuracy= 0.65649 accuracy_s= 0.79043 accuracy_f= 0.82272 time= 0.16543
Epoch: 0061 train_loss= 7127.33594 feature_loss= 14.34718 structure_loss= 4476.65430 proj_loss= 1987.07825 pca_loss= 649.25616 accuracy= 0.66143 accuracy_s= 0.79188 accuracy_f= 0.82213 time= 0.16497
Epoch: 0071 train_loss= 6449.16650 feature_loss= 13.96788 structure_loss= 3928.01855 proj_loss= 1881.07751 pca_loss= 626.10272 accuracy= 0.66201 accuracy_s= 0.79538 accuracy_f= 0.82213 time= 0.16638
Epoch: 0081 train_loss= 5707.40967 feature_loss= 13.54401 structure_loss= 3305.79517 proj_loss= 1782.63550 pca_loss= 605.43494 accuracy= 0.66129 accuracy_s= 0.79683 accuracy_f= 0.82257 time= 0.16584
Epoch: 0091 train_loss= 4918.37891 feature_loss= 13.38723 structure_loss= 2627.59351 proj_loss= 1689.87756 pca_loss= 587.52069 accuracy= 0.66012 accuracy_s= 0.79741 accuracy_f= 0.82228 time= 0.16473
Epoch: 0101 train_loss= 4180.24658 feature_loss= 13.28951 structure_loss= 1993.35437 proj_loss= 1601.06616 pca_loss= 572.53680 accuracy= 0.65634 accuracy_s= 0.79654 accuracy_f= 0.82228 time= 0.16514
Epoch: 0111 train_loss= 3532.59253 feature_loss= 13.20462 structure_loss= 1443.23096 proj_loss= 1516.18945 pca_loss= 559.96753 accuracy= 0.65430 accuracy_s= 0.79697 accuracy_f= 0.82257 time= 0.16444
Epoch: 0121 train_loss= 2989.22461 feature_loss= 13.13020 structure_loss= 991.16699 proj_loss= 1436.07007 pca_loss= 548.85730 accuracy= 0.64965 accuracy_s= 0.79610 accuracy_f= 0.82272 time= 0.16433
Epoch: 0131 train_loss= 2590.19678 feature_loss= 13.05995 structure_loss= 678.22321 proj_loss= 1361.24695 pca_loss= 537.66669 accuracy= 0.64500 accuracy_s= 0.79319 accuracy_f= 0.82257 time= 0.16347
Epoch: 0141 train_loss= 2282.32251 feature_loss= 12.99891 structure_loss= 452.05835 proj_loss= 1291.75659 pca_loss= 525.50873 accuracy= 0.64529 accuracy_s= 0.79159 accuracy_f= 0.82243 time= 0.16419
Epoch: 0151 train_loss= 2046.98193 feature_loss= 12.94902 structure_loss= 294.40335 proj_loss= 1227.32129 pca_loss= 512.30835 accuracy= 0.64165 accuracy_s= 0.79087 accuracy_f= 0.82243 time= 0.16466
Epoch: 0161 train_loss= 1850.87244 feature_loss= 12.90531 structure_loss= 172.71988 proj_loss= 1167.55200 pca_loss= 497.69519 accuracy= 0.64078 accuracy_s= 0.78869 accuracy_f= 0.82257 time= 0.16538
Epoch: 0171 train_loss= 1701.11499 feature_loss= 12.86700 structure_loss= 94.48909 proj_loss= 1111.97388 pca_loss= 481.78500 accuracy= 0.64500 accuracy_s= 0.78752 accuracy_f= 0.82243 time= 0.16357
Epoch: 0181 train_loss= 1594.69812 feature_loss= 12.83362 structure_loss= 56.92884 proj_loss= 1060.15637 pca_loss= 464.77933 accuracy= 0.64863 accuracy_s= 0.78723 accuracy_f= 0.82257 time= 0.16386
Epoch: 0191 train_loss= 1507.98926 feature_loss= 12.80463 structure_loss= 36.11205 proj_loss= 1011.71240 pca_loss= 447.36026 accuracy= 0.65329 accuracy_s= 0.78665 accuracy_f= 0.82257 time= 0.16498
Epoch: 0201 train_loss= 1434.29309 feature_loss= 12.77915 structure_loss= 25.17705 proj_loss= 966.37701 pca_loss= 429.95987 accuracy= 0.65794 accuracy_s= 0.78679 accuracy_f= 0.82257 time= 0.16545
Epoch: 0211 train_loss= 1367.40918 feature_loss= 12.75714 structure_loss= 17.74371 proj_loss= 923.82172 pca_loss= 413.08661 accuracy= 0.66347 accuracy_s= 0.78723 accuracy_f= 0.82257 time= 0.16402
Epoch: 0221 train_loss= 1306.20667 feature_loss= 12.73809 structure_loss= 12.69366 proj_loss= 883.84351 pca_loss= 396.93137 accuracy= 0.66914 accuracy_s= 0.78505 accuracy_f= 0.82257 time= 0.16491
Epoch: 0231 train_loss= 1247.03564 feature_loss= 12.72167 structure_loss= 6.58623 proj_loss= 846.24683 pca_loss= 381.48096 accuracy= 0.67437 accuracy_s= 0.78316 accuracy_f= 0.82243 time= 0.16365
Epoch: 0241 train_loss= 1195.25476 feature_loss= 12.70751 structure_loss= 5.16008 proj_loss= 810.75079 pca_loss= 366.63635 accuracy= 0.67656 accuracy_s= 0.78461 accuracy_f= 0.82257 time= 0.16379
Epoch: 0251 train_loss= 1146.79688 feature_loss= 12.69519 structure_loss= 4.43311 proj_loss= 777.15796 pca_loss= 352.51056 accuracy= 0.67670 accuracy_s= 0.78200 accuracy_f= 0.82243 time= 0.16515
Epoch: 0261 train_loss= 1100.33374 feature_loss= 12.68470 structure_loss= 3.24841 proj_loss= 745.42780 pca_loss= 338.97290 accuracy= 0.67670 accuracy_s= 0.78316 accuracy_f= 0.82243 time= 0.16575
Epoch: 0271 train_loss= 1055.79028 feature_loss= 12.67807 structure_loss= 1.53113 proj_loss= 715.41473 pca_loss= 326.16638 accuracy= 0.67714 accuracy_s= 0.78185 accuracy_f= 0.82243 time= 0.16487
Epoch: 0281 train_loss= 1014.64954 feature_loss= 12.66816 structure_loss= 0.96597 proj_loss= 686.92334 pca_loss= 314.09207 accuracy= 0.67699 accuracy_s= 0.78185 accuracy_f= 0.82257 time= 0.16540
Epoch: 0291 train_loss= 989.07043 feature_loss= 12.66121 structure_loss= 14.10531 proj_loss= 659.91107 pca_loss= 302.39279 accuracy= 0.67728 accuracy_s= 0.79741 accuracy_f= 0.82257 time= 0.16516

accuracy 0.67685
accuracy_s 0.78185
accuracy_f 0.82257
auc 0.49085
f1_score 0.25933
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 505
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6699314.50000 feature_loss= 22.23208 structure_loss= 6631.77979 proj_loss= 6688796.00000 pca_loss= 3864.53369 accuracy= 0.61867 accuracy_s= 0.78519 accuracy_f= 0.82359 time= 0.25384
Epoch: 0011 train_loss= 6283855.00000 feature_loss= 17.90605 structure_loss= 5173.45801 proj_loss= 6274999.00000 pca_loss= 3664.32300 accuracy= 0.61882 accuracy_s= 0.78636 accuracy_f= 0.83028 time= 0.18190
Epoch: 0021 train_loss= 5895749.00000 feature_loss= 16.43909 structure_loss= 4284.43359 proj_loss= 5887973.50000 pca_loss= 3474.59766 accuracy= 0.62071 accuracy_s= 0.78839 accuracy_f= 0.83013 time= 0.18159
Epoch: 0031 train_loss= 5535446.00000 feature_loss= 15.27911 structure_loss= 3632.44946 proj_loss= 5528510.00000 pca_loss= 3288.67456 accuracy= 0.62115 accuracy_s= 0.79029 accuracy_f= 0.82708 time= 0.18365
Epoch: 0041 train_loss= 5202195.50000 feature_loss= 14.71172 structure_loss= 3100.82300 proj_loss= 5195973.50000 pca_loss= 3106.73999 accuracy= 0.62362 accuracy_s= 0.79130 accuracy_f= 0.82213 time= 0.23727
Epoch: 0051 train_loss= 4894420.00000 feature_loss= 14.45408 structure_loss= 2658.86572 proj_loss= 4888817.00000 pca_loss= 2929.30029 accuracy= 0.62973 accuracy_s= 0.79276 accuracy_f= 0.82243 time= 0.20154
Epoch: 0061 train_loss= 4610322.50000 feature_loss= 14.27001 structure_loss= 2473.04102 proj_loss= 4605083.50000 pca_loss= 2751.64771 accuracy= 0.64761 accuracy_s= 0.79188 accuracy_f= 0.82243 time= 0.20157
Epoch: 0071 train_loss= 4347629.00000 feature_loss= 14.10304 structure_loss= 2299.13306 proj_loss= 4342738.50000 pca_loss= 2577.71240 accuracy= 0.63176 accuracy_s= 0.79072 accuracy_f= 0.82257 time= 0.19502
Epoch: 0081 train_loss= 4104439.75000 feature_loss= 13.95897 structure_loss= 2159.99316 proj_loss= 4099841.50000 pca_loss= 2424.32178 accuracy= 0.63903 accuracy_s= 0.79029 accuracy_f= 0.82257 time= 0.19515
Epoch: 0091 train_loss= 3878954.50000 feature_loss= 13.82971 structure_loss= 2034.75806 proj_loss= 3874637.00000 pca_loss= 2269.01978 accuracy= 0.63351 accuracy_s= 0.78927 accuracy_f= 0.82257 time= 0.20000
Epoch: 0101 train_loss= 3669597.00000 feature_loss= 13.71660 structure_loss= 1934.05212 proj_loss= 3665527.50000 pca_loss= 2121.76489 accuracy= 0.65081 accuracy_s= 0.78898 accuracy_f= 0.82257 time= 0.18853
Epoch: 0111 train_loss= 3474925.25000 feature_loss= 13.61709 structure_loss= 1840.10498 proj_loss= 3471089.25000 pca_loss= 1982.24219 accuracy= 0.65169 accuracy_s= 0.78883 accuracy_f= 0.82257 time= 0.18739
Epoch: 0121 train_loss= 3293669.50000 feature_loss= 13.52894 structure_loss= 1760.16699 proj_loss= 3290048.00000 pca_loss= 1847.68933 accuracy= 0.65750 accuracy_s= 0.78883 accuracy_f= 0.82257 time= 0.18255
Epoch: 0131 train_loss= 3124667.75000 feature_loss= 13.45110 structure_loss= 1674.51184 proj_loss= 3121263.25000 pca_loss= 1716.40820 accuracy= 0.65939 accuracy_s= 0.78869 accuracy_f= 0.82257 time= 0.18917
Epoch: 0141 train_loss= 2966902.25000 feature_loss= 13.38265 structure_loss= 1589.73889 proj_loss= 2963709.50000 pca_loss= 1589.82117 accuracy= 0.66347 accuracy_s= 0.78999 accuracy_f= 0.82272 time= 0.18470
Epoch: 0151 train_loss= 2819472.00000 feature_loss= 13.32182 structure_loss= 1524.83691 proj_loss= 2816464.00000 pca_loss= 1469.64807 accuracy= 0.66361 accuracy_s= 0.79232 accuracy_f= 0.82272 time= 0.18619
Epoch: 0161 train_loss= 2681511.00000 feature_loss= 13.27140 structure_loss= 1448.99536 proj_loss= 2678696.00000 pca_loss= 1352.63171 accuracy= 0.66361 accuracy_s= 0.79407 accuracy_f= 0.82257 time= 0.18782
Epoch: 0171 train_loss= 2552289.00000 feature_loss= 13.22427 structure_loss= 1379.89734 proj_loss= 2549654.50000 pca_loss= 1241.57617 accuracy= 0.66434 accuracy_s= 0.79319 accuracy_f= 0.82272 time= 0.18634
Epoch: 0181 train_loss= 2431124.25000 feature_loss= 13.18237 structure_loss= 1317.96313 proj_loss= 2428659.50000 pca_loss= 1133.61829 accuracy= 0.66449 accuracy_s= 0.79276 accuracy_f= 0.82272 time= 0.18978
Epoch: 0191 train_loss= 2317388.25000 feature_loss= 13.14445 structure_loss= 1250.64014 proj_loss= 2315093.00000 pca_loss= 1031.48645 accuracy= 0.66521 accuracy_s= 0.79378 accuracy_f= 0.82272 time= 0.19974
Epoch: 0201 train_loss= 2210521.75000 feature_loss= 13.11290 structure_loss= 1183.13757 proj_loss= 2208395.25000 pca_loss= 930.27490 accuracy= 0.66638 accuracy_s= 0.79465 accuracy_f= 0.82272 time= 0.19814
Epoch: 0211 train_loss= 2110030.25000 feature_loss= 13.08327 structure_loss= 1127.18384 proj_loss= 2108055.00000 pca_loss= 835.11273 accuracy= 0.66667 accuracy_s= 0.79436 accuracy_f= 0.82272 time= 0.19927
Epoch: 0221 train_loss= 2015425.25000 feature_loss= 13.06753 structure_loss= 1062.23560 proj_loss= 2013606.50000 pca_loss= 743.47052 accuracy= 0.66579 accuracy_s= 0.79596 accuracy_f= 0.82257 time= 0.20252
Epoch: 0231 train_loss= 1926292.87500 feature_loss= 13.04025 structure_loss= 999.66339 proj_loss= 1924627.50000 pca_loss= 652.56555 accuracy= 0.66667 accuracy_s= 0.79479 accuracy_f= 0.82272 time= 0.18082
Epoch: 0241 train_loss= 1842253.25000 feature_loss= 13.01412 structure_loss= 944.66919 proj_loss= 1840726.50000 pca_loss= 569.07227 accuracy= 0.66638 accuracy_s= 0.79538 accuracy_f= 0.82286 time= 0.20163
Epoch: 0251 train_loss= 1762937.50000 feature_loss= 12.96557 structure_loss= 889.99872 proj_loss= 1761548.37500 pca_loss= 486.16086 accuracy= 0.66667 accuracy_s= 0.79421 accuracy_f= 0.82286 time= 0.20103
Epoch: 0261 train_loss= 1688027.75000 feature_loss= 12.72834 structure_loss= 838.33905 proj_loss= 1686767.25000 pca_loss= 409.35529 accuracy= 0.66608 accuracy_s= 0.79319 accuracy_f= 0.82243 time= 0.18541
Epoch: 0271 train_loss= 1617196.25000 feature_loss= 12.71665 structure_loss= 769.26184 proj_loss= 1616082.37500 pca_loss= 331.83566 accuracy= 0.66638 accuracy_s= 0.79232 accuracy_f= 0.82243 time= 0.20822
Epoch: 0281 train_loss= 1550194.37500 feature_loss= 12.69848 structure_loss= 707.16791 proj_loss= 1549221.25000 pca_loss= 253.26941 accuracy= 0.66608 accuracy_s= 0.79508 accuracy_f= 0.82243 time= 0.19963
Epoch: 0291 train_loss= 1486751.00000 feature_loss= 12.68432 structure_loss= 632.37946 proj_loss= 1485929.25000 pca_loss= 176.61139 accuracy= 0.66579 accuracy_s= 0.79392 accuracy_f= 0.82257 time= 0.20251

accuracy 0.66638
accuracy_s 0.79465
accuracy_f 0.82257
auc 0.47265
f1_score 0.23533
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 382
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 2422.19336 reconstruction_loss= 28.00383 proj_loss= 679.57892 pca_loss= 1714.61072 accuracy= 0.64980 time= 0.14804
Epoch: 0011 train_loss= 2226.60205 reconstruction_loss= 21.58047 proj_loss= 651.29645 pca_loss= 1553.72510 accuracy= 0.67394 time= 0.08793
Epoch: 0021 train_loss= 2052.88940 reconstruction_loss= 18.61470 proj_loss= 623.98535 pca_loss= 1410.28943 accuracy= 0.67772 time= 0.09108
Epoch: 0031 train_loss= 1897.46497 reconstruction_loss= 16.69938 proj_loss= 597.52655 pca_loss= 1283.23901 accuracy= 0.67539 time= 0.08982
Epoch: 0041 train_loss= 1757.98010 reconstruction_loss= 15.35998 proj_loss= 571.98853 pca_loss= 1170.63159 accuracy= 0.67859 time= 0.08993
Epoch: 0051 train_loss= 1632.76733 reconstruction_loss= 14.76951 proj_loss= 547.47455 pca_loss= 1070.52332 accuracy= 0.67990 time= 0.09030
Epoch: 0061 train_loss= 1519.82349 reconstruction_loss= 14.38684 proj_loss= 524.04248 pca_loss= 981.39417 accuracy= 0.68252 time= 0.09061
Epoch: 0071 train_loss= 1418.03223 reconstruction_loss= 14.14037 proj_loss= 501.67120 pca_loss= 902.22064 accuracy= 0.68412 time= 0.09101
Epoch: 0081 train_loss= 1326.52344 reconstruction_loss= 13.92660 proj_loss= 480.27621 pca_loss= 832.32056 accuracy= 0.68528 time= 0.09163
Epoch: 0091 train_loss= 1244.60327 reconstruction_loss= 13.74309 proj_loss= 459.75388 pca_loss= 771.10632 accuracy= 0.68688 time= 0.08941
Epoch: 0101 train_loss= 1171.49426 reconstruction_loss= 13.58231 proj_loss= 440.02188 pca_loss= 717.89008 accuracy= 0.68674 time= 0.09970
Epoch: 0111 train_loss= 1106.24878 reconstruction_loss= 13.41379 proj_loss= 421.03497 pca_loss= 671.80005 accuracy= 0.68674 time= 0.10088
Epoch: 0121 train_loss= 1047.85144 reconstruction_loss= 13.26965 proj_loss= 402.78348 pca_loss= 631.79834 accuracy= 0.68775 time= 0.09296
Epoch: 0131 train_loss= 995.21539 reconstruction_loss= 13.14709 proj_loss= 385.28052 pca_loss= 596.78778 accuracy= 0.68761 time= 0.09167
Epoch: 0141 train_loss= 947.33264 reconstruction_loss= 13.03611 proj_loss= 368.54630 pca_loss= 565.75024 accuracy= 0.68950 time= 0.09205
Epoch: 0151 train_loss= 903.37683 reconstruction_loss= 12.93681 proj_loss= 352.59686 pca_loss= 537.84320 accuracy= 0.69081 time= 0.08966
Epoch: 0161 train_loss= 862.71100 reconstruction_loss= 12.84838 proj_loss= 337.43652 pca_loss= 512.42609 accuracy= 0.69124 time= 0.09222
Epoch: 0171 train_loss= 824.85571 reconstruction_loss= 12.76456 proj_loss= 323.05508 pca_loss= 489.03604 accuracy= 0.69372 time= 0.08996
Epoch: 0181 train_loss= 789.46106 reconstruction_loss= 12.68881 proj_loss= 309.42862 pca_loss= 467.34360 accuracy= 0.69459 time= 0.09029
Epoch: 0191 train_loss= 756.25146 reconstruction_loss= 12.61706 proj_loss= 296.52374 pca_loss= 447.11063 accuracy= 0.69634 time= 0.09131
Epoch: 0201 train_loss= 725.01050 reconstruction_loss= 12.54914 proj_loss= 284.30194 pca_loss= 428.15942 accuracy= 0.69648 time= 0.09239
Epoch: 0211 train_loss= 695.56555 reconstruction_loss= 12.49000 proj_loss= 272.72311 pca_loss= 410.35248 accuracy= 0.69721 time= 0.09211
Epoch: 0221 train_loss= 667.76233 reconstruction_loss= 12.43487 proj_loss= 261.74783 pca_loss= 393.57965 accuracy= 0.70026 time= 0.09239
Epoch: 0231 train_loss= 641.46930 reconstruction_loss= 12.38081 proj_loss= 251.33820 pca_loss= 377.75031 accuracy= 0.69953 time= 0.09021
Epoch: 0241 train_loss= 616.58167 reconstruction_loss= 12.33543 proj_loss= 241.45848 pca_loss= 362.78775 accuracy= 0.70026 time= 0.09572
Epoch: 0251 train_loss= 592.99512 reconstruction_loss= 12.29353 proj_loss= 232.07541 pca_loss= 348.62619 accuracy= 0.69939 time= 0.10296
Epoch: 0261 train_loss= 570.61682 reconstruction_loss= 12.25087 proj_loss= 223.15811 pca_loss= 335.20782 accuracy= 0.70259 time= 0.09183
Epoch: 0271 train_loss= 549.37134 reconstruction_loss= 12.21178 proj_loss= 214.67769 pca_loss= 322.48184 accuracy= 0.70404 time= 0.10197
Epoch: 0281 train_loss= 529.19189 reconstruction_loss= 12.18182 proj_loss= 206.60738 pca_loss= 310.40268 accuracy= 0.70462 time= 0.09941
Epoch: 0291 train_loss= 509.99710 reconstruction_loss= 12.14543 proj_loss= 198.92256 pca_loss= 298.92911 accuracy= 0.70593 time= 0.10374

accuracy 0.70666
auc 0.57173
f1_score 0.32767
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 266
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 1330545.62500 reconstruction_loss= 22.22131 proj_loss= 1320807.62500 pca_loss= 9715.79785 accuracy= 0.66376 time= 0.14025
Epoch: 0011 train_loss= 1247013.12500 reconstruction_loss= 17.37228 proj_loss= 1239711.87500 pca_loss= 7283.89746 accuracy= 0.67001 time= 0.11130
Epoch: 0021 train_loss= 1168890.37500 reconstruction_loss= 16.16833 proj_loss= 1163855.75000 pca_loss= 5018.55078 accuracy= 0.67248 time= 0.11145
Epoch: 0031 train_loss= 1096327.00000 reconstruction_loss= 15.34746 proj_loss= 1093372.37500 pca_loss= 2939.28613 accuracy= 0.67379 time= 0.11542
Epoch: 0041 train_loss= 1029203.68750 reconstruction_loss= 14.65342 proj_loss= 1028107.93750 pca_loss= 1081.13391 accuracy= 0.67830 time= 0.11398
Epoch: 0051 train_loss= 967990.06250 reconstruction_loss= 14.37759 proj_loss= 967372.75000 pca_loss= 602.94843 accuracy= 0.68077 time= 0.11231
Epoch: 0061 train_loss= 911680.68750 reconstruction_loss= 14.15829 proj_loss= 911163.37500 pca_loss= 503.13608 accuracy= 0.68034 time= 0.11229
Epoch: 0071 train_loss= 859702.06250 reconstruction_loss= 13.95592 proj_loss= 859251.56250 pca_loss= 436.54929 accuracy= 0.67946 time= 0.11281
Epoch: 0081 train_loss= 811651.50000 reconstruction_loss= 13.77750 proj_loss= 811227.25000 pca_loss= 410.47995 accuracy= 0.67946 time= 0.11183
Epoch: 0091 train_loss= 767112.00000 reconstruction_loss= 13.61983 proj_loss= 766706.56250 pca_loss= 391.78790 accuracy= 0.67946 time= 0.11542
Epoch: 0101 train_loss= 725769.43750 reconstruction_loss= 13.47194 proj_loss= 725376.31250 pca_loss= 379.64224 accuracy= 0.67946 time= 0.11260
Epoch: 0111 train_loss= 687327.12500 reconstruction_loss= 13.34268 proj_loss= 686945.68750 pca_loss= 368.14276 accuracy= 0.67917 time= 0.11357
Epoch: 0121 train_loss= 651529.25000 reconstruction_loss= 13.22558 proj_loss= 651157.25000 pca_loss= 358.74011 accuracy= 0.67946 time= 0.11305
Epoch: 0131 train_loss= 618148.43750 reconstruction_loss= 13.11919 proj_loss= 617786.31250 pca_loss= 348.99152 accuracy= 0.68092 time= 0.12656
Epoch: 0141 train_loss= 586982.62500 reconstruction_loss= 13.02303 proj_loss= 586629.18750 pca_loss= 340.41037 accuracy= 0.68194 time= 0.11633
Epoch: 0151 train_loss= 557850.00000 reconstruction_loss= 12.93829 proj_loss= 557505.00000 pca_loss= 332.06409 accuracy= 0.68281 time= 0.12201
Epoch: 0161 train_loss= 530587.18750 reconstruction_loss= 12.86161 proj_loss= 530250.25000 pca_loss= 324.04071 accuracy= 0.68296 time= 0.11414
Epoch: 0171 train_loss= 505046.65625 reconstruction_loss= 12.79623 proj_loss= 504717.31250 pca_loss= 316.56335 accuracy= 0.68310 time= 0.11965
Epoch: 0181 train_loss= 481094.84375 reconstruction_loss= 12.72865 proj_loss= 480773.09375 pca_loss= 309.03036 accuracy= 0.68281 time= 0.11714
Epoch: 0191 train_loss= 458610.43750 reconstruction_loss= 12.67317 proj_loss= 458295.75000 pca_loss= 302.00339 accuracy= 0.68426 time= 0.11731
Epoch: 0201 train_loss= 437483.06250 reconstruction_loss= 12.62014 proj_loss= 437175.25000 pca_loss= 295.18475 accuracy= 0.68441 time= 0.12008
Epoch: 0211 train_loss= 417612.25000 reconstruction_loss= 12.57689 proj_loss= 417310.93750 pca_loss= 288.74240 accuracy= 0.68586 time= 0.11660
Epoch: 0221 train_loss= 398906.31250 reconstruction_loss= 12.53544 proj_loss= 398611.59375 pca_loss= 282.19150 accuracy= 0.68455 time= 0.11610
Epoch: 0231 train_loss= 381281.78125 reconstruction_loss= 12.51912 proj_loss= 380993.15625 pca_loss= 276.08600 accuracy= 0.68819 time= 0.11509
Epoch: 0241 train_loss= 364661.75000 reconstruction_loss= 12.47374 proj_loss= 364379.18750 pca_loss= 270.09509 accuracy= 0.68499 time= 0.11289
Epoch: 0251 train_loss= 348976.25000 reconstruction_loss= 12.43104 proj_loss= 348699.31250 pca_loss= 264.50922 accuracy= 0.68892 time= 0.11290
Epoch: 0261 train_loss= 334160.71875 reconstruction_loss= 12.39953 proj_loss= 333889.31250 pca_loss= 258.99020 accuracy= 0.68834 time= 0.11214
Epoch: 0271 train_loss= 320156.06250 reconstruction_loss= 12.37827 proj_loss= 319890.12500 pca_loss= 253.57646 accuracy= 0.69299 time= 0.11278
Epoch: 0281 train_loss= 306908.15625 reconstruction_loss= 12.35506 proj_loss= 306647.25000 pca_loss= 248.56604 accuracy= 0.69401 time= 0.11186
Epoch: 0291 train_loss= 294366.43750 reconstruction_loss= 12.34506 proj_loss= 294110.71875 pca_loss= 243.36943 accuracy= 0.69561 time= 0.12287

accuracy 0.69139
auc 0.55520
f1_score 0.29267
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 513
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 12815.74902 reconstruction_loss= 10350.48145 proj_loss= 693.93158 pca_loss= 1771.33606 accuracy= 0.63104 time= 0.13566
Epoch: 0011 train_loss= 8198.93164 reconstruction_loss= 5884.08154 proj_loss= 682.25580 pca_loss= 1632.59436 accuracy= 0.63787 time= 0.08539
Epoch: 0021 train_loss= 6910.34180 reconstruction_loss= 4738.98145 proj_loss= 668.51343 pca_loss= 1502.84644 accuracy= 0.64761 time= 0.08511
Epoch: 0031 train_loss= 6074.11816 reconstruction_loss= 4036.72827 proj_loss= 651.80121 pca_loss= 1385.58875 accuracy= 0.65038 time= 0.08460
Epoch: 0041 train_loss= 5411.83594 reconstruction_loss= 3498.45337 proj_loss= 633.30298 pca_loss= 1280.07971 accuracy= 0.65663 time= 0.08448
Epoch: 0051 train_loss= 4803.54346 reconstruction_loss= 3003.47485 proj_loss= 614.02136 pca_loss= 1186.04749 accuracy= 0.66434 time= 0.08376
Epoch: 0061 train_loss= 4218.88086 reconstruction_loss= 2521.59766 proj_loss= 594.45282 pca_loss= 1102.83008 accuracy= 0.66943 time= 0.08573
Epoch: 0071 train_loss= 3638.28955 reconstruction_loss= 2033.93970 proj_loss= 574.82281 pca_loss= 1029.52698 accuracy= 0.67554 time= 0.08624
Epoch: 0081 train_loss= 3102.45386 reconstruction_loss= 1582.74414 proj_loss= 555.16608 pca_loss= 964.54370 accuracy= 0.67685 time= 0.08238
Epoch: 0091 train_loss= 2651.69678 reconstruction_loss= 1209.81592 proj_loss= 535.61957 pca_loss= 906.26111 accuracy= 0.66987 time= 0.09440
Epoch: 0101 train_loss= 2308.14258 reconstruction_loss= 937.82318 proj_loss= 516.31915 pca_loss= 854.00031 accuracy= 0.66652 time= 0.09448
Epoch: 0111 train_loss= 2036.97070 reconstruction_loss= 731.57672 proj_loss= 497.44086 pca_loss= 807.95306 accuracy= 0.66739 time= 0.09540
Epoch: 0121 train_loss= 1837.52246 reconstruction_loss= 591.18719 proj_loss= 479.14584 pca_loss= 767.18939 accuracy= 0.66623 time= 0.08466
Epoch: 0131 train_loss= 1677.42798 reconstruction_loss= 484.82111 proj_loss= 461.39197 pca_loss= 731.21490 accuracy= 0.65780 time= 0.08187
Epoch: 0141 train_loss= 1547.57178 reconstruction_loss= 404.01791 proj_loss= 444.18228 pca_loss= 699.37164 accuracy= 0.65285 time= 0.09727
Epoch: 0151 train_loss= 1432.31787 reconstruction_loss= 333.96219 proj_loss= 427.57477 pca_loss= 670.78088 accuracy= 0.64383 time= 0.09496
Epoch: 0161 train_loss= 1313.39014 reconstruction_loss= 256.51596 proj_loss= 411.52414 pca_loss= 645.35010 accuracy= 0.64980 time= 0.09157
Epoch: 0171 train_loss= 1213.33276 reconstruction_loss= 195.23225 proj_loss= 396.13727 pca_loss= 621.96326 accuracy= 0.64136 time= 0.08225
Epoch: 0181 train_loss= 1129.06128 reconstruction_loss= 147.60912 proj_loss= 381.48004 pca_loss= 599.97211 accuracy= 0.64689 time= 0.08192
Epoch: 0191 train_loss= 1060.62122 reconstruction_loss= 114.45121 proj_loss= 367.55835 pca_loss= 578.61169 accuracy= 0.64034 time= 0.09885
Epoch: 0201 train_loss= 1000.07056 reconstruction_loss= 87.91405 proj_loss= 354.34460 pca_loss= 557.81189 accuracy= 0.63045 time= 0.09998
Epoch: 0211 train_loss= 955.43414 reconstruction_loss= 75.97633 proj_loss= 341.78796 pca_loss= 537.66986 accuracy= 0.61838 time= 0.08310
Epoch: 0221 train_loss= 907.94104 reconstruction_loss= 59.69387 proj_loss= 329.83282 pca_loss= 518.41431 accuracy= 0.63322 time= 0.09957
Epoch: 0231 train_loss= 866.25867 reconstruction_loss= 47.80594 proj_loss= 318.44278 pca_loss= 500.00998 accuracy= 0.62711 time= 0.09631
Epoch: 0241 train_loss= 831.98419 reconstruction_loss= 42.09144 proj_loss= 307.55264 pca_loss= 482.34012 accuracy= 0.61926 time= 0.09886
Epoch: 0251 train_loss= 800.71985 reconstruction_loss= 38.13232 proj_loss= 297.13989 pca_loss= 465.44763 accuracy= 0.62056 time= 0.08235
Epoch: 0261 train_loss= 770.04535 reconstruction_loss= 33.56378 proj_loss= 287.17200 pca_loss= 449.30957 accuracy= 0.61373 time= 0.08190
Epoch: 0271 train_loss= 738.12720 reconstruction_loss= 26.48378 proj_loss= 277.60037 pca_loss= 434.04303 accuracy= 0.61446 time= 0.09390
Epoch: 0281 train_loss= 710.62830 reconstruction_loss= 22.71750 proj_loss= 268.41907 pca_loss= 419.49173 accuracy= 0.61417 time= 0.09495
Epoch: 0291 train_loss= 686.42157 reconstruction_loss= 21.31088 proj_loss= 259.61765 pca_loss= 405.49304 accuracy= 0.61664 time= 0.09512

accuracy 0.61460
auc 0.35292
f1_score 0.11667
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.1, weight_decay=0.0005)
random seed: 898
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 76 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 1332612.25000 reconstruction_loss= 6282.36816 proj_loss= 1316840.25000 pca_loss= 9489.56543 accuracy= 0.61649 time= 0.12955
Epoch: 0011 train_loss= 1246978.37500 reconstruction_loss= 3987.65356 proj_loss= 1235970.50000 pca_loss= 7020.26807 accuracy= 0.62115 time= 0.10489
Epoch: 0021 train_loss= 1168061.25000 reconstruction_loss= 3001.61182 proj_loss= 1160282.75000 pca_loss= 4776.91748 accuracy= 0.62245 time= 0.10392
Epoch: 0031 train_loss= 1094976.37500 reconstruction_loss= 2271.96924 proj_loss= 1089920.12500 pca_loss= 2784.28394 accuracy= 0.62013 time= 0.10556
Epoch: 0041 train_loss= 1027583.50000 reconstruction_loss= 1744.40820 proj_loss= 1024687.12500 pca_loss= 1151.96375 accuracy= 0.62565 time= 0.10367
Epoch: 0051 train_loss= 966200.62500 reconstruction_loss= 1656.20654 proj_loss= 964064.31250 pca_loss= 480.09628 accuracy= 0.63264 time= 0.10423
Epoch: 0061 train_loss= 909865.31250 reconstruction_loss= 1436.42969 proj_loss= 907994.93750 pca_loss= 433.94791 accuracy= 0.63540 time= 0.10439
Epoch: 0071 train_loss= 857937.50000 reconstruction_loss= 1288.20996 proj_loss= 856201.43750 pca_loss= 447.87189 accuracy= 0.63176 time= 0.10372
Epoch: 0081 train_loss= 809895.50000 reconstruction_loss= 1182.68140 proj_loss= 808300.31250 pca_loss= 412.47488 accuracy= 0.64369 time= 0.10336
Epoch: 0091 train_loss= 765384.56250 reconstruction_loss= 1098.70337 proj_loss= 763897.93750 pca_loss= 387.95523 accuracy= 0.64369 time= 0.10339
Epoch: 0101 train_loss= 724073.25000 reconstruction_loss= 1022.28015 proj_loss= 722672.31250 pca_loss= 378.69818 accuracy= 0.64660 time= 0.10492
Epoch: 0111 train_loss= 685667.12500 reconstruction_loss= 955.59998 proj_loss= 684346.12500 pca_loss= 365.34396 accuracy= 0.64412 time= 0.10354
Epoch: 0121 train_loss= 649908.00000 reconstruction_loss= 893.52258 proj_loss= 648657.18750 pca_loss= 357.31146 accuracy= 0.64936 time= 0.10358
Epoch: 0131 train_loss= 616562.50000 reconstruction_loss= 830.25482 proj_loss= 615382.68750 pca_loss= 349.53253 accuracy= 0.64282 time= 0.10452
Epoch: 0141 train_loss= 585445.81250 reconstruction_loss= 784.60748 proj_loss= 584319.43750 pca_loss= 341.71970 accuracy= 0.64558 time= 0.10324
Epoch: 0151 train_loss= 556372.87500 reconstruction_loss= 738.84991 proj_loss= 555293.93750 pca_loss= 340.06168 accuracy= 0.64587 time= 0.10352
Epoch: 0161 train_loss= 529161.62500 reconstruction_loss= 697.36407 proj_loss= 528139.93750 pca_loss= 324.32230 accuracy= 0.64514 time= 0.10728
Epoch: 0171 train_loss= 503680.53125 reconstruction_loss= 655.32776 proj_loss= 502705.90625 pca_loss= 319.32150 accuracy= 0.64863 time= 0.10400
Epoch: 0181 train_loss= 479790.18750 reconstruction_loss= 620.11389 proj_loss= 478856.21875 pca_loss= 313.84070 accuracy= 0.65169 time= 0.10458
Epoch: 0191 train_loss= 457366.43750 reconstruction_loss= 593.80939 proj_loss= 456471.53125 pca_loss= 301.08752 accuracy= 0.65052 time= 0.10510
Epoch: 0201 train_loss= 436304.78125 reconstruction_loss= 564.71106 proj_loss= 435439.78125 pca_loss= 300.28442 accuracy= 0.65460 time= 0.11737
Epoch: 0211 train_loss= 416471.18750 reconstruction_loss= 521.34625 proj_loss= 415661.03125 pca_loss= 288.82239 accuracy= 0.64703 time= 0.12477
Epoch: 0221 train_loss= 397823.31250 reconstruction_loss= 499.45428 proj_loss= 397041.62500 pca_loss= 282.23032 accuracy= 0.64369 time= 0.14292
Epoch: 0231 train_loss= 380250.43750 reconstruction_loss= 476.75861 proj_loss= 379497.84375 pca_loss= 275.85806 accuracy= 0.64645 time= 0.11697
Epoch: 0241 train_loss= 363677.65625 reconstruction_loss= 452.05829 proj_loss= 362953.68750 pca_loss= 271.89746 accuracy= 0.65140 time= 0.12771
Epoch: 0251 train_loss= 348031.93750 reconstruction_loss= 428.54117 proj_loss= 347339.53125 pca_loss= 263.88907 accuracy= 0.64311 time= 0.12930
Epoch: 0261 train_loss= 333261.09375 reconstruction_loss= 410.54163 proj_loss= 332591.15625 pca_loss= 259.41782 accuracy= 0.64936 time= 0.10809
Epoch: 0271 train_loss= 319290.46875 reconstruction_loss= 387.38126 proj_loss= 318649.96875 pca_loss= 253.11778 accuracy= 0.64151 time= 0.10544
Epoch: 0281 train_loss= 306077.78125 reconstruction_loss= 368.18924 proj_loss= 305461.40625 pca_loss= 248.19591 accuracy= 0.64471 time= 0.11855
Epoch: 0291 train_loss= 293571.31250 reconstruction_loss= 353.17532 proj_loss= 292975.40625 pca_loss= 242.73343 accuracy= 0.64878 time= 0.10737

accuracy 0.64020
auc 0.45992
f1_score 0.17533
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 841
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 3129.65845 reconstruction_loss= 28.02546 proj_loss= 2525.98828 pca_loss= 575.64471 accuracy= 0.64878 time= 0.13187
Epoch: 0011 train_loss= 2934.03223 reconstruction_loss= 22.72154 proj_loss= 2367.31787 pca_loss= 543.99292 accuracy= 0.66943 time= 0.11282
Epoch: 0021 train_loss= 2753.95361 reconstruction_loss= 20.40191 proj_loss= 2219.15088 pca_loss= 514.40082 accuracy= 0.67481 time= 0.08898
Epoch: 0031 train_loss= 2586.98438 reconstruction_loss= 18.37602 proj_loss= 2081.85376 pca_loss= 486.75467 accuracy= 0.68412 time= 0.09986
Epoch: 0041 train_loss= 2433.19531 reconstruction_loss= 17.08134 proj_loss= 1955.15710 pca_loss= 460.95682 accuracy= 0.68426 time= 0.08856
Epoch: 0051 train_loss= 2290.89136 reconstruction_loss= 15.61234 proj_loss= 1838.34558 pca_loss= 436.93353 accuracy= 0.68179 time= 0.08822
Epoch: 0061 train_loss= 2159.52515 reconstruction_loss= 14.36803 proj_loss= 1730.59509 pca_loss= 414.56198 accuracy= 0.67888 time= 0.10144
Epoch: 0071 train_loss= 2038.73523 reconstruction_loss= 13.94959 proj_loss= 1631.05652 pca_loss= 393.72916 accuracy= 0.67772 time= 0.09802
Epoch: 0081 train_loss= 1926.79443 reconstruction_loss= 13.52612 proj_loss= 1538.97888 pca_loss= 374.28940 accuracy= 0.67816 time= 0.09034
Epoch: 0091 train_loss= 1823.17554 reconstruction_loss= 13.38409 proj_loss= 1453.68286 pca_loss= 356.10861 accuracy= 0.67801 time= 0.08968
Epoch: 0101 train_loss= 1726.90698 reconstruction_loss= 13.28367 proj_loss= 1374.54846 pca_loss= 339.07489 accuracy= 0.67801 time= 0.09959
Epoch: 0111 train_loss= 1637.30957 reconstruction_loss= 13.19782 proj_loss= 1301.00891 pca_loss= 323.10272 accuracy= 0.67816 time= 0.10555
Epoch: 0121 train_loss= 1553.79321 reconstruction_loss= 13.11995 proj_loss= 1232.57178 pca_loss= 308.10144 accuracy= 0.67816 time= 0.08678
Epoch: 0131 train_loss= 1475.84106 reconstruction_loss= 13.05380 proj_loss= 1168.79578 pca_loss= 293.99152 accuracy= 0.67816 time= 0.10161
Epoch: 0141 train_loss= 1402.97290 reconstruction_loss= 12.98705 proj_loss= 1109.28882 pca_loss= 280.69705 accuracy= 0.67816 time= 0.09466
Epoch: 0151 train_loss= 1334.78809 reconstruction_loss= 12.93870 proj_loss= 1053.69678 pca_loss= 268.15265 accuracy= 0.67801 time= 0.10178
Epoch: 0161 train_loss= 1270.89551 reconstruction_loss= 12.89581 proj_loss= 1001.70129 pca_loss= 256.29843 accuracy= 0.67816 time= 0.08819
Epoch: 0171 train_loss= 1210.95337 reconstruction_loss= 12.85851 proj_loss= 953.01392 pca_loss= 245.08087 accuracy= 0.67816 time= 0.08894
Epoch: 0181 train_loss= 1154.65515 reconstruction_loss= 12.82915 proj_loss= 907.37903 pca_loss= 234.44701 accuracy= 0.67801 time= 0.10207
Epoch: 0191 train_loss= 1101.71082 reconstruction_loss= 12.79768 proj_loss= 864.55884 pca_loss= 224.35435 accuracy= 0.67801 time= 0.10105
Epoch: 0201 train_loss= 1051.88159 reconstruction_loss= 12.77894 proj_loss= 824.34143 pca_loss= 214.76122 accuracy= 0.67801 time= 0.10228
Epoch: 0211 train_loss= 1004.91467 reconstruction_loss= 12.75175 proj_loss= 786.53271 pca_loss= 205.63020 accuracy= 0.67801 time= 0.08867
Epoch: 0221 train_loss= 960.61768 reconstruction_loss= 12.73330 proj_loss= 750.95667 pca_loss= 196.92770 accuracy= 0.67787 time= 0.10209
Epoch: 0231 train_loss= 918.79266 reconstruction_loss= 12.71736 proj_loss= 717.45264 pca_loss= 188.62268 accuracy= 0.67787 time= 0.10186
Epoch: 0241 train_loss= 879.26489 reconstruction_loss= 12.70363 proj_loss= 685.87347 pca_loss= 180.68781 accuracy= 0.67787 time= 0.09674
Epoch: 0251 train_loss= 841.87891 reconstruction_loss= 12.69577 proj_loss= 656.08453 pca_loss= 173.09862 accuracy= 0.67801 time= 0.08744
Epoch: 0261 train_loss= 806.47668 reconstruction_loss= 12.68169 proj_loss= 627.96375 pca_loss= 165.83124 accuracy= 0.67787 time= 0.10110
Epoch: 0271 train_loss= 772.93799 reconstruction_loss= 12.67391 proj_loss= 601.39655 pca_loss= 158.86755 accuracy= 0.67787 time= 0.08948
Epoch: 0281 train_loss= 741.13818 reconstruction_loss= 12.66904 proj_loss= 576.27893 pca_loss= 152.19019 accuracy= 0.67801 time= 0.09875
Epoch: 0291 train_loss= 710.95795 reconstruction_loss= 12.65940 proj_loss= 552.51886 pca_loss= 145.77965 accuracy= 0.67816 time= 0.08884

accuracy 0.67816
auc 0.49439
f1_score 0.26233
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 845
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6604909.50000 reconstruction_loss= 22.33149 proj_loss= 6600061.50000 pca_loss= 4825.40967 accuracy= 0.66434 time= 0.13086
Epoch: 0011 train_loss= 6195325.00000 reconstruction_loss= 17.89523 proj_loss= 6190756.00000 pca_loss= 4551.04053 accuracy= 0.66798 time= 0.10695
Epoch: 0021 train_loss= 5812311.50000 reconstruction_loss= 16.39721 proj_loss= 5808012.00000 pca_loss= 4282.93262 accuracy= 0.67379 time= 0.10347
Epoch: 0031 train_loss= 5456635.00000 reconstruction_loss= 15.42447 proj_loss= 5452596.00000 pca_loss= 4023.64233 accuracy= 0.67685 time= 0.10246
Epoch: 0041 train_loss= 5127657.50000 reconstruction_loss= 14.69056 proj_loss= 5123869.50000 pca_loss= 3773.61108 accuracy= 0.68048 time= 0.10396
Epoch: 0051 train_loss= 4823838.00000 reconstruction_loss= 14.24328 proj_loss= 4820291.00000 pca_loss= 3533.09497 accuracy= 0.67830 time= 0.10601
Epoch: 0061 train_loss= 4543228.50000 reconstruction_loss= 14.05967 proj_loss= 4539913.00000 pca_loss= 3301.60864 accuracy= 0.67801 time= 0.10290
Epoch: 0071 train_loss= 4283812.50000 reconstruction_loss= 13.89330 proj_loss= 4280719.50000 pca_loss= 3079.16528 accuracy= 0.67801 time= 0.11399
Epoch: 0081 train_loss= 4043669.75000 reconstruction_loss= 13.66062 proj_loss= 4040790.25000 pca_loss= 2865.75293 accuracy= 0.67801 time= 0.10232
Epoch: 0091 train_loss= 3821046.00000 reconstruction_loss= 13.40380 proj_loss= 3818371.50000 pca_loss= 2660.90112 accuracy= 0.67801 time= 0.10951
Epoch: 0101 train_loss= 3614360.50000 reconstruction_loss= 13.29057 proj_loss= 3611883.00000 pca_loss= 2464.30518 accuracy= 0.67801 time= 0.10248
Epoch: 0111 train_loss= 3422202.75000 reconstruction_loss= 13.19822 proj_loss= 3419913.75000 pca_loss= 2275.64429 accuracy= 0.67801 time= 0.10251
Epoch: 0121 train_loss= 3243305.25000 reconstruction_loss= 13.12374 proj_loss= 3241197.75000 pca_loss= 2094.53247 accuracy= 0.67816 time= 0.10204
Epoch: 0131 train_loss= 3076539.00000 reconstruction_loss= 13.05830 proj_loss= 3074605.25000 pca_loss= 1920.65186 accuracy= 0.67816 time= 0.10194
Epoch: 0141 train_loss= 2920886.00000 reconstruction_loss= 13.00086 proj_loss= 2919119.25000 pca_loss= 1753.70386 accuracy= 0.67816 time= 0.10281
Epoch: 0151 train_loss= 2775433.25000 reconstruction_loss= 12.95053 proj_loss= 2773826.75000 pca_loss= 1593.42969 accuracy= 0.67816 time= 0.10305
Epoch: 0161 train_loss= 2639356.25000 reconstruction_loss= 12.90649 proj_loss= 2637903.75000 pca_loss= 1439.56250 accuracy= 0.67801 time= 0.10230
Epoch: 0171 train_loss= 2511911.25000 reconstruction_loss= 12.86802 proj_loss= 2510606.75000 pca_loss= 1291.83435 accuracy= 0.67816 time= 0.10264
Epoch: 0181 train_loss= 2392424.75000 reconstruction_loss= 12.83447 proj_loss= 2391262.00000 pca_loss= 1149.99915 accuracy= 0.67801 time= 0.10217
Epoch: 0191 train_loss= 2280285.00000 reconstruction_loss= 12.80526 proj_loss= 2279258.50000 pca_loss= 1013.82678 accuracy= 0.67801 time= 0.10284
Epoch: 0201 train_loss= 2174937.00000 reconstruction_loss= 12.77988 proj_loss= 2174041.25000 pca_loss= 883.11188 accuracy= 0.67801 time= 0.10263
Epoch: 0211 train_loss= 2075875.75000 reconstruction_loss= 12.75784 proj_loss= 2075105.37500 pca_loss= 757.67432 accuracy= 0.67801 time= 0.10255
Epoch: 0221 train_loss= 1982640.12500 reconstruction_loss= 12.74018 proj_loss= 1981990.00000 pca_loss= 637.37286 accuracy= 0.67772 time= 0.10306
Epoch: 0231 train_loss= 1894809.25000 reconstruction_loss= 12.72226 proj_loss= 1894274.37500 pca_loss= 522.12897 accuracy= 0.67787 time= 0.10447
Epoch: 0241 train_loss= 1811999.00000 reconstruction_loss= 12.70801 proj_loss= 1811574.25000 pca_loss= 411.97598 accuracy= 0.67787 time= 0.10287
Epoch: 0251 train_loss= 1733856.87500 reconstruction_loss= 12.70039 proj_loss= 1733536.87500 pca_loss= 307.28070 accuracy= 0.67787 time= 0.10363
Epoch: 0261 train_loss= 1660061.25000 reconstruction_loss= 12.68521 proj_loss= 1659839.00000 pca_loss= 209.59734 accuracy= 0.67787 time= 0.10329
Epoch: 0271 train_loss= 1590318.50000 reconstruction_loss= 12.67612 proj_loss= 1590175.00000 pca_loss= 130.84602 accuracy= 0.67787 time= 0.10315
Epoch: 0281 train_loss= 1524364.00000 reconstruction_loss= 12.67037 proj_loss= 1524230.25000 pca_loss= 121.15776 accuracy= 0.67787 time= 0.10296
Epoch: 0291 train_loss= 1461941.50000 reconstruction_loss= 12.66293 proj_loss= 1461812.37500 pca_loss= 116.52672 accuracy= 0.67816 time= 0.10165

accuracy 0.67816
auc 0.49442
f1_score 0.26233
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 279
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([13752, 191]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 14176.26953 reconstruction_loss= 10886.79395 proj_loss= 2542.83057 pca_loss= 746.64447 accuracy= 0.63307 time= 0.14224
Epoch: 0011 train_loss= 11118.41113 reconstruction_loss= 7996.87549 proj_loss= 2409.82422 pca_loss= 711.71161 accuracy= 0.63104 time= 0.08462
Epoch: 0021 train_loss= 9758.98047 reconstruction_loss= 6796.95215 proj_loss= 2282.26294 pca_loss= 679.76605 accuracy= 0.63656 time= 0.08439
Epoch: 0031 train_loss= 8867.16895 reconstruction_loss= 6059.82422 proj_loss= 2157.65210 pca_loss= 649.69232 accuracy= 0.64558 time= 0.08378
Epoch: 0041 train_loss= 8161.16357 reconstruction_loss= 5502.52734 proj_loss= 2036.97510 pca_loss= 621.66119 accuracy= 0.65314 time= 0.09216
Epoch: 0051 train_loss= 7542.65723 reconstruction_loss= 5023.83838 proj_loss= 1923.07788 pca_loss= 595.74146 accuracy= 0.66027 time= 0.08406
Epoch: 0061 train_loss= 6963.59277 reconstruction_loss= 4574.66748 proj_loss= 1817.18909 pca_loss= 571.73651 accuracy= 0.66259 time= 0.08514
Epoch: 0071 train_loss= 6364.86572 reconstruction_loss= 4095.87866 proj_loss= 1719.13989 pca_loss= 549.84717 accuracy= 0.66318 time= 0.08524
Epoch: 0081 train_loss= 5658.28906 reconstruction_loss= 3499.26929 proj_loss= 1628.41321 pca_loss= 530.60645 accuracy= 0.66434 time= 0.09242
Epoch: 0091 train_loss= 4852.71924 reconstruction_loss= 2795.18066 proj_loss= 1543.69263 pca_loss= 513.84619 accuracy= 0.66419 time= 0.09437
Epoch: 0101 train_loss= 4042.87402 reconstruction_loss= 2080.89453 proj_loss= 1463.53467 pca_loss= 498.44473 accuracy= 0.66012 time= 0.09111
Epoch: 0111 train_loss= 3296.96167 reconstruction_loss= 1425.60938 proj_loss= 1386.99512 pca_loss= 484.35721 accuracy= 0.65561 time= 0.09291
Epoch: 0121 train_loss= 2675.25269 reconstruction_loss= 888.44025 proj_loss= 1314.53381 pca_loss= 472.27866 accuracy= 0.65125 time= 0.08407
Epoch: 0131 train_loss= 2214.50488 reconstruction_loss= 507.08084 proj_loss= 1246.11035 pca_loss= 461.31366 accuracy= 0.64994 time= 0.09490
Epoch: 0141 train_loss= 1910.21021 reconstruction_loss= 278.97202 proj_loss= 1181.72668 pca_loss= 449.51151 accuracy= 0.64660 time= 0.08216
Epoch: 0151 train_loss= 1717.57690 reconstruction_loss= 160.08395 proj_loss= 1121.74500 pca_loss= 435.74796 accuracy= 0.64165 time= 0.09193
Epoch: 0161 train_loss= 1565.44263 reconstruction_loss= 79.10252 proj_loss= 1065.88281 pca_loss= 420.45728 accuracy= 0.65314 time= 0.09173
Epoch: 0171 train_loss= 1460.48547 reconstruction_loss= 42.18942 proj_loss= 1013.92462 pca_loss= 404.37146 accuracy= 0.65009 time= 0.08352
Epoch: 0181 train_loss= 1380.02588 reconstruction_loss= 26.47230 proj_loss= 965.55798 pca_loss= 387.99567 accuracy= 0.65678 time= 0.08356
Epoch: 0191 train_loss= 1309.69165 reconstruction_loss= 17.45122 proj_loss= 920.41864 pca_loss= 371.82178 accuracy= 0.65358 time= 0.08206
Epoch: 0201 train_loss= 1246.55054 reconstruction_loss= 12.18623 proj_loss= 878.18597 pca_loss= 356.17838 accuracy= 0.64994 time= 0.10438
Epoch: 0211 train_loss= 1189.16174 reconstruction_loss= 9.33019 proj_loss= 838.57416 pca_loss= 341.25735 accuracy= 0.63074 time= 0.08434
Epoch: 0221 train_loss= 1135.02698 reconstruction_loss= 6.59486 proj_loss= 801.36041 pca_loss= 327.07169 accuracy= 0.61926 time= 0.08589
Epoch: 0231 train_loss= 1086.62109 reconstruction_loss= 6.61604 proj_loss= 766.33252 pca_loss= 313.67255 accuracy= 0.61766 time= 0.08627
Epoch: 0241 train_loss= 1039.65784 reconstruction_loss= 5.22044 proj_loss= 733.27100 pca_loss= 301.16638 accuracy= 0.61562 time= 0.10915
Epoch: 0251 train_loss= 994.44873 reconstruction_loss= 3.11182 proj_loss= 702.07629 pca_loss= 289.26059 accuracy= 0.61693 time= 0.08439
Epoch: 0261 train_loss= 956.33295 reconstruction_loss= 5.82115 proj_loss= 672.59009 pca_loss= 277.92169 accuracy= 0.62769 time= 0.08709
Epoch: 0271 train_loss= 913.13354 reconstruction_loss= 1.24825 proj_loss= 644.69879 pca_loss= 267.18652 accuracy= 0.61707 time= 0.08233
Epoch: 0281 train_loss= 879.81311 reconstruction_loss= 4.55602 proj_loss= 618.30280 pca_loss= 256.95432 accuracy= 0.62318 time= 0.08860
Epoch: 0291 train_loss= 842.99127 reconstruction_loss= 2.43967 proj_loss= 593.28046 pca_loss= 247.27110 accuracy= 0.61664 time= 0.09297

accuracy 0.61533
auc 0.35131
f1_score 0.11833
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='amazon_electronics_computers', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=30, rsr_dim=0.02, weight_decay=0.0005)
random seed: 651
Found existing ad data, loading...
feature_dim: 767 hidden1_dim: 383 hidden2_dim: 191 rsr_dim: 15 nodes_num: 13752 anomaly_num: 3000

Start modeling
using wavelet scattering transform
y_features shape after scatting (13752, 9971) <class 'numpy.ndarray'>
9971
y_features shape after NoReduction torch.Size([13752, 9971]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 6640715.50000 reconstruction_loss= 6715.79297 proj_loss= 6629996.00000 pca_loss= 4003.44336 accuracy= 0.61620 time= 0.11910
Epoch: 0011 train_loss= 6228006.50000 reconstruction_loss= 5030.20068 proj_loss= 6219193.50000 pca_loss= 3783.19922 accuracy= 0.61809 time= 0.09712
Epoch: 0021 train_loss= 5842734.50000 reconstruction_loss= 4135.35498 proj_loss= 5835025.00000 pca_loss= 3574.01831 accuracy= 0.61984 time= 0.09639
Epoch: 0031 train_loss= 5485098.50000 reconstruction_loss= 3462.77466 proj_loss= 5478262.50000 pca_loss= 3373.11182 accuracy= 0.62129 time= 0.09742
Epoch: 0041 train_loss= 5154342.00000 reconstruction_loss= 2890.38721 proj_loss= 5148273.00000 pca_loss= 3178.70776 accuracy= 0.62464 time= 0.09711
Epoch: 0051 train_loss= 4848960.00000 reconstruction_loss= 2460.67236 proj_loss= 4843513.50000 pca_loss= 2985.94312 accuracy= 0.63962 time= 0.09711
Epoch: 0061 train_loss= 4567114.50000 reconstruction_loss= 2289.78320 proj_loss= 4562034.50000 pca_loss= 2790.15479 accuracy= 0.64383 time= 0.09700
Epoch: 0071 train_loss= 4306541.50000 reconstruction_loss= 2130.24292 proj_loss= 4301795.00000 pca_loss= 2616.48242 accuracy= 0.62871 time= 0.09578
Epoch: 0081 train_loss= 4065345.25000 reconstruction_loss= 2012.34314 proj_loss= 4060888.75000 pca_loss= 2444.18018 accuracy= 0.62740 time= 0.09713
Epoch: 0091 train_loss= 3841731.50000 reconstruction_loss= 1900.66553 proj_loss= 3837552.75000 pca_loss= 2277.95850 accuracy= 0.63191 time= 0.09747
Epoch: 0101 train_loss= 3634140.00000 reconstruction_loss= 1818.37585 proj_loss= 3630201.75000 pca_loss= 2119.64746 accuracy= 0.62900 time= 0.09630
Epoch: 0111 train_loss= 3441133.75000 reconstruction_loss= 1746.17456 proj_loss= 3437422.50000 pca_loss= 1965.02368 accuracy= 0.65009 time= 0.09609
Epoch: 0121 train_loss= 3261422.00000 reconstruction_loss= 1660.41809 proj_loss= 3257942.50000 pca_loss= 1819.01147 accuracy= 0.63903 time= 0.09550
Epoch: 0131 train_loss= 3093885.75000 reconstruction_loss= 1577.06873 proj_loss= 3090629.50000 pca_loss= 1679.22083 accuracy= 0.64529 time= 0.10607
Epoch: 0141 train_loss= 2937531.75000 reconstruction_loss= 1521.64038 proj_loss= 2934463.75000 pca_loss= 1546.26160 accuracy= 0.64063 time= 0.10019
Epoch: 0151 train_loss= 2791412.25000 reconstruction_loss= 1465.20776 proj_loss= 2788530.25000 pca_loss= 1416.73975 accuracy= 0.64398 time= 0.10460
Epoch: 0161 train_loss= 2654709.25000 reconstruction_loss= 1414.09998 proj_loss= 2651998.00000 pca_loss= 1297.30872 accuracy= 0.64863 time= 0.09618
Epoch: 0171 train_loss= 2526669.25000 reconstruction_loss= 1361.70422 proj_loss= 2524125.00000 pca_loss= 1182.43286 accuracy= 0.65038 time= 0.10331
Epoch: 0181 train_loss= 2406607.75000 reconstruction_loss= 1300.88660 proj_loss= 2404233.25000 pca_loss= 1073.49646 accuracy= 0.64485 time= 0.10078
Epoch: 0191 train_loss= 2293916.25000 reconstruction_loss= 1235.16846 proj_loss= 2291710.75000 pca_loss= 970.19885 accuracy= 0.64616 time= 0.10065
Epoch: 0201 train_loss= 2188062.25000 reconstruction_loss= 1189.27417 proj_loss= 2185999.00000 pca_loss= 873.93561 accuracy= 0.64412 time= 0.09707
Epoch: 0211 train_loss= 2088526.75000 reconstruction_loss= 1149.48242 proj_loss= 2086590.00000 pca_loss= 787.19104 accuracy= 0.64776 time= 0.09698
Epoch: 0221 train_loss= 1994822.12500 reconstruction_loss= 1095.24622 proj_loss= 1993026.87500 pca_loss= 699.98822 accuracy= 0.64892 time= 0.09806
Epoch: 0231 train_loss= 1906561.37500 reconstruction_loss= 1056.43127 proj_loss= 1904881.00000 pca_loss= 623.95312 accuracy= 0.64412 time= 0.09700
Epoch: 0241 train_loss= 1823327.87500 reconstruction_loss= 1006.07770 proj_loss= 1821773.00000 pca_loss= 548.75220 accuracy= 0.64791 time= 0.09686
Epoch: 0251 train_loss= 1744792.62500 reconstruction_loss= 966.81812 proj_loss= 1743345.50000 pca_loss= 480.29755 accuracy= 0.64572 time= 0.10890
Epoch: 0261 train_loss= 1670620.12500 reconstruction_loss= 924.74969 proj_loss= 1669273.37500 pca_loss= 422.02737 accuracy= 0.65358 time= 0.11109
Epoch: 0271 train_loss= 1600508.00000 reconstruction_loss= 880.52625 proj_loss= 1599265.37500 pca_loss= 362.10104 accuracy= 0.64587 time= 0.09764
Epoch: 0281 train_loss= 1534185.87500 reconstruction_loss= 835.78143 proj_loss= 1533045.25000 pca_loss= 304.88516 accuracy= 0.65300 time= 0.09686
Epoch: 0291 train_loss= 1471410.50000 reconstruction_loss= 795.45148 proj_loss= 1470360.62500 pca_loss= 254.42461 accuracy= 0.64907 time= 0.09689

accuracy 0.64980
auc 0.48149
f1_score 0.19733
Job finished!
amz computer job finished!
