nohup: ignoring input
rsr and rsr scat on cora, citeseer, cora_full, pubmed, amazon-computer and amazon photo
Start pubmed



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 843
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 6628.83789 feature_loss= 19.99365 structure_loss= 5529.06836 proj_loss= 440.58459 pca_loss= 639.19165 accuracy= 0.63838 accuracy_s= 0.79835 accuracy_f= 0.81711 time= 0.31802
Epoch: 0011 train_loss= 4790.06250 feature_loss= 11.53046 structure_loss= 3903.51807 proj_loss= 425.05194 pca_loss= 449.96216 accuracy= 0.64021 accuracy_s= 0.79855 accuracy_f= 0.81620 time= 0.29207
Epoch: 0021 train_loss= 3939.12769 feature_loss= 5.21314 structure_loss= 3179.11401 proj_loss= 408.51425 pca_loss= 346.28629 accuracy= 0.64092 accuracy_s= 0.79896 accuracy_f= 0.81823 time= 0.28970
Epoch: 0031 train_loss= 2479.30176 feature_loss= 1.69999 structure_loss= 1842.75952 proj_loss= 393.65689 pca_loss= 241.18527 accuracy= 0.64853 accuracy_s= 0.79987 accuracy_f= 0.82999 time= 0.28720
Epoch: 0041 train_loss= 1388.55701 feature_loss= 1.49515 structure_loss= 833.68341 proj_loss= 381.04263 pca_loss= 172.33577 accuracy= 0.64203 accuracy_s= 0.79936 accuracy_f= 0.84714 time= 0.28737
Epoch: 0051 train_loss= 1027.16077 feature_loss= 1.13908 structure_loss= 519.54730 proj_loss= 368.69595 pca_loss= 137.77843 accuracy= 0.64122 accuracy_s= 0.79896 accuracy_f= 0.84967 time= 0.28729
Epoch: 0061 train_loss= 862.33862 feature_loss= 0.84561 structure_loss= 390.86905 proj_loss= 356.44824 pca_loss= 114.17574 accuracy= 0.64041 accuracy_s= 0.79814 accuracy_f= 0.85140 time= 0.28537
Epoch: 0071 train_loss= 754.32623 feature_loss= 0.78562 structure_loss= 312.01593 proj_loss= 344.24783 pca_loss= 97.27688 accuracy= 0.65370 accuracy_s= 0.79794 accuracy_f= 0.85160 time= 0.30799
Epoch: 0081 train_loss= 698.18195 feature_loss= 0.71474 structure_loss= 281.29819 proj_loss= 332.30847 pca_loss= 83.86052 accuracy= 0.65411 accuracy_s= 0.80007 accuracy_f= 0.85130 time= 0.28990
Epoch: 0091 train_loss= 657.81433 feature_loss= 0.67499 structure_loss= 263.73688 proj_loss= 320.65714 pca_loss= 72.74533 accuracy= 0.66760 accuracy_s= 0.80474 accuracy_f= 0.85170 time= 0.28417
Epoch: 0101 train_loss= 629.62213 feature_loss= 0.64357 structure_loss= 256.20020 proj_loss= 309.32770 pca_loss= 63.45069 accuracy= 0.67541 accuracy_s= 0.80727 accuracy_f= 0.85180 time= 0.28672
Epoch: 0111 train_loss= 609.58118 feature_loss= 0.63798 structure_loss= 255.57550 proj_loss= 298.35599 pca_loss= 55.01170 accuracy= 0.67328 accuracy_s= 0.80606 accuracy_f= 0.85201 time= 0.28499
Epoch: 0121 train_loss= 579.51733 feature_loss= 0.63610 structure_loss= 242.66362 proj_loss= 287.81473 pca_loss= 48.40288 accuracy= 0.67378 accuracy_s= 0.80616 accuracy_f= 0.85190 time= 0.28748
Epoch: 0131 train_loss= 560.50446 feature_loss= 0.63576 structure_loss= 239.41724 proj_loss= 277.69620 pca_loss= 42.75525 accuracy= 0.68210 accuracy_s= 0.80666 accuracy_f= 0.85190 time= 0.31023
Epoch: 0141 train_loss= 507.80746 feature_loss= 0.63377 structure_loss= 201.79672 proj_loss= 267.96255 pca_loss= 37.41441 accuracy= 0.68007 accuracy_s= 0.80514 accuracy_f= 0.85201 time= 0.28647
Epoch: 0151 train_loss= 450.67282 feature_loss= 0.63050 structure_loss= 158.11031 proj_loss= 258.72745 pca_loss= 33.20455 accuracy= 0.68251 accuracy_s= 0.80423 accuracy_f= 0.85190 time= 0.28901
Epoch: 0161 train_loss= 420.88843 feature_loss= 0.62851 structure_loss= 140.86824 proj_loss= 249.90494 pca_loss= 29.48676 accuracy= 0.68301 accuracy_s= 0.80707 accuracy_f= 0.85190 time= 0.28959
Epoch: 0171 train_loss= 388.19589 feature_loss= 0.62452 structure_loss= 120.43410 proj_loss= 241.35274 pca_loss= 25.78451 accuracy= 0.68109 accuracy_s= 0.80504 accuracy_f= 0.85180 time= 0.29087
Epoch: 0181 train_loss= 364.04041 feature_loss= 0.62053 structure_loss= 107.52084 proj_loss= 233.15059 pca_loss= 22.74844 accuracy= 0.68798 accuracy_s= 0.80727 accuracy_f= 0.85201 time= 0.28319
Epoch: 0191 train_loss= 337.01889 feature_loss= 0.61318 structure_loss= 91.05264 proj_loss= 225.29652 pca_loss= 20.05655 accuracy= 0.69701 accuracy_s= 0.80464 accuracy_f= 0.85190 time= 0.28885
Epoch: 0201 train_loss= 317.09006 feature_loss= 0.61177 structure_loss= 81.28960 proj_loss= 217.73157 pca_loss= 17.45712 accuracy= 0.70087 accuracy_s= 0.80859 accuracy_f= 0.85150 time= 0.31286
Epoch: 0211 train_loss= 307.37207 feature_loss= 0.60993 structure_loss= 81.04867 proj_loss= 210.43065 pca_loss= 15.28282 accuracy= 0.70036 accuracy_s= 0.81103 accuracy_f= 0.85170 time= 0.28807
Epoch: 0221 train_loss= 266.06772 feature_loss= 0.65208 structure_loss= 48.10120 proj_loss= 203.44594 pca_loss= 13.86851 accuracy= 0.72146 accuracy_s= 0.80109 accuracy_f= 0.84166 time= 0.28738
Epoch: 0231 train_loss= 243.43013 feature_loss= 0.63388 structure_loss= 32.83923 proj_loss= 196.88759 pca_loss= 13.06943 accuracy= 0.70969 accuracy_s= 0.80322 accuracy_f= 0.85140 time= 0.28405
Epoch: 0241 train_loss= 222.82715 feature_loss= 0.63114 structure_loss= 20.24431 proj_loss= 190.56114 pca_loss= 11.39055 accuracy= 0.70746 accuracy_s= 0.79885 accuracy_f= 0.85160 time= 0.28826
Epoch: 0251 train_loss= 210.39417 feature_loss= 0.62594 structure_loss= 15.64497 proj_loss= 184.45592 pca_loss= 9.66735 accuracy= 0.70259 accuracy_s= 0.79733 accuracy_f= 0.85150 time= 0.28730
Epoch: 0261 train_loss= 199.45905 feature_loss= 0.62787 structure_loss= 11.44114 proj_loss= 178.56160 pca_loss= 8.82845 accuracy= 0.70117 accuracy_s= 0.79723 accuracy_f= 0.85170 time= 0.30800
Epoch: 0271 train_loss= 192.76871 feature_loss= 0.62735 structure_loss= 10.18521 proj_loss= 172.99185 pca_loss= 8.96429 accuracy= 0.69965 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.28677
Epoch: 0281 train_loss= 188.96275 feature_loss= 0.62627 structure_loss= 11.61131 proj_loss= 167.73746 pca_loss= 8.98771 accuracy= 0.70300 accuracy_s= 0.79723 accuracy_f= 0.85160 time= 0.28672
Epoch: 0291 train_loss= 182.34558 feature_loss= 0.62371 structure_loss= 10.74453 proj_loss= 162.65758 pca_loss= 8.31976 accuracy= 0.70432 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.28677

accuracy 0.69407
accuracy_s 0.79723
accuracy_f 0.85190
auc 0.41423
f1_score 0.24600
Job finished!



Initializing Rsr twodecoders
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 760
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 10298.42188 feature_loss= 19.60087 structure_loss= 8076.38965 proj_loss= 1938.76013 pca_loss= 263.67136 accuracy= 0.64021 accuracy_s= 0.79845 accuracy_f= 0.81752 time= 0.32708
Epoch: 0011 train_loss= 6929.24756 feature_loss= 6.81146 structure_loss= 4878.21045 proj_loss= 1836.56189 pca_loss= 207.66357 accuracy= 0.64579 accuracy_s= 0.79885 accuracy_f= 0.81792 time= 0.29091
Epoch: 0021 train_loss= 4035.91406 feature_loss= 2.52810 structure_loss= 2152.61108 proj_loss= 1739.96777 pca_loss= 140.80725 accuracy= 0.64599 accuracy_s= 0.79997 accuracy_f= 0.83882 time= 0.29445
Epoch: 0031 train_loss= 3088.04321 feature_loss= 1.63353 structure_loss= 1325.69177 proj_loss= 1647.28845 pca_loss= 113.42952 accuracy= 0.64345 accuracy_s= 0.79956 accuracy_f= 0.84450 time= 0.29409
Epoch: 0041 train_loss= 2595.33960 feature_loss= 1.50876 structure_loss= 940.35461 proj_loss= 1557.39148 pca_loss= 96.08478 accuracy= 0.64406 accuracy_s= 0.79906 accuracy_f= 0.84977 time= 0.29041
Epoch: 0051 train_loss= 2279.99023 feature_loss= 1.28252 structure_loss= 724.85803 proj_loss= 1472.72485 pca_loss= 81.12464 accuracy= 0.64153 accuracy_s= 0.79936 accuracy_f= 0.85038 time= 0.31547
Epoch: 0061 train_loss= 2066.38916 feature_loss= 1.18036 structure_loss= 603.02362 proj_loss= 1393.26917 pca_loss= 68.91591 accuracy= 0.64772 accuracy_s= 0.79956 accuracy_f= 0.85069 time= 0.28730
Epoch: 0071 train_loss= 1919.21753 feature_loss= 1.12769 structure_loss= 540.17810 proj_loss= 1318.60352 pca_loss= 59.30827 accuracy= 0.64548 accuracy_s= 0.79946 accuracy_f= 0.85069 time= 0.28713
Epoch: 0081 train_loss= 1799.40405 feature_loss= 1.03972 structure_loss= 498.77740 proj_loss= 1248.43799 pca_loss= 51.14896 accuracy= 0.64406 accuracy_s= 0.79936 accuracy_f= 0.85079 time= 0.28757
Epoch: 0091 train_loss= 1678.17188 feature_loss= 0.97345 structure_loss= 450.14633 proj_loss= 1182.70837 pca_loss= 44.34381 accuracy= 0.64974 accuracy_s= 0.79946 accuracy_f= 0.85089 time= 0.28984
Epoch: 0101 train_loss= 1536.78589 feature_loss= 0.92817 structure_loss= 375.80573 proj_loss= 1121.33411 pca_loss= 38.71789 accuracy= 0.65076 accuracy_s= 0.79936 accuracy_f= 0.85089 time= 0.29340
Epoch: 0111 train_loss= 1439.81006 feature_loss= 0.86874 structure_loss= 341.42426 proj_loss= 1063.99573 pca_loss= 33.52136 accuracy= 0.68119 accuracy_s= 0.80240 accuracy_f= 0.85130 time= 0.31427
Epoch: 0121 train_loss= 1340.38196 feature_loss= 0.84725 structure_loss= 300.30197 proj_loss= 1010.25653 pca_loss= 28.97614 accuracy= 0.69438 accuracy_s= 0.80109 accuracy_f= 0.85069 time= 0.29144
Epoch: 0131 train_loss= 1261.49573 feature_loss= 0.77874 structure_loss= 275.03180 proj_loss= 960.00452 pca_loss= 25.68061 accuracy= 0.66810 accuracy_s= 0.80088 accuracy_f= 0.85059 time= 0.33187
Epoch: 0141 train_loss= 1168.05493 feature_loss= 0.72552 structure_loss= 231.80031 proj_loss= 912.86884 pca_loss= 22.66023 accuracy= 0.67003 accuracy_s= 0.80180 accuracy_f= 0.85059 time= 0.36171
Epoch: 0151 train_loss= 1099.05176 feature_loss= 0.64980 structure_loss= 209.59090 proj_loss= 868.56964 pca_loss= 20.24150 accuracy= 0.68535 accuracy_s= 0.81285 accuracy_f= 0.85160 time= 0.29282
Epoch: 0161 train_loss= 991.68512 feature_loss= 0.61334 structure_loss= 145.79584 proj_loss= 826.80280 pca_loss= 18.47316 accuracy= 0.67815 accuracy_s= 0.81052 accuracy_f= 0.85150 time= 0.29242
Epoch: 0171 train_loss= 1028.67981 feature_loss= 0.74927 structure_loss= 199.65639 proj_loss= 794.85828 pca_loss= 33.41584 accuracy= 0.65583 accuracy_s= 0.79743 accuracy_f= 0.84906 time= 0.33424
Epoch: 0181 train_loss= 915.33575 feature_loss= 0.78373 structure_loss= 98.66595 proj_loss= 771.43738 pca_loss= 44.44867 accuracy= 0.64437 accuracy_s= 0.79987 accuracy_f= 0.85089 time= 0.29083
Epoch: 0191 train_loss= 860.39563 feature_loss= 0.81410 structure_loss= 68.64365 proj_loss= 746.94031 pca_loss= 43.99755 accuracy= 0.66648 accuracy_s= 0.79764 accuracy_f= 0.85089 time= 0.28926
Epoch: 0201 train_loss= 813.93048 feature_loss= 0.77189 structure_loss= 50.72409 proj_loss= 722.44232 pca_loss= 39.99221 accuracy= 0.70036 accuracy_s= 0.80991 accuracy_f= 0.85170 time= 0.29167
Epoch: 0211 train_loss= 771.86938 feature_loss= 0.65750 structure_loss= 36.22513 proj_loss= 698.62427 pca_loss= 36.36251 accuracy= 0.70239 accuracy_s= 0.80748 accuracy_f= 0.85201 time= 0.28983
Epoch: 0221 train_loss= 736.12823 feature_loss= 0.61724 structure_loss= 26.43547 proj_loss= 675.75183 pca_loss= 33.32365 accuracy= 0.69995 accuracy_s= 0.80281 accuracy_f= 0.85170 time= 0.29403
Epoch: 0231 train_loss= 704.96912 feature_loss= 0.54693 structure_loss= 19.70777 proj_loss= 653.89581 pca_loss= 30.81858 accuracy= 0.70259 accuracy_s= 0.79916 accuracy_f= 0.85190 time= 0.29125
Epoch: 0241 train_loss= 676.05780 feature_loss= 0.57226 structure_loss= 13.77982 proj_loss= 633.00555 pca_loss= 28.70017 accuracy= 0.70077 accuracy_s= 0.79733 accuracy_f= 0.85170 time= 0.28869
Epoch: 0251 train_loss= 651.58130 feature_loss= 0.56648 structure_loss= 11.06945 proj_loss= 613.05334 pca_loss= 26.89205 accuracy= 0.70006 accuracy_s= 0.79723 accuracy_f= 0.85170 time= 0.28843
Epoch: 0261 train_loss= 630.03790 feature_loss= 0.40443 structure_loss= 10.23305 proj_loss= 593.99353 pca_loss= 25.40691 accuracy= 0.69630 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.29029
Epoch: 0271 train_loss= 609.08081 feature_loss= 0.38938 structure_loss= 8.97623 proj_loss= 575.76770 pca_loss= 23.94748 accuracy= 0.69509 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.29052
Epoch: 0281 train_loss= 588.53711 feature_loss= 0.38640 structure_loss= 6.98324 proj_loss= 558.33246 pca_loss= 22.83503 accuracy= 0.69346 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.34993
Epoch: 0291 train_loss= 567.65338 feature_loss= 0.38557 structure_loss= 3.74688 proj_loss= 541.63879 pca_loss= 21.88216 accuracy= 0.69103 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.36448

accuracy 0.69072
accuracy_s 0.79723
accuracy_f 0.85221
auc 0.38424
f1_score 0.23775
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 837
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 1090.43188 reconstruction_loss= 20.07504 proj_loss= 435.27530 pca_loss= 635.08154 accuracy= 0.63940 time= 0.21882
Epoch: 0011 train_loss= 549.40625 reconstruction_loss= 11.61285 proj_loss= 408.53653 pca_loss= 129.25688 accuracy= 0.65867 time= 0.17966
Epoch: 0021 train_loss= 469.95062 reconstruction_loss= 2.83383 proj_loss= 384.50085 pca_loss= 82.61593 accuracy= 0.64731 time= 0.18285
Epoch: 0031 train_loss= 422.12579 reconstruction_loss= 1.37707 proj_loss= 362.46704 pca_loss= 58.28169 accuracy= 0.68454 time= 0.19140
Epoch: 0041 train_loss= 378.34747 reconstruction_loss= 1.13993 proj_loss= 342.01767 pca_loss= 35.18989 accuracy= 0.70320 time= 0.18013
Epoch: 0051 train_loss= 345.38782 reconstruction_loss= 0.84157 proj_loss= 322.89764 pca_loss= 21.64861 accuracy= 0.71588 time= 0.17952
Epoch: 0061 train_loss= 319.57501 reconstruction_loss= 0.66627 proj_loss= 305.08939 pca_loss= 13.81936 accuracy= 0.71933 time= 0.17803
Epoch: 0071 train_loss= 296.14102 reconstruction_loss= 0.62743 proj_loss= 288.47937 pca_loss= 7.03422 accuracy= 0.71973 time= 0.18083
Epoch: 0081 train_loss= 276.02557 reconstruction_loss= 0.60575 proj_loss= 272.92239 pca_loss= 2.49745 accuracy= 0.72237 time= 0.17725
Epoch: 0091 train_loss= 259.72867 reconstruction_loss= 0.60546 proj_loss= 258.36130 pca_loss= 0.76190 accuracy= 0.72237 time= 0.17884
Epoch: 0101 train_loss= 245.95657 reconstruction_loss= 0.60153 proj_loss= 244.77377 pca_loss= 0.58127 accuracy= 0.72247 time= 0.17750
Epoch: 0111 train_loss= 233.03551 reconstruction_loss= 0.60045 proj_loss= 232.11302 pca_loss= 0.32204 accuracy= 0.72247 time= 0.21619
Epoch: 0121 train_loss= 221.21243 reconstruction_loss= 0.60031 proj_loss= 220.30762 pca_loss= 0.30450 accuracy= 0.72217 time= 0.17806
Epoch: 0131 train_loss= 209.90782 reconstruction_loss= 0.41310 proj_loss= 209.28999 pca_loss= 0.20472 accuracy= 0.72288 time= 0.17848
Epoch: 0141 train_loss= 199.57903 reconstruction_loss= 0.38947 proj_loss= 198.99513 pca_loss= 0.19443 accuracy= 0.72217 time= 0.18177
Epoch: 0151 train_loss= 189.90903 reconstruction_loss= 0.38710 proj_loss= 189.36319 pca_loss= 0.15874 accuracy= 0.72207 time= 0.17925
Epoch: 0161 train_loss= 180.87079 reconstruction_loss= 0.38735 proj_loss= 180.34102 pca_loss= 0.14242 accuracy= 0.72247 time= 0.17930
Epoch: 0171 train_loss= 172.40900 reconstruction_loss= 0.38626 proj_loss= 171.88005 pca_loss= 0.14269 accuracy= 0.72268 time= 0.18058
Epoch: 0181 train_loss= 164.45662 reconstruction_loss= 0.38548 proj_loss= 163.93687 pca_loss= 0.13427 accuracy= 0.72257 time= 0.17938
Epoch: 0191 train_loss= 156.98535 reconstruction_loss= 0.38694 proj_loss= 156.47194 pca_loss= 0.12646 accuracy= 0.72257 time= 0.17944
Epoch: 0201 train_loss= 149.95827 reconstruction_loss= 0.38597 proj_loss= 149.44940 pca_loss= 0.12289 accuracy= 0.72268 time= 0.18197
Epoch: 0211 train_loss= 143.33424 reconstruction_loss= 0.38598 proj_loss= 142.83684 pca_loss= 0.11143 accuracy= 0.72237 time= 0.17909
Epoch: 0221 train_loss= 137.09648 reconstruction_loss= 0.38573 proj_loss= 136.60458 pca_loss= 0.10617 accuracy= 0.72247 time= 0.19109
Epoch: 0231 train_loss= 131.21518 reconstruction_loss= 0.38577 proj_loss= 130.72557 pca_loss= 0.10384 accuracy= 0.72257 time= 0.18063
Epoch: 0241 train_loss= 125.65832 reconstruction_loss= 0.38566 proj_loss= 125.17507 pca_loss= 0.09759 accuracy= 0.72257 time= 0.18548
Epoch: 0251 train_loss= 120.40990 reconstruction_loss= 0.38541 proj_loss= 119.93044 pca_loss= 0.09405 accuracy= 0.72268 time= 0.17946
Epoch: 0261 train_loss= 115.44479 reconstruction_loss= 0.38541 proj_loss= 114.97085 pca_loss= 0.08854 accuracy= 0.72257 time= 0.18673
Epoch: 0271 train_loss= 110.74954 reconstruction_loss= 0.38540 proj_loss= 110.27724 pca_loss= 0.08690 accuracy= 0.72268 time= 0.19256
Epoch: 0281 train_loss= 106.30052 reconstruction_loss= 0.38539 proj_loss= 105.83201 pca_loss= 0.08312 accuracy= 0.72257 time= 0.18110
Epoch: 0291 train_loss= 102.08451 reconstruction_loss= 0.38539 proj_loss= 101.61896 pca_loss= 0.08016 accuracy= 0.72247 time= 0.18070

accuracy 0.72257
auc 0.61612
f1_score 0.31625
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 663
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 6907.67871 reconstruction_loss= 5772.35498 proj_loss= 458.26898 pca_loss= 677.05463 accuracy= 0.64041 time= 0.18545
Epoch: 0011 train_loss= 4810.93652 reconstruction_loss= 3914.32544 proj_loss= 442.42657 pca_loss= 454.18472 accuracy= 0.64193 time= 0.17877
Epoch: 0021 train_loss= 3896.68091 reconstruction_loss= 3119.26538 proj_loss= 425.49139 pca_loss= 351.92404 accuracy= 0.64427 time= 0.17838
Epoch: 0031 train_loss= 2579.87476 reconstruction_loss= 1920.20654 proj_loss= 409.97415 pca_loss= 249.69415 accuracy= 0.64609 time= 0.17826
Epoch: 0041 train_loss= 1454.66760 reconstruction_loss= 883.64398 proj_loss= 396.63220 pca_loss= 174.39146 accuracy= 0.64132 time= 0.17808
Epoch: 0051 train_loss= 1113.18311 reconstruction_loss= 588.37494 proj_loss= 383.78183 pca_loss= 141.02631 accuracy= 0.63980 time= 0.17736
Epoch: 0061 train_loss= 961.74200 reconstruction_loss= 474.66983 proj_loss= 371.04413 pca_loss= 116.02804 accuracy= 0.63909 time= 0.17637
Epoch: 0071 train_loss= 841.69049 reconstruction_loss= 390.37039 proj_loss= 358.36395 pca_loss= 92.95612 accuracy= 0.63767 time= 0.17730
Epoch: 0081 train_loss= 734.30743 reconstruction_loss= 312.81894 proj_loss= 346.07874 pca_loss= 75.40973 accuracy= 0.65613 time= 0.17724
Epoch: 0091 train_loss= 629.52618 reconstruction_loss= 231.79500 proj_loss= 334.30673 pca_loss= 63.42445 accuracy= 0.66131 time= 0.17660
Epoch: 0101 train_loss= 580.78296 reconstruction_loss= 204.51727 proj_loss= 322.91104 pca_loss= 53.35464 accuracy= 0.66699 time= 0.17687
Epoch: 0111 train_loss= 542.72534 reconstruction_loss= 186.13492 proj_loss= 311.86292 pca_loss= 44.72751 accuracy= 0.66394 time= 0.17638
Epoch: 0121 train_loss= 501.83081 reconstruction_loss= 162.26926 proj_loss= 301.25650 pca_loss= 38.30507 accuracy= 0.66831 time= 0.17707
Epoch: 0131 train_loss= 462.34839 reconstruction_loss= 138.11163 proj_loss= 291.06787 pca_loss= 33.16887 accuracy= 0.66821 time= 0.19612
Epoch: 0141 train_loss= 414.33951 reconstruction_loss= 104.05680 proj_loss= 281.21439 pca_loss= 29.06833 accuracy= 0.66029 time= 0.19536
Epoch: 0151 train_loss= 369.13394 reconstruction_loss= 73.45134 proj_loss= 271.65479 pca_loss= 24.02780 accuracy= 0.68251 time= 0.21710
Epoch: 0161 train_loss= 330.84448 reconstruction_loss= 47.83722 proj_loss= 262.47818 pca_loss= 20.52907 accuracy= 0.65908 time= 0.17766
Epoch: 0171 train_loss= 304.64349 reconstruction_loss= 32.48378 proj_loss= 253.65010 pca_loss= 18.50961 accuracy= 0.65218 time= 0.17727
Epoch: 0181 train_loss= 284.39081 reconstruction_loss= 23.72581 proj_loss= 245.11034 pca_loss= 15.55465 accuracy= 0.64985 time= 0.17647
Epoch: 0191 train_loss= 272.16983 reconstruction_loss= 21.95222 proj_loss= 236.85312 pca_loss= 13.36450 accuracy= 0.65198 time= 0.17589
Epoch: 0201 train_loss= 253.64978 reconstruction_loss= 13.09698 proj_loss= 228.87489 pca_loss= 11.67791 accuracy= 0.64345 time= 0.17613
Epoch: 0211 train_loss= 235.78633 reconstruction_loss= 3.98980 proj_loss= 221.21149 pca_loss= 10.58504 accuracy= 0.64122 time= 0.17790
Epoch: 0221 train_loss= 224.85481 reconstruction_loss= 1.59531 proj_loss= 213.85027 pca_loss= 9.40924 accuracy= 0.64234 time= 0.17672
Epoch: 0231 train_loss= 215.89171 reconstruction_loss= 0.51818 proj_loss= 206.76170 pca_loss= 8.61183 accuracy= 0.64274 time= 0.17634
Epoch: 0241 train_loss= 208.45306 reconstruction_loss= 0.49181 proj_loss= 199.93091 pca_loss= 8.03034 accuracy= 0.64254 time= 0.17805
Epoch: 0251 train_loss= 201.62863 reconstruction_loss= 0.54012 proj_loss= 193.36360 pca_loss= 7.72492 accuracy= 0.64254 time= 0.17683
Epoch: 0261 train_loss= 194.82300 reconstruction_loss= 0.45648 proj_loss= 187.04434 pca_loss= 7.32217 accuracy= 0.64234 time= 0.18110
Epoch: 0271 train_loss= 188.47220 reconstruction_loss= 0.48318 proj_loss= 180.96907 pca_loss= 7.01996 accuracy= 0.64264 time= 0.17662
Epoch: 0281 train_loss= 182.47607 reconstruction_loss= 0.44911 proj_loss= 175.14056 pca_loss= 6.88639 accuracy= 0.64203 time= 0.17714
Epoch: 0291 train_loss= 176.63640 reconstruction_loss= 0.47795 proj_loss= 169.53195 pca_loss= 6.62649 accuracy= 0.64244 time= 0.17716

accuracy 0.64305
auc 0.25588
f1_score 0.12025
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 229
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 1851.31580 reconstruction_loss= 19.81984 proj_loss= 1597.51086 pca_loss= 233.98514 accuracy= 0.64031 time= 0.19730
Epoch: 0011 train_loss= 1551.50024 reconstruction_loss= 10.43395 proj_loss= 1494.64966 pca_loss= 46.41667 accuracy= 0.64325 time= 0.18484
Epoch: 0021 train_loss= 1426.79114 reconstruction_loss= 2.65271 proj_loss= 1399.38513 pca_loss= 24.75335 accuracy= 0.68656 time= 0.19503
Epoch: 0031 train_loss= 1328.74475 reconstruction_loss= 1.33268 proj_loss= 1311.51062 pca_loss= 15.90152 accuracy= 0.65745 time= 0.20604
Epoch: 0041 train_loss= 1243.02563 reconstruction_loss= 1.05716 proj_loss= 1230.63013 pca_loss= 11.33834 accuracy= 0.67683 time= 0.19511
Epoch: 0051 train_loss= 1165.38062 reconstruction_loss= 0.79124 proj_loss= 1156.16150 pca_loss= 8.42780 accuracy= 0.69711 time= 0.20472
Epoch: 0061 train_loss= 1095.08423 reconstruction_loss= 0.73457 proj_loss= 1087.51672 pca_loss= 6.83292 accuracy= 0.70624 time= 0.18351
Epoch: 0071 train_loss= 1030.67847 reconstruction_loss= 0.68533 proj_loss= 1024.10010 pca_loss= 5.89306 accuracy= 0.71172 time= 0.18656
Epoch: 0081 train_loss= 971.46246 reconstruction_loss= 0.66884 proj_loss= 965.43530 pca_loss= 5.35831 accuracy= 0.71334 time= 0.19906
Epoch: 0091 train_loss= 916.80646 reconstruction_loss= 0.65855 proj_loss= 911.12030 pca_loss= 5.02760 accuracy= 0.71537 time= 0.18714
Epoch: 0101 train_loss= 866.29346 reconstruction_loss= 0.65003 proj_loss= 860.79126 pca_loss= 4.85216 accuracy= 0.71852 time= 0.18088
Epoch: 0111 train_loss= 819.33264 reconstruction_loss= 0.65025 proj_loss= 814.09186 pca_loss= 4.59049 accuracy= 0.71639 time= 0.18012
Epoch: 0121 train_loss= 775.75702 reconstruction_loss= 0.64553 proj_loss= 770.69000 pca_loss= 4.42150 accuracy= 0.71872 time= 0.18040
Epoch: 0131 train_loss= 735.19824 reconstruction_loss= 0.64029 proj_loss= 730.28937 pca_loss= 4.26859 accuracy= 0.71973 time= 0.18266
Epoch: 0141 train_loss= 697.43286 reconstruction_loss= 0.63664 proj_loss= 692.63373 pca_loss= 4.16246 accuracy= 0.72105 time= 0.18047
Epoch: 0151 train_loss= 662.18976 reconstruction_loss= 0.63587 proj_loss= 657.49286 pca_loss= 4.06106 accuracy= 0.72136 time= 0.18111
Epoch: 0161 train_loss= 629.26581 reconstruction_loss= 0.63433 proj_loss= 624.65973 pca_loss= 3.97176 accuracy= 0.72176 time= 0.18119
Epoch: 0171 train_loss= 598.50854 reconstruction_loss= 0.63320 proj_loss= 593.94684 pca_loss= 3.92855 accuracy= 0.72146 time= 0.18234
Epoch: 0181 train_loss= 569.63306 reconstruction_loss= 0.64070 proj_loss= 565.18536 pca_loss= 3.80699 accuracy= 0.71872 time= 0.17938
Epoch: 0191 train_loss= 542.61041 reconstruction_loss= 0.62658 proj_loss= 538.22327 pca_loss= 3.76057 accuracy= 0.72460 time= 0.18759
Epoch: 0201 train_loss= 517.30566 reconstruction_loss= 0.62561 proj_loss= 512.92255 pca_loss= 3.75753 accuracy= 0.72623 time= 0.18350
Epoch: 0211 train_loss= 493.40988 reconstruction_loss= 0.62556 proj_loss= 489.15536 pca_loss= 3.62896 accuracy= 0.72105 time= 0.18215
Epoch: 0221 train_loss= 471.03506 reconstruction_loss= 0.62369 proj_loss= 466.80820 pca_loss= 3.60319 accuracy= 0.72359 time= 0.18316
Epoch: 0231 train_loss= 453.73773 reconstruction_loss= 0.71112 proj_loss= 445.87115 pca_loss= 7.15547 accuracy= 0.70858 time= 0.20445
Epoch: 0241 train_loss= 432.51508 reconstruction_loss= 0.63931 proj_loss= 426.12335 pca_loss= 5.75240 accuracy= 0.72197 time= 0.19465
Epoch: 0251 train_loss= 412.74841 reconstruction_loss= 0.63321 proj_loss= 407.49045 pca_loss= 4.62475 accuracy= 0.72369 time= 0.18154
Epoch: 0261 train_loss= 394.53226 reconstruction_loss= 0.62880 proj_loss= 389.91006 pca_loss= 3.99338 accuracy= 0.72308 time= 0.18448
Epoch: 0271 train_loss= 377.71561 reconstruction_loss= 0.62449 proj_loss= 373.32593 pca_loss= 3.76520 accuracy= 0.72308 time= 0.18553
Epoch: 0281 train_loss= 361.88876 reconstruction_loss= 0.62556 proj_loss= 357.64569 pca_loss= 3.61752 accuracy= 0.72278 time= 0.19142
Epoch: 0291 train_loss= 346.96213 reconstruction_loss= 0.62086 proj_loss= 342.81332 pca_loss= 3.52797 accuracy= 0.72257 time= 0.17937

accuracy 0.72288
auc 0.61676
f1_score 0.31700
Job finished!



Initializing normal onedecoder
Namespace(alpha=1, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 583
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
Epoch: 0001 train_loss= 10206.72754 reconstruction_loss= 8348.09863 proj_loss= 1631.74670 pca_loss= 226.88150 accuracy= 0.63899 time= 0.23366
Epoch: 0011 train_loss= 6829.23535 reconstruction_loss= 5110.33838 proj_loss= 1547.95947 pca_loss= 170.93736 accuracy= 0.64772 time= 0.18695
Epoch: 0021 train_loss= 3467.56641 reconstruction_loss= 1903.54175 proj_loss= 1470.85181 pca_loss= 93.17290 accuracy= 0.64893 time= 0.18365
Epoch: 0031 train_loss= 2615.95386 reconstruction_loss= 1153.63782 proj_loss= 1399.44580 pca_loss= 62.87043 accuracy= 0.64437 time= 0.18492
Epoch: 0041 train_loss= 2250.54370 reconstruction_loss= 875.34253 proj_loss= 1327.20825 pca_loss= 47.99296 accuracy= 0.64396 time= 0.18520
Epoch: 0051 train_loss= 2027.93921 reconstruction_loss= 734.96820 proj_loss= 1257.61597 pca_loss= 35.35502 accuracy= 0.64477 time= 0.21318
Epoch: 0061 train_loss= 1834.96741 reconstruction_loss= 618.32294 proj_loss= 1191.67212 pca_loss= 24.97225 accuracy= 0.64731 time= 0.18460
Epoch: 0071 train_loss= 1592.35413 reconstruction_loss= 445.19608 proj_loss= 1129.59497 pca_loss= 17.56310 accuracy= 0.64741 time= 0.19580
Epoch: 0081 train_loss= 1432.91101 reconstruction_loss= 347.69171 proj_loss= 1071.33704 pca_loss= 13.88218 accuracy= 0.65187 time= 0.20117
Epoch: 0091 train_loss= 1261.58997 reconstruction_loss= 233.16714 proj_loss= 1016.40277 pca_loss= 12.02007 accuracy= 0.65897 time= 0.18005
Epoch: 0101 train_loss= 1161.76904 reconstruction_loss= 185.90562 proj_loss= 964.79089 pca_loss= 11.07256 accuracy= 0.65137 time= 0.18029
Epoch: 0111 train_loss= 1089.46411 reconstruction_loss= 162.74419 proj_loss= 916.45886 pca_loss= 10.26105 accuracy= 0.68271 time= 0.17982
Epoch: 0121 train_loss= 986.83783 reconstruction_loss= 106.17274 proj_loss= 871.14050 pca_loss= 9.52461 accuracy= 0.64761 time= 0.19914
Epoch: 0131 train_loss= 927.15546 reconstruction_loss= 89.40440 proj_loss= 828.77856 pca_loss= 8.97250 accuracy= 0.66394 time= 0.18879
Epoch: 0141 train_loss= 878.35522 reconstruction_loss= 80.81533 proj_loss= 789.10278 pca_loss= 8.43713 accuracy= 0.66405 time= 0.19491
Epoch: 0151 train_loss= 833.43298 reconstruction_loss= 73.59344 proj_loss= 751.83453 pca_loss= 8.00500 accuracy= 0.65025 time= 0.19289
Epoch: 0161 train_loss= 793.76282 reconstruction_loss= 69.42812 proj_loss= 716.74335 pca_loss= 7.59139 accuracy= 0.66973 time= 0.19497
Epoch: 0171 train_loss= 753.90442 reconstruction_loss= 62.96973 proj_loss= 683.59296 pca_loss= 7.34173 accuracy= 0.65390 time= 0.21210
Epoch: 0181 train_loss= 722.47565 reconstruction_loss= 62.91504 proj_loss= 652.36493 pca_loss= 7.19570 accuracy= 0.66293 time= 0.17964
Epoch: 0191 train_loss= 694.31879 reconstruction_loss= 64.34525 proj_loss= 622.94324 pca_loss= 7.03035 accuracy= 0.65553 time= 0.18049
Epoch: 0201 train_loss= 660.06952 reconstruction_loss= 57.99743 proj_loss= 595.21552 pca_loss= 6.85655 accuracy= 0.65766 time= 0.18003
Epoch: 0211 train_loss= 626.37738 reconstruction_loss= 50.62279 proj_loss= 569.04755 pca_loss= 6.70705 accuracy= 0.66739 time= 0.17939
Epoch: 0221 train_loss= 596.56750 reconstruction_loss= 45.63449 proj_loss= 544.34937 pca_loss= 6.58359 accuracy= 0.65005 time= 0.17807
Epoch: 0231 train_loss= 572.49921 reconstruction_loss= 45.01535 proj_loss= 521.00720 pca_loss= 6.47660 accuracy= 0.67419 time= 0.18208
Epoch: 0241 train_loss= 546.53308 reconstruction_loss= 41.23174 proj_loss= 498.92136 pca_loss= 6.38001 accuracy= 0.65847 time= 0.19036
Epoch: 0251 train_loss= 1257.55505 reconstruction_loss= 763.28650 proj_loss= 480.70367 pca_loss= 13.56478 accuracy= 0.63950 time= 0.18838
Epoch: 0261 train_loss= 541.02795 reconstruction_loss= 56.53257 proj_loss= 468.03433 pca_loss= 16.46105 accuracy= 0.62652 time= 0.19135
Epoch: 0271 train_loss= 521.03387 reconstruction_loss= 48.98050 proj_loss= 454.77045 pca_loss= 17.28295 accuracy= 0.64974 time= 0.18105
Epoch: 0281 train_loss= 500.00290 reconstruction_loss= 41.57199 proj_loss= 441.53598 pca_loss= 16.89494 accuracy= 0.63930 time= 0.19183
Epoch: 0291 train_loss= 480.19296 reconstruction_loss= 35.23428 proj_loss= 428.63000 pca_loss= 16.32869 accuracy= 0.64325 time= 0.19167

accuracy 0.64112
auc 0.29811
f1_score 0.11550
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 610
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 7800.95996 feature_loss= 21.24170 structure_loss= 6319.85547 proj_loss= 422.91348 pca_loss= 1036.94910 accuracy= 0.74996 accuracy_s= 0.83628 accuracy_f= 0.81518 time= 0.29249
Epoch: 0011 train_loss= 5989.97363 feature_loss= 16.90209 structure_loss= 4556.41895 proj_loss= 407.51428 pca_loss= 1009.13873 accuracy= 0.72014 accuracy_s= 0.82452 accuracy_f= 0.80707 time= 0.24297
Epoch: 0021 train_loss= 5453.29346 feature_loss= 13.14945 structure_loss= 4072.52661 proj_loss= 388.05487 pca_loss= 979.56232 accuracy= 0.71274 accuracy_s= 0.82066 accuracy_f= 0.80869 time= 0.24364
Epoch: 0031 train_loss= 5066.95020 feature_loss= 9.39094 structure_loss= 3739.21484 proj_loss= 367.74509 pca_loss= 950.59967 accuracy= 0.71142 accuracy_s= 0.82401 accuracy_f= 0.81285 time= 0.23954
Epoch: 0041 train_loss= 4736.28320 feature_loss= 5.73871 structure_loss= 3459.84497 proj_loss= 347.84851 pca_loss= 922.85095 accuracy= 0.70878 accuracy_s= 0.82137 accuracy_f= 0.81701 time= 0.24582
Epoch: 0051 train_loss= 4434.90430 feature_loss= 3.04857 structure_loss= 3206.90869 proj_loss= 328.76767 pca_loss= 896.17932 accuracy= 0.70350 accuracy_s= 0.82026 accuracy_f= 0.81853 time= 0.24378
Epoch: 0061 train_loss= 4149.15771 feature_loss= 2.54037 structure_loss= 2965.42773 proj_loss= 310.68909 pca_loss= 870.50037 accuracy= 0.69884 accuracy_s= 0.82431 accuracy_f= 0.83720 time= 0.24001
Epoch: 0071 train_loss= 3851.77808 feature_loss= 2.19012 structure_loss= 2709.68335 proj_loss= 293.82031 pca_loss= 846.08423 accuracy= 0.69539 accuracy_s= 0.82391 accuracy_f= 0.84450 time= 0.23739
Epoch: 0081 train_loss= 3527.76025 feature_loss= 1.67183 structure_loss= 2424.57251 proj_loss= 278.28723 pca_loss= 823.22839 accuracy= 0.69042 accuracy_s= 0.82279 accuracy_f= 0.84430 time= 0.24284
Epoch: 0091 train_loss= 3162.97510 feature_loss= 1.45119 structure_loss= 2095.42725 proj_loss= 264.02405 pca_loss= 802.07288 accuracy= 0.68575 accuracy_s= 0.81884 accuracy_f= 0.84906 time= 0.24407
Epoch: 0101 train_loss= 2743.53613 feature_loss= 1.42137 structure_loss= 1708.92212 proj_loss= 250.76414 pca_loss= 782.42847 accuracy= 0.67662 accuracy_s= 0.81032 accuracy_f= 0.84967 time= 0.23763
Epoch: 0111 train_loss= 2288.29614 feature_loss= 1.35988 structure_loss= 1284.85791 proj_loss= 238.18047 pca_loss= 763.89795 accuracy= 0.66496 accuracy_s= 0.80474 accuracy_f= 0.84977 time= 0.24130
Epoch: 0121 train_loss= 1862.96179 feature_loss= 1.35537 structure_loss= 889.62787 proj_loss= 225.98196 pca_loss= 745.99658 accuracy= 0.65928 accuracy_s= 0.80413 accuracy_f= 0.85018 time= 0.24419
Epoch: 0131 train_loss= 1520.67090 feature_loss= 1.36077 structure_loss= 577.05573 proj_loss= 214.18149 pca_loss= 728.07281 accuracy= 0.66861 accuracy_s= 0.81092 accuracy_f= 0.85028 time= 0.24220
Epoch: 0141 train_loss= 1261.62524 feature_loss= 1.34474 structure_loss= 347.43149 proj_loss= 202.94783 pca_loss= 709.90112 accuracy= 0.66932 accuracy_s= 0.81427 accuracy_f= 0.85059 time= 0.24583
Epoch: 0151 train_loss= 1063.43176 feature_loss= 1.33437 structure_loss= 178.16890 proj_loss= 192.39671 pca_loss= 691.53174 accuracy= 0.66060 accuracy_s= 0.81082 accuracy_f= 0.85038 time= 0.24449
Epoch: 0161 train_loss= 939.47803 feature_loss= 1.28208 structure_loss= 82.65962 proj_loss= 182.53043 pca_loss= 673.00592 accuracy= 0.66029 accuracy_s= 0.80271 accuracy_f= 0.85089 time= 0.24690
Epoch: 0171 train_loss= 874.52625 feature_loss= 1.20108 structure_loss= 45.46222 proj_loss= 173.29974 pca_loss= 654.56317 accuracy= 0.66892 accuracy_s= 0.80839 accuracy_f= 0.85038 time= 0.24653
Epoch: 0181 train_loss= 831.87183 feature_loss= 0.67892 structure_loss= 30.11772 proj_loss= 164.62527 pca_loss= 636.44989 accuracy= 0.67013 accuracy_s= 0.81468 accuracy_f= 0.85180 time= 0.24587
Epoch: 0191 train_loss= 801.02930 feature_loss= 0.42479 structure_loss= 25.34517 proj_loss= 156.45032 pca_loss= 618.80902 accuracy= 0.67186 accuracy_s= 0.81387 accuracy_f= 0.85089 time= 0.24571
Epoch: 0201 train_loss= 772.65271 feature_loss= 0.41690 structure_loss= 21.79465 proj_loss= 148.73233 pca_loss= 601.70886 accuracy= 0.67003 accuracy_s= 0.81295 accuracy_f= 0.85170 time= 0.24160
Epoch: 0211 train_loss= 746.02893 feature_loss= 0.39179 structure_loss= 19.00017 proj_loss= 141.44519 pca_loss= 585.19177 accuracy= 0.66881 accuracy_s= 0.81366 accuracy_f= 0.85211 time= 0.24339
Epoch: 0221 train_loss= 721.00165 feature_loss= 0.38850 structure_loss= 16.80012 proj_loss= 134.56071 pca_loss= 569.25232 accuracy= 0.66658 accuracy_s= 0.81468 accuracy_f= 0.85190 time= 0.24913
Epoch: 0231 train_loss= 697.51483 feature_loss= 0.38762 structure_loss= 15.20767 proj_loss= 128.05130 pca_loss= 553.86823 accuracy= 0.66455 accuracy_s= 0.81488 accuracy_f= 0.85160 time= 0.24429
Epoch: 0241 train_loss= 674.72833 feature_loss= 0.38574 structure_loss= 13.43429 proj_loss= 121.89317 pca_loss= 539.01514 accuracy= 0.66486 accuracy_s= 0.81498 accuracy_f= 0.85211 time= 0.24366
Epoch: 0251 train_loss= 653.19299 feature_loss= 0.38550 structure_loss= 12.07945 proj_loss= 116.06340 pca_loss= 524.66461 accuracy= 0.66506 accuracy_s= 0.81498 accuracy_f= 0.85201 time= 0.24134
Epoch: 0261 train_loss= 632.47510 feature_loss= 0.38543 structure_loss= 10.75791 proj_loss= 110.54105 pca_loss= 510.79071 accuracy= 0.66526 accuracy_s= 0.81529 accuracy_f= 0.85211 time= 0.24040
Epoch: 0271 train_loss= 612.84625 feature_loss= 0.39149 structure_loss= 9.77169 proj_loss= 105.30880 pca_loss= 497.37427 accuracy= 0.66526 accuracy_s= 0.81539 accuracy_f= 0.85150 time= 0.24076
Epoch: 0281 train_loss= 593.89764 feature_loss= 0.38566 structure_loss= 8.77024 proj_loss= 100.34848 pca_loss= 484.39328 accuracy= 0.66587 accuracy_s= 0.81508 accuracy_f= 0.85211 time= 0.24343
Epoch: 0291 train_loss= 575.76099 feature_loss= 0.38539 structure_loss= 7.90483 proj_loss= 95.64466 pca_loss= 471.82614 accuracy= 0.66557 accuracy_s= 0.81559 accuracy_f= 0.85211 time= 0.24228

accuracy 0.66577
accuracy_s 0.81549
accuracy_f 0.85211
auc 0.43972
f1_score 0.17625
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 966
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 855595.62500 feature_loss= 20.14279 structure_loss= 5642.09814 proj_loss= 849766.50000 pca_loss= 166.88170 accuracy= 0.64995 accuracy_s= 0.79764 accuracy_f= 0.82249 time= 0.30462
Epoch: 0011 train_loss= 801954.62500 feature_loss= 15.20479 structure_loss= 4869.26270 proj_loss= 796908.62500 pca_loss= 161.55452 accuracy= 0.64843 accuracy_s= 0.79743 accuracy_f= 0.82320 time= 0.25445
Epoch: 0021 train_loss= 752144.37500 feature_loss= 11.60432 structure_loss= 4477.02539 proj_loss= 747499.31250 pca_loss= 156.41782 accuracy= 0.65005 accuracy_s= 0.79743 accuracy_f= 0.82279 time= 0.25568
Epoch: 0031 train_loss= 705975.12500 feature_loss= 9.20324 structure_loss= 4179.58496 proj_loss= 701634.87500 pca_loss= 151.45268 accuracy= 0.65056 accuracy_s= 0.79754 accuracy_f= 0.82279 time= 0.25966
Epoch: 0041 train_loss= 663306.00000 feature_loss= 7.40748 structure_loss= 3923.10718 proj_loss= 659228.81250 pca_loss= 146.70450 accuracy= 0.65167 accuracy_s= 0.79774 accuracy_f= 0.82381 time= 0.29521
Epoch: 0051 train_loss= 623921.56250 feature_loss= 5.29905 structure_loss= 3695.68530 proj_loss= 620078.37500 pca_loss= 142.17934 accuracy= 0.65187 accuracy_s= 0.79784 accuracy_f= 0.82320 time= 0.27528
Epoch: 0061 train_loss= 587547.87500 feature_loss= 3.43498 structure_loss= 3476.98096 proj_loss= 583929.56250 pca_loss= 137.85207 accuracy= 0.65269 accuracy_s= 0.79784 accuracy_f= 0.82289 time= 0.28939
Epoch: 0071 train_loss= 553926.68750 feature_loss= 2.93856 structure_loss= 3270.28955 proj_loss= 550519.75000 pca_loss= 133.71278 accuracy= 0.65116 accuracy_s= 0.79764 accuracy_f= 0.82381 time= 0.25847
Epoch: 0081 train_loss= 522795.59375 feature_loss= 2.43407 structure_loss= 3063.49390 proj_loss= 519599.90625 pca_loss= 129.75920 accuracy= 0.65177 accuracy_s= 0.79774 accuracy_f= 0.83567 time= 0.27796
Epoch: 0091 train_loss= 493922.37500 feature_loss= 1.89763 structure_loss= 2852.10156 proj_loss= 490942.40625 pca_loss= 125.98375 accuracy= 0.65137 accuracy_s= 0.79764 accuracy_f= 0.83730 time= 0.30700
Epoch: 0101 train_loss= 467104.00000 feature_loss= 1.37927 structure_loss= 2637.51904 proj_loss= 464342.71875 pca_loss= 122.37765 accuracy= 0.65248 accuracy_s= 0.79754 accuracy_f= 0.84176 time= 0.26176
Epoch: 0111 train_loss= 442150.87500 feature_loss= 0.96629 structure_loss= 2413.33228 proj_loss= 439617.62500 pca_loss= 118.93691 accuracy= 0.65258 accuracy_s= 0.79764 accuracy_f= 0.84744 time= 0.25742
Epoch: 0121 train_loss= 418890.37500 feature_loss= 0.71166 structure_loss= 2170.74561 proj_loss= 416603.28125 pca_loss= 115.64026 accuracy= 0.65269 accuracy_s= 0.79754 accuracy_f= 0.84906 time= 0.25713
Epoch: 0131 train_loss= 397186.59375 feature_loss= 0.51242 structure_loss= 1920.58435 proj_loss= 395153.00000 pca_loss= 112.48770 accuracy= 0.65238 accuracy_s= 0.79754 accuracy_f= 0.85099 time= 0.25548
Epoch: 0141 train_loss= 376897.78125 feature_loss= 0.39953 structure_loss= 1652.91699 proj_loss= 375135.00000 pca_loss= 109.48002 accuracy= 0.65187 accuracy_s= 0.79754 accuracy_f= 0.85089 time= 0.25538
Epoch: 0151 train_loss= 357939.40625 feature_loss= 0.40382 structure_loss= 1401.71973 proj_loss= 356430.68750 pca_loss= 106.58809 accuracy= 0.65289 accuracy_s= 0.79754 accuracy_f= 0.85211 time= 0.25764
Epoch: 0161 train_loss= 340213.81250 feature_loss= 0.38767 structure_loss= 1175.94763 proj_loss= 338933.65625 pca_loss= 103.80950 accuracy= 0.65238 accuracy_s= 0.79754 accuracy_f= 0.85201 time= 0.25697
Epoch: 0171 train_loss= 323627.68750 feature_loss= 0.38678 structure_loss= 977.70776 proj_loss= 322548.46875 pca_loss= 101.13958 accuracy= 0.65309 accuracy_s= 0.79754 accuracy_f= 0.85221 time= 0.25702
Epoch: 0181 train_loss= 308094.56250 feature_loss= 0.38966 structure_loss= 807.14716 proj_loss= 307188.46875 pca_loss= 98.57222 accuracy= 0.65279 accuracy_s= 0.79754 accuracy_f= 0.85211 time= 0.25539
Epoch: 0191 train_loss= 293538.21875 feature_loss= 0.38544 structure_loss= 667.28375 proj_loss= 292774.46875 pca_loss= 96.10376 accuracy= 0.65421 accuracy_s= 0.79774 accuracy_f= 0.85190 time= 0.25734
Epoch: 0201 train_loss= 279881.09375 feature_loss= 0.38541 structure_loss= 552.03094 proj_loss= 279234.96875 pca_loss= 93.73170 accuracy= 0.65400 accuracy_s= 0.79764 accuracy_f= 0.85201 time= 0.25623
Epoch: 0211 train_loss= 267051.00000 feature_loss= 0.39238 structure_loss= 454.33069 proj_loss= 266504.84375 pca_loss= 91.44599 accuracy= 0.65400 accuracy_s= 0.79774 accuracy_f= 0.85160 time= 0.25974
Epoch: 0221 train_loss= 254989.73438 feature_loss= 0.38588 structure_loss= 375.33493 proj_loss= 254524.76562 pca_loss= 89.24432 accuracy= 0.65390 accuracy_s= 0.79764 accuracy_f= 0.85221 time= 0.25665
Epoch: 0231 train_loss= 243649.56250 feature_loss= 0.38539 structure_loss= 321.71014 proj_loss= 243240.34375 pca_loss= 87.12173 accuracy= 0.65563 accuracy_s= 0.79794 accuracy_f= 0.85211 time= 0.25798
Epoch: 0241 train_loss= 232968.12500 feature_loss= 0.38539 structure_loss= 280.55307 proj_loss= 232602.10938 pca_loss= 85.07648 accuracy= 0.65350 accuracy_s= 0.79764 accuracy_f= 0.85211 time= 0.25854
Epoch: 0251 train_loss= 222895.25000 feature_loss= 0.38539 structure_loss= 247.09520 proj_loss= 222564.65625 pca_loss= 83.10616 accuracy= 0.65299 accuracy_s= 0.79774 accuracy_f= 0.85211 time= 0.25625
Epoch: 0261 train_loss= 213388.93750 feature_loss= 0.39237 structure_loss= 221.04597 proj_loss= 213086.29688 pca_loss= 81.20401 accuracy= 0.65309 accuracy_s= 0.79784 accuracy_f= 0.85190 time= 0.25789
Epoch: 0271 train_loss= 204406.26562 feature_loss= 0.38539 structure_loss= 197.70052 proj_loss= 204128.81250 pca_loss= 79.37038 accuracy= 0.65370 accuracy_s= 0.79774 accuracy_f= 0.85211 time= 0.25759
Epoch: 0281 train_loss= 195912.81250 feature_loss= 0.38549 structure_loss= 177.77771 proj_loss= 195657.04688 pca_loss= 77.60241 accuracy= 0.65289 accuracy_s= 0.79794 accuracy_f= 0.85211 time= 0.25725
Epoch: 0291 train_loss= 187874.00000 feature_loss= 0.38597 structure_loss= 159.06204 proj_loss= 187638.65625 pca_loss= 75.89397 accuracy= 0.65360 accuracy_s= 0.79784 accuracy_f= 0.85211 time= 0.25720

accuracy 0.65279
accuracy_s 0.79794
accuracy_f 0.85211
auc 0.29359
f1_score 0.14425
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 281
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 10674.51562 feature_loss= 21.02949 structure_loss= 8589.56445 proj_loss= 1650.05029 pca_loss= 413.87073 accuracy= 0.73779 accuracy_s= 0.83851 accuracy_f= 0.81508 time= 0.29136
Epoch: 0011 train_loss= 9410.73047 feature_loss= 17.89441 structure_loss= 7436.87891 proj_loss= 1554.73743 pca_loss= 401.21973 accuracy= 0.70269 accuracy_s= 0.82421 accuracy_f= 0.81447 time= 0.23510
Epoch: 0021 train_loss= 8850.95605 feature_loss= 15.00704 structure_loss= 6986.46338 proj_loss= 1460.35522 pca_loss= 389.13101 accuracy= 0.68839 accuracy_s= 0.81630 accuracy_f= 0.81468 time= 0.23840
Epoch: 0031 train_loss= 8401.46875 feature_loss= 12.17471 structure_loss= 6640.95215 proj_loss= 1370.55029 pca_loss= 377.79175 accuracy= 0.68849 accuracy_s= 0.81549 accuracy_f= 0.81529 time= 0.23837
Epoch: 0041 train_loss= 7985.25928 feature_loss= 9.20919 structure_loss= 6322.30859 proj_loss= 1286.75073 pca_loss= 366.99057 accuracy= 0.68585 accuracy_s= 0.81366 accuracy_f= 0.81508 time= 0.23902
Epoch: 0051 train_loss= 7578.53564 feature_loss= 5.15120 structure_loss= 6007.49658 proj_loss= 1209.23914 pca_loss= 356.64862 accuracy= 0.68525 accuracy_s= 0.81285 accuracy_f= 0.81549 time= 0.23627
Epoch: 0061 train_loss= 7177.20801 feature_loss= 2.88008 structure_loss= 5689.77490 proj_loss= 1137.77856 pca_loss= 346.77448 accuracy= 0.68443 accuracy_s= 0.81275 accuracy_f= 0.82381 time= 0.23744
Epoch: 0071 train_loss= 6779.69922 feature_loss= 2.24532 structure_loss= 5368.07568 proj_loss= 1071.95813 pca_loss= 337.42017 accuracy= 0.68484 accuracy_s= 0.81174 accuracy_f= 0.84562 time= 0.23827
Epoch: 0081 train_loss= 6352.01270 feature_loss= 1.71636 structure_loss= 5010.14502 proj_loss= 1011.50592 pca_loss= 328.64560 accuracy= 0.68007 accuracy_s= 0.80981 accuracy_f= 0.84967 time= 0.24208
Epoch: 0091 train_loss= 5876.23242 feature_loss= 1.38444 structure_loss= 4597.83203 proj_loss= 956.41907 pca_loss= 320.59695 accuracy= 0.67652 accuracy_s= 0.81437 accuracy_f= 0.84998 time= 0.23982
Epoch: 0101 train_loss= 5282.18701 feature_loss= 0.81186 structure_loss= 4060.71851 proj_loss= 907.11536 pca_loss= 313.54141 accuracy= 0.67135 accuracy_s= 0.81407 accuracy_f= 0.84967 time= 0.24221
Epoch: 0111 train_loss= 4440.08887 feature_loss= 0.45851 structure_loss= 3267.35522 proj_loss= 864.40515 pca_loss= 307.87030 accuracy= 0.67460 accuracy_s= 0.81488 accuracy_f= 0.85201 time= 0.23782
Epoch: 0121 train_loss= 3294.21045 feature_loss= 0.43294 structure_loss= 2161.02856 proj_loss= 828.86829 pca_loss= 303.88092 accuracy= 0.67967 accuracy_s= 0.81427 accuracy_f= 0.85130 time= 0.24130
Epoch: 0131 train_loss= 2299.28442 feature_loss= 0.40176 structure_loss= 1200.61963 proj_loss= 797.53491 pca_loss= 300.72815 accuracy= 0.68646 accuracy_s= 0.81498 accuracy_f= 0.85180 time= 0.24289
Epoch: 0141 train_loss= 1756.91870 feature_loss= 0.39165 structure_loss= 695.70667 proj_loss= 764.36456 pca_loss= 296.45575 accuracy= 0.67946 accuracy_s= 0.81468 accuracy_f= 0.85211 time= 0.24028
Epoch: 0151 train_loss= 1456.18604 feature_loss= 0.38762 structure_loss= 436.87970 proj_loss= 728.23578 pca_loss= 290.68301 accuracy= 0.67967 accuracy_s= 0.81681 accuracy_f= 0.85180 time= 0.24017
Epoch: 0161 train_loss= 1246.40015 feature_loss= 0.38580 structure_loss= 270.35529 proj_loss= 691.56812 pca_loss= 284.09088 accuracy= 0.66699 accuracy_s= 0.80697 accuracy_f= 0.85180 time= 0.24052
Epoch: 0171 train_loss= 1111.76782 feature_loss= 0.38681 structure_loss= 177.96275 proj_loss= 656.16711 pca_loss= 277.25122 accuracy= 0.65867 accuracy_s= 0.81204 accuracy_f= 0.85201 time= 0.23908
Epoch: 0181 train_loss= 1023.57104 feature_loss= 0.38597 structure_loss= 130.31171 proj_loss= 622.55219 pca_loss= 270.32114 accuracy= 0.65370 accuracy_s= 0.80352 accuracy_f= 0.85201 time= 0.24346
Epoch: 0191 train_loss= 947.46741 feature_loss= 0.38579 structure_loss= 92.70277 proj_loss= 590.91052 pca_loss= 263.46829 accuracy= 0.65654 accuracy_s= 0.80798 accuracy_f= 0.85201 time= 0.23997
Epoch: 0201 train_loss= 883.31250 feature_loss= 0.38540 structure_loss= 64.79562 proj_loss= 561.31036 pca_loss= 256.82111 accuracy= 0.66719 accuracy_s= 0.81174 accuracy_f= 0.85211 time= 0.24408
Epoch: 0211 train_loss= 835.14349 feature_loss= 0.38539 structure_loss= 50.64427 proj_loss= 533.70123 pca_loss= 250.41261 accuracy= 0.67267 accuracy_s= 0.81123 accuracy_f= 0.85211 time= 0.24189
Epoch: 0221 train_loss= 797.01678 feature_loss= 0.38601 structure_loss= 44.51735 proj_loss= 507.88937 pca_loss= 244.22408 accuracy= 0.67297 accuracy_s= 0.81407 accuracy_f= 0.85211 time= 0.25329
Epoch: 0231 train_loss= 762.67139 feature_loss= 0.38539 structure_loss= 40.32016 proj_loss= 483.70883 pca_loss= 238.25702 accuracy= 0.67186 accuracy_s= 0.81387 accuracy_f= 0.85211 time= 0.25604
Epoch: 0241 train_loss= 730.15753 feature_loss= 0.38539 structure_loss= 36.23205 proj_loss= 461.03128 pca_loss= 232.50880 accuracy= 0.67064 accuracy_s= 0.81529 accuracy_f= 0.85211 time= 0.24202
Epoch: 0251 train_loss= 700.58380 feature_loss= 0.38539 structure_loss= 33.48822 proj_loss= 439.74100 pca_loss= 226.96919 accuracy= 0.66973 accuracy_s= 0.81488 accuracy_f= 0.85211 time= 0.24217
Epoch: 0261 train_loss= 671.48950 feature_loss= 0.38539 structure_loss= 29.73202 proj_loss= 419.73737 pca_loss= 221.63477 accuracy= 0.67165 accuracy_s= 0.81468 accuracy_f= 0.85211 time= 0.24019
Epoch: 0271 train_loss= 645.12860 feature_loss= 0.38606 structure_loss= 27.35117 proj_loss= 400.90573 pca_loss= 216.48566 accuracy= 0.67155 accuracy_s= 0.81478 accuracy_f= 0.85211 time= 0.24609
Epoch: 0281 train_loss= 620.15112 feature_loss= 0.38539 structure_loss= 25.05692 proj_loss= 383.18219 pca_loss= 211.52663 accuracy= 0.67074 accuracy_s= 0.81407 accuracy_f= 0.85211 time= 0.24320
Epoch: 0291 train_loss= 596.41364 feature_loss= 0.38539 structure_loss= 22.80979 proj_loss= 366.47546 pca_loss= 206.74297 accuracy= 0.66963 accuracy_s= 0.81559 accuracy_f= 0.85211 time= 0.24460

accuracy 0.66993
accuracy_s 0.81478
accuracy_f 0.85160
auc 0.46130
f1_score 0.18650
Job finished!



Initializing rsr scat twodecoders training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 778
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 4268164.50000 feature_loss= 19.90713 structure_loss= 8147.26953 proj_loss= 4259920.50000 pca_loss= 77.20135 accuracy= 0.64680 accuracy_s= 0.79774 accuracy_f= 0.82137 time= 0.28634
Epoch: 0011 train_loss= 4003862.25000 feature_loss= 14.16858 structure_loss= 7406.43945 proj_loss= 3996366.75000 pca_loss= 74.94910 accuracy= 0.65086 accuracy_s= 0.79754 accuracy_f= 0.82076 time= 0.25399
Epoch: 0021 train_loss= 3756950.25000 feature_loss= 11.58307 structure_loss= 7008.63770 proj_loss= 3749857.25000 pca_loss= 72.77320 accuracy= 0.64914 accuracy_s= 0.79754 accuracy_f= 0.82198 time= 0.25929
Epoch: 0031 train_loss= 3527635.25000 feature_loss= 10.19310 structure_loss= 6662.33594 proj_loss= 3520892.00000 pca_loss= 70.66589 accuracy= 0.64853 accuracy_s= 0.79754 accuracy_f= 0.82279 time= 0.27335
Epoch: 0041 train_loss= 3315484.25000 feature_loss= 8.70885 structure_loss= 6339.00488 proj_loss= 3309067.75000 pca_loss= 68.63120 accuracy= 0.64914 accuracy_s= 0.79754 accuracy_f= 0.82198 time= 0.25896
Epoch: 0051 train_loss= 3119505.50000 feature_loss= 6.61118 structure_loss= 6034.33301 proj_loss= 3113397.75000 pca_loss= 66.67618 accuracy= 0.64843 accuracy_s= 0.79754 accuracy_f= 0.82208 time= 0.27223
Epoch: 0061 train_loss= 2938431.25000 feature_loss= 3.84924 structure_loss= 5724.49854 proj_loss= 2932638.25000 pca_loss= 64.81007 accuracy= 0.64883 accuracy_s= 0.79743 accuracy_f= 0.82168 time= 0.25445
Epoch: 0071 train_loss= 2770989.25000 feature_loss= 3.03452 structure_loss= 5425.79688 proj_loss= 2765497.50000 pca_loss= 63.02948 accuracy= 0.64903 accuracy_s= 0.79743 accuracy_f= 0.82320 time= 0.31214
Epoch: 0081 train_loss= 2615914.00000 feature_loss= 2.48768 structure_loss= 5103.61963 proj_loss= 2610746.75000 pca_loss= 61.32421 accuracy= 0.64812 accuracy_s= 0.79743 accuracy_f= 0.84105 time= 0.25925
Epoch: 0091 train_loss= 2472091.50000 feature_loss= 1.91819 structure_loss= 4768.35742 proj_loss= 2467261.50000 pca_loss= 59.69032 accuracy= 0.64893 accuracy_s= 0.79733 accuracy_f= 0.84775 time= 0.25846
Epoch: 0101 train_loss= 2338493.00000 feature_loss= 1.37677 structure_loss= 4404.94775 proj_loss= 2334028.50000 pca_loss= 58.12550 accuracy= 0.64822 accuracy_s= 0.79723 accuracy_f= 0.85089 time= 0.24625
Epoch: 0111 train_loss= 2214199.00000 feature_loss= 0.94024 structure_loss= 4000.85376 proj_loss= 2210140.50000 pca_loss= 56.62612 accuracy= 0.64832 accuracy_s= 0.79723 accuracy_f= 0.85099 time= 0.25263
Epoch: 0121 train_loss= 2098379.00000 feature_loss= 0.51633 structure_loss= 3535.13745 proj_loss= 2094788.00000 pca_loss= 55.19101 accuracy= 0.64792 accuracy_s= 0.79723 accuracy_f= 0.85099 time= 0.25704
Epoch: 0131 train_loss= 1990323.25000 feature_loss= 0.40986 structure_loss= 3026.11523 proj_loss= 1987242.87500 pca_loss= 53.81836 accuracy= 0.64741 accuracy_s= 0.79723 accuracy_f= 0.85130 time= 0.26623
Epoch: 0141 train_loss= 1889378.25000 feature_loss= 0.41379 structure_loss= 2471.83862 proj_loss= 1886853.50000 pca_loss= 52.50457 accuracy= 0.64640 accuracy_s= 0.79723 accuracy_f= 0.85130 time= 0.26259
Epoch: 0151 train_loss= 1794991.25000 feature_loss= 0.39007 structure_loss= 1906.87915 proj_loss= 1793032.75000 pca_loss= 51.24683 accuracy= 0.64579 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.26686
Epoch: 0161 train_loss= 1706675.12500 feature_loss= 0.38957 structure_loss= 1372.63745 proj_loss= 1705252.12500 pca_loss= 50.04142 accuracy= 0.64619 accuracy_s= 0.79723 accuracy_f= 0.85201 time= 0.25310
Epoch: 0171 train_loss= 1623987.87500 feature_loss= 0.38930 structure_loss= 905.45520 proj_loss= 1623033.12500 pca_loss= 48.88672 accuracy= 0.64690 accuracy_s= 0.79723 accuracy_f= 0.85211 time= 0.30975
Epoch: 0181 train_loss= 1546524.37500 feature_loss= 0.38876 structure_loss= 533.87000 proj_loss= 1545942.37500 pca_loss= 47.77978 accuracy= 0.64812 accuracy_s= 0.79743 accuracy_f= 0.85190 time= 0.33623
Epoch: 0191 train_loss= 1473912.62500 feature_loss= 0.38755 structure_loss= 280.82416 proj_loss= 1473584.62500 pca_loss= 46.70688 accuracy= 0.64680 accuracy_s= 0.79754 accuracy_f= 0.85190 time= 0.26615
Epoch: 0201 train_loss= 1405797.37500 feature_loss= 0.38588 structure_loss= 152.96460 proj_loss= 1405598.37500 pca_loss= 45.65718 accuracy= 0.64711 accuracy_s= 0.79754 accuracy_f= 0.85190 time= 0.32598
Epoch: 0211 train_loss= 1341775.12500 feature_loss= 0.39209 structure_loss= 68.84946 proj_loss= 1341661.25000 pca_loss= 44.63358 accuracy= 0.68058 accuracy_s= 0.79713 accuracy_f= 0.85211 time= 0.25963
Epoch: 0221 train_loss= 1281561.75000 feature_loss= 0.38540 structure_loss= 37.72284 proj_loss= 1281480.00000 pca_loss= 43.64730 accuracy= 0.71121 accuracy_s= 0.80494 accuracy_f= 0.85211 time= 0.28559
Epoch: 0231 train_loss= 1224850.25000 feature_loss= 0.38594 structure_loss= 22.23888 proj_loss= 1224784.87500 pca_loss= 42.69764 accuracy= 0.70695 accuracy_s= 0.81082 accuracy_f= 0.85211 time= 0.30923
Epoch: 0241 train_loss= 1171385.50000 feature_loss= 0.38539 structure_loss= 15.43105 proj_loss= 1171327.87500 pca_loss= 41.78120 accuracy= 0.70462 accuracy_s= 0.80200 accuracy_f= 0.85211 time= 0.25988
Epoch: 0251 train_loss= 1120938.00000 feature_loss= 0.38574 structure_loss= 14.82937 proj_loss= 1120881.87500 pca_loss= 40.89726 accuracy= 0.70929 accuracy_s= 0.80017 accuracy_f= 0.85211 time= 0.32306
Epoch: 0261 train_loss= 1073288.00000 feature_loss= 0.38787 structure_loss= 8.28952 proj_loss= 1073239.37500 pca_loss= 40.04380 accuracy= 0.70949 accuracy_s= 0.79713 accuracy_f= 0.85190 time= 0.25834
Epoch: 0271 train_loss= 1028254.93750 feature_loss= 0.38539 structure_loss= 6.73329 proj_loss= 1028208.56250 pca_loss= 39.21981 accuracy= 0.71192 accuracy_s= 0.79713 accuracy_f= 0.85211 time= 0.25493
Epoch: 0281 train_loss= 985662.93750 feature_loss= 0.38539 structure_loss= 10.04042 proj_loss= 985614.06250 pca_loss= 38.42255 accuracy= 0.71142 accuracy_s= 0.80859 accuracy_f= 0.85211 time= 0.28906
Epoch: 0291 train_loss= 945337.12500 feature_loss= 0.38618 structure_loss= 4.81884 proj_loss= 945294.31250 pca_loss= 37.65155 accuracy= 0.70533 accuracy_s= 0.79713 accuracy_f= 0.85211 time= 0.25629

accuracy 0.70117
accuracy_s 0.79713
accuracy_f 0.85211
auc 0.46512
f1_score 0.26350
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 426
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 1553.68042 reconstruction_loss= 21.23637 proj_loss= 457.73514 pca_loss= 1074.70898 accuracy= 0.72582 time= 0.16756
Epoch: 0011 train_loss= 1479.13062 reconstruction_loss= 16.70045 proj_loss= 428.49750 pca_loss= 1033.93274 accuracy= 0.71456 time= 0.12718
Epoch: 0021 train_loss= 1408.74194 reconstruction_loss= 12.50604 proj_loss= 401.28418 pca_loss= 994.95166 accuracy= 0.70452 time= 0.13154
Epoch: 0031 train_loss= 1342.56775 reconstruction_loss= 8.60377 proj_loss= 376.05777 pca_loss= 957.90619 accuracy= 0.67957 time= 0.12801
Epoch: 0041 train_loss= 1281.52319 reconstruction_loss= 6.00539 proj_loss= 352.73386 pca_loss= 922.78400 accuracy= 0.67145 time= 0.13082
Epoch: 0051 train_loss= 1224.71021 reconstruction_loss= 4.02251 proj_loss= 331.17383 pca_loss= 889.51385 accuracy= 0.67084 time= 0.12685
Epoch: 0061 train_loss= 1172.18506 reconstruction_loss= 2.97086 proj_loss= 311.22308 pca_loss= 857.99109 accuracy= 0.69874 time= 0.12787
Epoch: 0071 train_loss= 1123.25464 reconstruction_loss= 2.42816 proj_loss= 292.73499 pca_loss= 828.09149 accuracy= 0.70847 time= 0.12905
Epoch: 0081 train_loss= 1077.22974 reconstruction_loss= 1.96341 proj_loss= 275.57971 pca_loss= 799.68658 accuracy= 0.71700 time= 0.13086
Epoch: 0091 train_loss= 1033.85425 reconstruction_loss= 1.55417 proj_loss= 259.64050 pca_loss= 772.65961 accuracy= 0.71892 time= 0.12838
Epoch: 0101 train_loss= 993.11823 reconstruction_loss= 1.39956 proj_loss= 244.80809 pca_loss= 746.91058 accuracy= 0.72470 time= 0.12653
Epoch: 0111 train_loss= 954.74579 reconstruction_loss= 1.41086 proj_loss= 230.98680 pca_loss= 722.34814 accuracy= 0.72511 time= 0.12615
Epoch: 0121 train_loss= 917.76746 reconstruction_loss= 0.78558 proj_loss= 218.09349 pca_loss= 698.88837 accuracy= 0.72308 time= 0.12782
Epoch: 0131 train_loss= 882.96906 reconstruction_loss= 0.45891 proj_loss= 206.04688 pca_loss= 676.46326 accuracy= 0.72247 time= 0.12976
Epoch: 0141 train_loss= 850.19397 reconstruction_loss= 0.40867 proj_loss= 194.78589 pca_loss= 654.99945 accuracy= 0.72217 time= 0.12848
Epoch: 0151 train_loss= 819.08606 reconstruction_loss= 0.40008 proj_loss= 184.24492 pca_loss= 634.44104 accuracy= 0.72207 time= 0.12636
Epoch: 0161 train_loss= 789.49054 reconstruction_loss= 0.38830 proj_loss= 174.36885 pca_loss= 614.73340 accuracy= 0.72278 time= 0.12893
Epoch: 0171 train_loss= 761.32080 reconstruction_loss= 0.38668 proj_loss= 165.10666 pca_loss= 595.82745 accuracy= 0.72268 time= 0.12985
Epoch: 0181 train_loss= 734.47705 reconstruction_loss= 0.38629 proj_loss= 156.41318 pca_loss= 577.67761 accuracy= 0.72227 time= 0.13102
Epoch: 0191 train_loss= 708.87439 reconstruction_loss= 0.38551 proj_loss= 148.24608 pca_loss= 560.24280 accuracy= 0.72237 time= 0.12609
Epoch: 0201 train_loss= 684.43909 reconstruction_loss= 0.38695 proj_loss= 140.56792 pca_loss= 543.48419 accuracy= 0.72247 time= 0.12633
Epoch: 0211 train_loss= 661.09766 reconstruction_loss= 0.38742 proj_loss= 133.34404 pca_loss= 527.36621 accuracy= 0.72278 time= 0.12225
Epoch: 0221 train_loss= 638.78412 reconstruction_loss= 0.38547 proj_loss= 126.54255 pca_loss= 511.85608 accuracy= 0.72257 time= 0.12369
Epoch: 0231 train_loss= 617.44293 reconstruction_loss= 0.38539 proj_loss= 120.13454 pca_loss= 496.92300 accuracy= 0.72247 time= 0.12495
Epoch: 0241 train_loss= 597.01709 reconstruction_loss= 0.38539 proj_loss= 114.09337 pca_loss= 482.53836 accuracy= 0.72268 time= 0.12399
Epoch: 0251 train_loss= 577.45569 reconstruction_loss= 0.38575 proj_loss= 108.39437 pca_loss= 468.67557 accuracy= 0.72257 time= 0.12243
Epoch: 0261 train_loss= 558.70996 reconstruction_loss= 0.38539 proj_loss= 103.01506 pca_loss= 455.30954 accuracy= 0.72257 time= 0.12760
Epoch: 0271 train_loss= 540.73694 reconstruction_loss= 0.38552 proj_loss= 97.93456 pca_loss= 442.41684 accuracy= 0.72247 time= 0.12249
Epoch: 0281 train_loss= 523.49463 reconstruction_loss= 0.38539 proj_loss= 93.13380 pca_loss= 429.97546 accuracy= 0.72257 time= 0.12713
Epoch: 0291 train_loss= 506.94495 reconstruction_loss= 0.38539 proj_loss= 88.59491 pca_loss= 417.96463 accuracy= 0.72257 time= 0.12383

accuracy 0.72257
auc 0.61612
f1_score 0.31625
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 713
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 846966.56250 reconstruction_loss= 20.12351 proj_loss= 846768.06250 pca_loss= 178.39629 accuracy= 0.64518 time= 0.17301
Epoch: 0011 train_loss= 794270.18750 reconstruction_loss= 14.71295 proj_loss= 794082.93750 pca_loss= 172.53775 accuracy= 0.64447 time= 0.14217
Epoch: 0021 train_loss= 745016.87500 reconstruction_loss= 11.35796 proj_loss= 744838.62500 pca_loss= 166.86591 accuracy= 0.64974 time= 0.13917
Epoch: 0031 train_loss= 699300.18750 reconstruction_loss= 8.81126 proj_loss= 699129.93750 pca_loss= 161.43683 accuracy= 0.66425 time= 0.14029
Epoch: 0041 train_loss= 657033.12500 reconstruction_loss= 6.20346 proj_loss= 656870.68750 pca_loss= 156.26555 accuracy= 0.66344 time= 0.14287
Epoch: 0051 train_loss= 618013.56250 reconstruction_loss= 3.73400 proj_loss= 617858.43750 pca_loss= 151.34628 accuracy= 0.69884 time= 0.14280
Epoch: 0061 train_loss= 581988.68750 reconstruction_loss= 2.85257 proj_loss= 581839.12500 pca_loss= 146.66621 accuracy= 0.68454 time= 0.13860
Epoch: 0071 train_loss= 548695.56250 reconstruction_loss= 2.51621 proj_loss= 548550.87500 pca_loss= 142.20934 accuracy= 0.69985 time= 0.14002
Epoch: 0081 train_loss= 517885.03125 reconstruction_loss= 2.11895 proj_loss= 517744.93750 pca_loss= 137.96313 accuracy= 0.70584 time= 0.14093
Epoch: 0091 train_loss= 489329.68750 reconstruction_loss= 1.74307 proj_loss= 489194.03125 pca_loss= 133.91737 accuracy= 0.71020 time= 0.14495
Epoch: 0101 train_loss= 462825.28125 reconstruction_loss= 1.32865 proj_loss= 462693.87500 pca_loss= 130.05974 accuracy= 0.71142 time= 0.14392
Epoch: 0111 train_loss= 438189.06250 reconstruction_loss= 0.86062 proj_loss= 438061.81250 pca_loss= 126.37724 accuracy= 0.72065 time= 0.13965
Epoch: 0121 train_loss= 415257.96875 reconstruction_loss= 0.52282 proj_loss= 415134.59375 pca_loss= 122.85819 accuracy= 0.72227 time= 0.14490
Epoch: 0131 train_loss= 393886.09375 reconstruction_loss= 0.39173 proj_loss= 393766.18750 pca_loss= 119.49257 accuracy= 0.72237 time= 0.14407
Epoch: 0141 train_loss= 373942.12500 reconstruction_loss= 0.39749 proj_loss= 373825.43750 pca_loss= 116.27080 accuracy= 0.72227 time= 0.13993
Epoch: 0151 train_loss= 355308.18750 reconstruction_loss= 0.38845 proj_loss= 355194.62500 pca_loss= 113.18433 accuracy= 0.72278 time= 0.13966
Epoch: 0161 train_loss= 337878.12500 reconstruction_loss= 0.38664 proj_loss= 337767.53125 pca_loss= 110.22517 accuracy= 0.72257 time= 0.14004
Epoch: 0171 train_loss= 321556.09375 reconstruction_loss= 0.38566 proj_loss= 321448.34375 pca_loss= 107.38579 accuracy= 0.72247 time= 0.14159
Epoch: 0181 train_loss= 306255.25000 reconstruction_loss= 0.38552 proj_loss= 306150.21875 pca_loss= 104.65950 accuracy= 0.72257 time= 0.13946
Epoch: 0191 train_loss= 291897.03125 reconstruction_loss= 0.38542 proj_loss= 291794.62500 pca_loss= 102.03995 accuracy= 0.72247 time= 0.14134
Epoch: 0201 train_loss= 278410.03125 reconstruction_loss= 0.38541 proj_loss= 278310.12500 pca_loss= 99.52126 accuracy= 0.72257 time= 0.14416
Epoch: 0211 train_loss= 265729.06250 reconstruction_loss= 0.38557 proj_loss= 265631.59375 pca_loss= 97.09807 accuracy= 0.72247 time= 0.14174
Epoch: 0221 train_loss= 253795.14062 reconstruction_loss= 0.38539 proj_loss= 253699.98438 pca_loss= 94.76529 accuracy= 0.72257 time= 0.14436
Epoch: 0231 train_loss= 242553.98438 reconstruction_loss= 0.38539 proj_loss= 242461.07812 pca_loss= 92.51823 accuracy= 0.72257 time= 0.13990
Epoch: 0241 train_loss= 231956.34375 reconstruction_loss= 0.38547 proj_loss= 231865.59375 pca_loss= 90.35251 accuracy= 0.72257 time= 0.14787
Epoch: 0251 train_loss= 221956.84375 reconstruction_loss= 0.38564 proj_loss= 221868.18750 pca_loss= 88.26404 accuracy= 0.72247 time= 0.14792
Epoch: 0261 train_loss= 212514.10938 reconstruction_loss= 0.38640 proj_loss= 212427.46875 pca_loss= 86.24897 accuracy= 0.72247 time= 0.15117
Epoch: 0271 train_loss= 203590.03125 reconstruction_loss= 0.38539 proj_loss= 203505.34375 pca_loss= 84.30375 accuracy= 0.72257 time= 0.14460
Epoch: 0281 train_loss= 195149.65625 reconstruction_loss= 0.39270 proj_loss= 195066.84375 pca_loss= 82.42501 accuracy= 0.72237 time= 0.14591
Epoch: 0291 train_loss= 187160.79688 reconstruction_loss= 0.39362 proj_loss= 187079.79688 pca_loss= 80.60960 accuracy= 0.72268 time= 0.14125

accuracy 0.72288
auc 0.61614
f1_score 0.31700
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 438
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 7835.04395 reconstruction_loss= 6339.53662 proj_loss= 446.78802 pca_loss= 1048.71899 accuracy= 0.76224 time= 0.16567
Epoch: 0011 train_loss= 6025.31934 reconstruction_loss= 4575.69336 proj_loss= 430.21100 pca_loss= 1019.41504 accuracy= 0.72866 time= 0.12184
Epoch: 0021 train_loss= 5473.26758 reconstruction_loss= 4075.15430 proj_loss= 409.14505 pca_loss= 988.96832 accuracy= 0.71416 time= 0.12181
Epoch: 0031 train_loss= 5077.64844 reconstruction_loss= 3730.88818 proj_loss= 387.34680 pca_loss= 959.41333 accuracy= 0.71274 time= 0.12186
Epoch: 0041 train_loss= 4749.86719 reconstruction_loss= 3452.92969 proj_loss= 365.94598 pca_loss= 930.99133 accuracy= 0.70239 time= 0.12140
Epoch: 0051 train_loss= 4460.23926 reconstruction_loss= 3211.02979 proj_loss= 345.47900 pca_loss= 903.73041 accuracy= 0.69914 time= 0.12134
Epoch: 0061 train_loss= 4180.61670 reconstruction_loss= 2976.80713 proj_loss= 326.19949 pca_loss= 877.61017 accuracy= 0.69924 time= 0.12158
Epoch: 0071 train_loss= 3898.98608 reconstruction_loss= 2738.04248 proj_loss= 308.21609 pca_loss= 852.72748 accuracy= 0.69975 time= 0.12131
Epoch: 0081 train_loss= 3596.19678 reconstruction_loss= 2475.38940 proj_loss= 291.56940 pca_loss= 829.23804 accuracy= 0.69691 time= 0.12175
Epoch: 0091 train_loss= 3261.06909 reconstruction_loss= 2177.52612 proj_loss= 276.25650 pca_loss= 807.28644 accuracy= 0.69549 time= 0.12161
Epoch: 0101 train_loss= 2876.49536 reconstruction_loss= 1827.57385 proj_loss= 262.12695 pca_loss= 786.79468 accuracy= 0.68403 time= 0.12134
Epoch: 0111 train_loss= 2438.93213 reconstruction_loss= 1422.58203 proj_loss= 248.83850 pca_loss= 767.51172 accuracy= 0.68068 time= 0.12126
Epoch: 0121 train_loss= 2010.53735 reconstruction_loss= 1025.47449 proj_loss= 236.05096 pca_loss= 749.01190 accuracy= 0.67581 time= 0.12120
Epoch: 0131 train_loss= 1642.31824 reconstruction_loss= 688.03979 proj_loss= 223.66469 pca_loss= 730.61377 accuracy= 0.68443 time= 0.12337
Epoch: 0141 train_loss= 1331.93018 reconstruction_loss= 407.95886 proj_loss= 211.82794 pca_loss= 712.14343 accuracy= 0.67409 time= 0.12283
Epoch: 0151 train_loss= 1124.65869 reconstruction_loss= 230.48715 proj_loss= 200.74751 pca_loss= 693.42395 accuracy= 0.67044 time= 0.12184
Epoch: 0161 train_loss= 988.04749 reconstruction_loss= 123.19952 proj_loss= 190.35374 pca_loss= 674.49420 accuracy= 0.67054 time= 0.12172
Epoch: 0171 train_loss= 912.78967 reconstruction_loss= 76.54800 proj_loss= 180.64656 pca_loss= 655.59509 accuracy= 0.66110 time= 0.12208
Epoch: 0181 train_loss= 864.84265 reconstruction_loss= 56.31947 proj_loss= 171.58029 pca_loss= 636.94287 accuracy= 0.66760 time= 0.12190
Epoch: 0191 train_loss= 829.96844 reconstruction_loss= 48.19673 proj_loss= 163.05595 pca_loss= 618.71576 accuracy= 0.67196 time= 0.12199
Epoch: 0201 train_loss= 798.32007 reconstruction_loss= 42.25754 proj_loss= 155.01953 pca_loss= 601.04297 accuracy= 0.67318 time= 0.12169
Epoch: 0211 train_loss= 768.68164 reconstruction_loss= 37.26455 proj_loss= 147.43687 pca_loss= 583.98022 accuracy= 0.67176 time= 0.12187
Epoch: 0221 train_loss= 741.21820 reconstruction_loss= 33.41745 proj_loss= 140.27609 pca_loss= 567.52466 accuracy= 0.66993 time= 0.12160
Epoch: 0231 train_loss= 715.15930 reconstruction_loss= 29.99711 proj_loss= 133.50777 pca_loss= 551.65442 accuracy= 0.66800 time= 0.12177
Epoch: 0241 train_loss= 690.41138 reconstruction_loss= 26.96290 proj_loss= 127.10555 pca_loss= 536.34296 accuracy= 0.66861 time= 0.12242
Epoch: 0251 train_loss= 666.86926 reconstruction_loss= 24.25948 proj_loss= 121.04552 pca_loss= 521.56427 accuracy= 0.66881 time= 0.12226
Epoch: 0261 train_loss= 644.61700 reconstruction_loss= 22.01681 proj_loss= 115.30587 pca_loss= 507.29431 accuracy= 0.66942 time= 0.12200
Epoch: 0271 train_loss= 623.29352 reconstruction_loss= 19.91780 proj_loss= 109.86690 pca_loss= 493.50882 accuracy= 0.66912 time= 0.12236
Epoch: 0281 train_loss= 602.78668 reconstruction_loss= 17.89019 proj_loss= 104.71026 pca_loss= 480.18625 accuracy= 0.66912 time= 0.12167
Epoch: 0291 train_loss= 583.33801 reconstruction_loss= 16.21240 proj_loss= 99.81938 pca_loss= 467.30624 accuracy= 0.66922 time= 0.12338

accuracy 0.66871
auc 0.44523
f1_score 0.18350
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.1, weight_decay=0.0005)
random seed: 19
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 50 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 856731.81250 reconstruction_loss= 5591.37891 proj_loss= 850974.87500 pca_loss= 165.57191 accuracy= 0.64974 time= 0.15458
Epoch: 0011 train_loss= 803149.25000 reconstruction_loss= 4870.88086 proj_loss= 798118.18750 pca_loss= 160.21487 accuracy= 0.65147 time= 0.13698
Epoch: 0021 train_loss= 753343.18750 reconstruction_loss= 4481.02539 proj_loss= 748707.12500 pca_loss= 155.08298 accuracy= 0.65147 time= 0.13631
Epoch: 0031 train_loss= 707165.12500 reconstruction_loss= 4176.75049 proj_loss= 702838.18750 pca_loss= 150.17474 accuracy= 0.64974 time= 0.13767
Epoch: 0041 train_loss= 664486.25000 reconstruction_loss= 3915.23267 proj_loss= 660425.50000 pca_loss= 145.49893 accuracy= 0.65066 time= 0.13649
Epoch: 0051 train_loss= 625083.56250 reconstruction_loss= 3675.57593 proj_loss= 621266.93750 pca_loss= 141.03636 accuracy= 0.65187 time= 0.13988
Epoch: 0061 train_loss= 588691.75000 reconstruction_loss= 3446.56323 proj_loss= 585108.43750 pca_loss= 136.77420 accuracy= 0.65319 time= 0.13671
Epoch: 0071 train_loss= 555047.43750 reconstruction_loss= 3227.00806 proj_loss= 551687.75000 pca_loss= 132.70982 accuracy= 0.65390 time= 0.13716
Epoch: 0081 train_loss= 523883.03125 reconstruction_loss= 2998.34351 proj_loss= 520755.84375 pca_loss= 128.84158 accuracy= 0.65502 time= 0.13783
Epoch: 0091 train_loss= 494973.53125 reconstruction_loss= 2763.01318 proj_loss= 492085.37500 pca_loss= 125.15932 accuracy= 0.65573 time= 0.13679
Epoch: 0101 train_loss= 468113.28125 reconstruction_loss= 2519.74976 proj_loss= 465471.87500 pca_loss= 121.65299 accuracy= 0.65461 time= 0.13652
Epoch: 0111 train_loss= 443116.12500 reconstruction_loss= 2265.66675 proj_loss= 440732.15625 pca_loss= 118.30711 accuracy= 0.65502 time= 0.13740
Epoch: 0121 train_loss= 419819.87500 reconstruction_loss= 2002.71936 proj_loss= 417702.03125 pca_loss= 115.11183 accuracy= 0.65553 time= 0.13800
Epoch: 0131 train_loss= 398069.53125 reconstruction_loss= 1722.70837 proj_loss= 396234.78125 pca_loss= 112.04149 accuracy= 0.65411 time= 0.13931
Epoch: 0141 train_loss= 377754.84375 reconstruction_loss= 1446.97729 proj_loss= 376198.78125 pca_loss= 109.08376 accuracy= 0.65563 time= 0.13811
Epoch: 0151 train_loss= 358798.90625 reconstruction_loss= 1216.45520 proj_loss= 357476.21875 pca_loss= 106.22577 accuracy= 0.65573 time= 0.13731
Epoch: 0161 train_loss= 341072.15625 reconstruction_loss= 1007.35498 proj_loss= 339961.34375 pca_loss= 103.47316 accuracy= 0.65390 time= 0.13711
Epoch: 0171 train_loss= 324488.84375 reconstruction_loss= 830.15472 proj_loss= 323557.87500 pca_loss= 100.82381 accuracy= 0.65502 time= 0.13679
Epoch: 0181 train_loss= 308961.56250 reconstruction_loss= 684.09113 proj_loss= 308179.21875 pca_loss= 98.26304 accuracy= 0.65522 time= 0.13725
Epoch: 0191 train_loss= 294406.25000 reconstruction_loss= 563.67084 proj_loss= 293746.78125 pca_loss= 95.79831 accuracy= 0.65421 time= 0.13793
Epoch: 0201 train_loss= 280753.09375 reconstruction_loss= 470.76636 proj_loss= 280188.87500 pca_loss= 93.42247 accuracy= 0.65340 time= 0.13833
Epoch: 0211 train_loss= 267936.87500 reconstruction_loss= 405.44446 proj_loss= 267440.28125 pca_loss= 91.14735 accuracy= 0.65532 time= 0.13857
Epoch: 0221 train_loss= 255880.15625 reconstruction_loss= 349.50165 proj_loss= 255441.70312 pca_loss= 88.95798 accuracy= 0.65370 time= 0.13807
Epoch: 0231 train_loss= 244529.18750 reconstruction_loss= 303.37216 proj_loss= 244138.95312 pca_loss= 86.85327 accuracy= 0.65360 time= 0.13762
Epoch: 0241 train_loss= 233834.95312 reconstruction_loss= 267.73145 proj_loss= 233482.39062 pca_loss= 84.82355 accuracy= 0.65228 time= 0.13799
Epoch: 0251 train_loss= 223752.60938 reconstruction_loss= 243.06979 proj_loss= 223426.68750 pca_loss= 82.86590 accuracy= 0.65258 time= 0.13785
Epoch: 0261 train_loss= 214233.51562 reconstruction_loss= 222.40717 proj_loss= 213930.12500 pca_loss= 80.97716 accuracy= 0.65319 time= 0.13862
Epoch: 0271 train_loss= 205237.64062 reconstruction_loss= 203.87378 proj_loss= 204954.60938 pca_loss= 79.15677 accuracy= 0.65198 time= 0.13768
Epoch: 0281 train_loss= 196727.40625 reconstruction_loss= 185.00287 proj_loss= 196465.00000 pca_loss= 77.39966 accuracy= 0.65238 time= 0.13817
Epoch: 0291 train_loss= 188672.98438 reconstruction_loss= 168.23936 proj_loss= 188429.04688 pca_loss= 75.70285 accuracy= 0.65127 time= 0.13788

accuracy 0.65198
auc 0.29033
f1_score 0.14225
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 396
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 2271.89893 reconstruction_loss= 21.02029 proj_loss= 1831.26404 pca_loss= 419.61456 accuracy= 0.74043 time= 0.16359
Epoch: 0011 train_loss= 2140.08203 reconstruction_loss= 16.56549 proj_loss= 1717.30554 pca_loss= 406.21103 accuracy= 0.70492 time= 0.12422
Epoch: 0021 train_loss= 2016.32764 reconstruction_loss= 12.23400 proj_loss= 1610.80725 pca_loss= 393.28632 accuracy= 0.68809 time= 0.12424
Epoch: 0031 train_loss= 1902.28442 reconstruction_loss= 9.45111 proj_loss= 1511.94312 pca_loss= 380.89011 accuracy= 0.68383 time= 0.12764
Epoch: 0041 train_loss= 1796.88257 reconstruction_loss= 7.34658 proj_loss= 1420.48450 pca_loss= 369.05157 accuracy= 0.68788 time= 0.12438
Epoch: 0051 train_loss= 1698.00964 reconstruction_loss= 4.26913 proj_loss= 1335.97668 pca_loss= 357.76376 accuracy= 0.69275 time= 0.12696
Epoch: 0061 train_loss= 1607.65051 reconstruction_loss= 2.78084 proj_loss= 1257.87207 pca_loss= 346.99753 accuracy= 0.71375 time= 0.12583
Epoch: 0071 train_loss= 1524.67639 reconstruction_loss= 2.34648 proj_loss= 1185.60181 pca_loss= 336.72815 accuracy= 0.72227 time= 0.12457
Epoch: 0081 train_loss= 1447.42773 reconstruction_loss= 1.86555 proj_loss= 1118.64258 pca_loss= 326.91956 accuracy= 0.72491 time= 0.12768
Epoch: 0091 train_loss= 1375.51709 reconstruction_loss= 1.46390 proj_loss= 1056.50952 pca_loss= 317.54376 accuracy= 0.72521 time= 0.12376
Epoch: 0101 train_loss= 1308.28381 reconstruction_loss= 0.94326 proj_loss= 998.76941 pca_loss= 308.57120 accuracy= 0.72227 time= 0.12626
Epoch: 0111 train_loss= 1245.54456 reconstruction_loss= 0.53285 proj_loss= 945.03168 pca_loss= 299.98001 accuracy= 0.72227 time= 0.12483
Epoch: 0121 train_loss= 1187.09131 reconstruction_loss= 0.39461 proj_loss= 894.95398 pca_loss= 291.74268 accuracy= 0.72247 time= 0.12617
Epoch: 0131 train_loss= 1132.47681 reconstruction_loss= 0.41237 proj_loss= 848.22577 pca_loss= 283.83868 accuracy= 0.72186 time= 0.12609
Epoch: 0141 train_loss= 1081.21106 reconstruction_loss= 0.39327 proj_loss= 804.56824 pca_loss= 276.24957 accuracy= 0.72197 time= 0.12623
Epoch: 0151 train_loss= 1033.08008 reconstruction_loss= 0.39066 proj_loss= 763.73370 pca_loss= 268.95563 accuracy= 0.72227 time= 0.12634
Epoch: 0161 train_loss= 987.82379 reconstruction_loss= 0.38612 proj_loss= 725.49652 pca_loss= 261.94116 accuracy= 0.72247 time= 0.12663
Epoch: 0171 train_loss= 945.22980 reconstruction_loss= 0.38554 proj_loss= 689.65387 pca_loss= 255.19035 accuracy= 0.72247 time= 0.12785
Epoch: 0181 train_loss= 905.09674 reconstruction_loss= 0.38559 proj_loss= 656.02173 pca_loss= 248.68945 accuracy= 0.72268 time= 0.12397
Epoch: 0191 train_loss= 867.24390 reconstruction_loss= 0.38585 proj_loss= 624.43280 pca_loss= 242.42525 accuracy= 0.72247 time= 0.12611
Epoch: 0201 train_loss= 831.50659 reconstruction_loss= 0.38546 proj_loss= 594.73572 pca_loss= 236.38544 accuracy= 0.72247 time= 0.12714
Epoch: 0211 train_loss= 797.73608 reconstruction_loss= 0.38539 proj_loss= 566.79181 pca_loss= 230.55888 accuracy= 0.72257 time= 0.12596
Epoch: 0221 train_loss= 765.79584 reconstruction_loss= 0.38584 proj_loss= 540.47498 pca_loss= 224.93498 accuracy= 0.72247 time= 0.12430
Epoch: 0231 train_loss= 735.55920 reconstruction_loss= 0.38539 proj_loss= 515.67004 pca_loss= 219.50380 accuracy= 0.72257 time= 0.12565
Epoch: 0241 train_loss= 706.92395 reconstruction_loss= 0.39643 proj_loss= 492.27121 pca_loss= 214.25629 accuracy= 0.72227 time= 0.12454
Epoch: 0251 train_loss= 679.75073 reconstruction_loss= 0.38540 proj_loss= 470.18173 pca_loss= 209.18361 accuracy= 0.72268 time= 0.12153
Epoch: 0261 train_loss= 653.97589 reconstruction_loss= 0.38539 proj_loss= 449.31235 pca_loss= 204.27817 accuracy= 0.72257 time= 0.12459
Epoch: 0271 train_loss= 629.49957 reconstruction_loss= 0.38598 proj_loss= 429.58182 pca_loss= 199.53178 accuracy= 0.72247 time= 0.12165
Epoch: 0281 train_loss= 606.23804 reconstruction_loss= 0.38580 proj_loss= 410.91443 pca_loss= 194.93777 accuracy= 0.72247 time= 0.12655
Epoch: 0291 train_loss= 584.11597 reconstruction_loss= 0.38558 proj_loss= 393.24139 pca_loss= 190.48900 accuracy= 0.72257 time= 0.12548

accuracy 0.72257
auc 0.61603
f1_score 0.31625
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=0, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 931
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 4288631.00000 reconstruction_loss= 19.55103 proj_loss= 4288533.00000 pca_loss= 78.56493 accuracy= 0.64508 time= 0.16972
Epoch: 0011 train_loss= 4023739.50000 reconstruction_loss= 13.96534 proj_loss= 4023649.75000 pca_loss= 75.85806 accuracy= 0.64559 time= 0.13927
Epoch: 0021 train_loss= 3775957.00000 reconstruction_loss= 11.32323 proj_loss= 3775872.50000 pca_loss= 73.27147 accuracy= 0.66658 time= 0.14181
Epoch: 0031 train_loss= 3545779.25000 reconstruction_loss= 9.47103 proj_loss= 3545699.00000 pca_loss= 70.81068 accuracy= 0.65968 time= 0.13388
Epoch: 0041 train_loss= 3332803.50000 reconstruction_loss= 7.71034 proj_loss= 3332727.25000 pca_loss= 68.47890 accuracy= 0.65411 time= 0.14450
Epoch: 0051 train_loss= 3136042.50000 reconstruction_loss= 5.41519 proj_loss= 3135970.75000 pca_loss= 66.27455 accuracy= 0.66242 time= 0.13807
Epoch: 0061 train_loss= 2954250.50000 reconstruction_loss= 3.33949 proj_loss= 2954183.00000 pca_loss= 64.19117 accuracy= 0.68109 time= 0.14137
Epoch: 0071 train_loss= 2786134.25000 reconstruction_loss= 2.88346 proj_loss= 2786069.00000 pca_loss= 62.22197 accuracy= 0.71081 time= 0.13036
Epoch: 0081 train_loss= 2630460.50000 reconstruction_loss= 2.39019 proj_loss= 2630397.75000 pca_loss= 60.35956 accuracy= 0.70695 time= 0.13984
Epoch: 0091 train_loss= 2486102.25000 reconstruction_loss= 1.84262 proj_loss= 2486042.00000 pca_loss= 58.59366 accuracy= 0.71446 time= 0.14050
Epoch: 0101 train_loss= 2352043.75000 reconstruction_loss= 1.32859 proj_loss= 2351985.50000 pca_loss= 56.91586 accuracy= 0.71994 time= 0.14137
Epoch: 0111 train_loss= 2227375.25000 reconstruction_loss= 0.89631 proj_loss= 2227319.00000 pca_loss= 55.31989 accuracy= 0.72237 time= 0.13614
Epoch: 0121 train_loss= 2111283.25000 reconstruction_loss= 0.47153 proj_loss= 2111229.00000 pca_loss= 53.79972 accuracy= 0.72247 time= 0.14262
Epoch: 0131 train_loss= 2003038.75000 reconstruction_loss= 0.41067 proj_loss= 2002986.00000 pca_loss= 52.34981 accuracy= 0.72217 time= 0.14223
Epoch: 0141 train_loss= 1901986.37500 reconstruction_loss= 0.40425 proj_loss= 1901935.00000 pca_loss= 50.96513 accuracy= 0.72268 time= 0.13703
Epoch: 0151 train_loss= 1807537.37500 reconstruction_loss= 0.38847 proj_loss= 1807487.37500 pca_loss= 49.64140 accuracy= 0.72237 time= 0.13883
Epoch: 0161 train_loss= 1719159.00000 reconstruction_loss= 0.38766 proj_loss= 1719110.25000 pca_loss= 48.37474 accuracy= 0.72247 time= 0.14239
Epoch: 0171 train_loss= 1636372.00000 reconstruction_loss= 0.38709 proj_loss= 1636324.50000 pca_loss= 47.16164 accuracy= 0.72257 time= 0.13920
Epoch: 0181 train_loss= 1558741.25000 reconstruction_loss= 0.38619 proj_loss= 1558694.87500 pca_loss= 45.99887 accuracy= 0.72257 time= 0.14126
Epoch: 0191 train_loss= 1485871.50000 reconstruction_loss= 0.38695 proj_loss= 1485826.25000 pca_loss= 44.88348 accuracy= 0.72247 time= 0.14354
Epoch: 0201 train_loss= 1417404.25000 reconstruction_loss= 0.38541 proj_loss= 1417360.00000 pca_loss= 43.81273 accuracy= 0.72257 time= 0.14155
Epoch: 0211 train_loss= 1353012.75000 reconstruction_loss= 0.38540 proj_loss= 1352969.62500 pca_loss= 42.78410 accuracy= 0.72257 time= 0.14475
Epoch: 0221 train_loss= 1292399.25000 reconstruction_loss= 0.38565 proj_loss= 1292357.12500 pca_loss= 41.79525 accuracy= 0.72247 time= 0.14068
Epoch: 0231 train_loss= 1235291.75000 reconstruction_loss= 0.38539 proj_loss= 1235250.50000 pca_loss= 40.84400 accuracy= 0.72257 time= 0.13578
Epoch: 0241 train_loss= 1181441.00000 reconstruction_loss= 0.38684 proj_loss= 1181400.75000 pca_loss= 39.92836 accuracy= 0.72247 time= 0.14027
Epoch: 0251 train_loss= 1130619.50000 reconstruction_loss= 0.39655 proj_loss= 1130580.12500 pca_loss= 39.04646 accuracy= 0.72268 time= 0.13433
Epoch: 0261 train_loss= 1082618.25000 reconstruction_loss= 0.38753 proj_loss= 1082579.62500 pca_loss= 38.19653 accuracy= 0.72227 time= 0.13998
Epoch: 0271 train_loss= 1037244.93750 reconstruction_loss= 0.38539 proj_loss= 1037207.18750 pca_loss= 37.37696 accuracy= 0.72257 time= 0.14028
Epoch: 0281 train_loss= 994323.37500 reconstruction_loss= 0.38794 proj_loss= 994286.43750 pca_loss= 36.58624 accuracy= 0.72257 time= 0.14136
Epoch: 0291 train_loss= 953690.87500 reconstruction_loss= 0.38539 proj_loss= 953654.68750 pca_loss= 35.82294 accuracy= 0.72257 time= 0.13500

accuracy 0.72257
auc 0.61612
f1_score 0.31625
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=0, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 598
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
using PCA to reduce dim
y_features shape after PCA torch.Size([19717, 125]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 10673.56250 reconstruction_loss= 8459.68750 proj_loss= 1810.03857 pca_loss= 403.83615 accuracy= 0.71375 time= 0.16195
Epoch: 0011 train_loss= 9541.00879 reconstruction_loss= 7441.61426 proj_loss= 1707.57898 pca_loss= 391.81512 accuracy= 0.70503 time= 0.12100
Epoch: 0021 train_loss= 8957.50000 reconstruction_loss= 6970.01465 proj_loss= 1607.23218 pca_loss= 380.25284 accuracy= 0.69620 time= 0.11991
Epoch: 0031 train_loss= 8504.59668 reconstruction_loss= 6623.42334 proj_loss= 1511.77686 pca_loss= 369.39658 accuracy= 0.69367 time= 0.12019
Epoch: 0041 train_loss= 8089.64941 reconstruction_loss= 6307.97900 proj_loss= 1422.63330 pca_loss= 359.03705 accuracy= 0.69427 time= 0.11855
Epoch: 0051 train_loss= 7696.16113 reconstruction_loss= 6006.74707 proj_loss= 1340.27307 pca_loss= 349.14093 accuracy= 0.69833 time= 0.12038
Epoch: 0061 train_loss= 7304.77979 reconstruction_loss= 5700.78027 proj_loss= 1264.28906 pca_loss= 339.71024 accuracy= 0.69793 time= 0.12104
Epoch: 0071 train_loss= 6921.25000 reconstruction_loss= 5396.37061 proj_loss= 1194.09619 pca_loss= 330.78345 accuracy= 0.69488 time= 0.12038
Epoch: 0081 train_loss= 6519.19727 reconstruction_loss= 5067.44727 proj_loss= 1129.33667 pca_loss= 322.41321 accuracy= 0.69326 time= 0.12056
Epoch: 0091 train_loss= 6100.68848 reconstruction_loss= 4716.01416 proj_loss= 1069.97119 pca_loss= 314.70306 accuracy= 0.69265 time= 0.12051
Epoch: 0101 train_loss= 5618.57715 reconstruction_loss= 4294.44727 proj_loss= 1016.26630 pca_loss= 307.86374 accuracy= 0.68920 time= 0.12057
Epoch: 0111 train_loss= 5005.94580 reconstruction_loss= 3735.10327 proj_loss= 968.66156 pca_loss= 302.18106 accuracy= 0.68859 time= 0.12121
Epoch: 0121 train_loss= 4123.32520 reconstruction_loss= 2897.63428 proj_loss= 927.76923 pca_loss= 297.92178 accuracy= 0.68159 time= 0.12009
Epoch: 0131 train_loss= 3000.87061 reconstruction_loss= 1812.21411 proj_loss= 893.57819 pca_loss= 295.07846 accuracy= 0.68251 time= 0.12047
Epoch: 0141 train_loss= 2164.40625 reconstruction_loss= 1011.19849 proj_loss= 861.01923 pca_loss= 292.18835 accuracy= 0.67267 time= 0.12197
Epoch: 0151 train_loss= 1704.16211 reconstruction_loss= 591.89996 proj_loss= 824.59521 pca_loss= 287.66705 accuracy= 0.67318 time= 0.12064
Epoch: 0161 train_loss= 1429.48438 reconstruction_loss= 361.96680 proj_loss= 785.65820 pca_loss= 281.85931 accuracy= 0.66476 time= 0.12034
Epoch: 0171 train_loss= 1264.83923 reconstruction_loss= 242.56749 proj_loss= 746.83435 pca_loss= 275.43738 accuracy= 0.67865 time= 0.12033
Epoch: 0181 train_loss= 1147.85034 reconstruction_loss= 169.53380 proj_loss= 709.50781 pca_loss= 268.80878 accuracy= 0.67389 time= 0.12100
Epoch: 0191 train_loss= 1066.09583 reconstruction_loss= 129.60640 proj_loss= 674.27185 pca_loss= 262.21756 accuracy= 0.66029 time= 0.12058
Epoch: 0201 train_loss= 1003.19415 reconstruction_loss= 106.13589 proj_loss= 641.29559 pca_loss= 255.76265 accuracy= 0.66719 time= 0.12066
Epoch: 0211 train_loss= 944.95996 reconstruction_loss= 84.93968 proj_loss= 610.49634 pca_loss= 249.52390 accuracy= 0.67054 time= 0.12094
Epoch: 0221 train_loss= 891.37158 reconstruction_loss= 66.07642 proj_loss= 581.76447 pca_loss= 243.53069 accuracy= 0.66810 time= 0.12124
Epoch: 0231 train_loss= 842.29114 reconstruction_loss= 49.60588 proj_loss= 554.91681 pca_loss= 237.76843 accuracy= 0.66131 time= 0.12090
Epoch: 0241 train_loss= 797.39221 reconstruction_loss= 35.38519 proj_loss= 529.77167 pca_loss= 232.23534 accuracy= 0.66476 time= 0.12112
Epoch: 0251 train_loss= 760.30664 reconstruction_loss= 27.22147 proj_loss= 506.17041 pca_loss= 226.91470 accuracy= 0.66993 time= 0.12010
Epoch: 0261 train_loss= 727.87866 reconstruction_loss= 22.08578 proj_loss= 483.99875 pca_loss= 221.79414 accuracy= 0.67105 time= 0.12046
Epoch: 0271 train_loss= 698.79919 reconstruction_loss= 18.80744 proj_loss= 463.13120 pca_loss= 216.86058 accuracy= 0.67064 time= 0.11985
Epoch: 0281 train_loss= 671.44116 reconstruction_loss= 15.87141 proj_loss= 443.46420 pca_loss= 212.10555 accuracy= 0.67216 time= 0.12067
Epoch: 0291 train_loss= 646.39056 reconstruction_loss= 14.00123 proj_loss= 424.88147 pca_loss= 207.50786 accuracy= 0.67176 time= 0.12068

accuracy 0.67074
auc 0.49402
f1_score 0.18850
Job finished!



Initializing rsr scat onedecoder training
Namespace(alpha=1, att=0, beta=1, clique_size=50, cuda=False, dataset='pubmed', decoder=1, delta=1, device=device(type='cuda'), dim_reduce=2, dropout=0.01, epochs=300, gamma=1, hidden1=0.5, hidden2=0.25, k=10, lr=0.002, num_clique=40, rsr_dim=0.02, weight_decay=0.0005)
random seed: 393
Found existing ad data, loading...
feature_dim: 500 hidden1_dim: 250 hidden2_dim: 125 rsr_dim: 10 nodes_num: 19717 anomaly_num: 4000

Start modeling
using wavelet scattering transform
y_features shape after scatting (19717, 6500) <class 'numpy.ndarray'>
6500
y_features shape after NoReduction torch.Size([19717, 6500]) <class 'torch.Tensor'>
Epoch: 0001 train_loss= 4352133.00000 reconstruction_loss= 7964.70898 proj_loss= 4344084.50000 pca_loss= 84.00932 accuracy= 0.64934 time= 0.16489
Epoch: 0011 train_loss= 4083765.00000 reconstruction_loss= 7380.74951 proj_loss= 4076302.75000 pca_loss= 81.45111 accuracy= 0.65005 time= 0.13344
Epoch: 0021 train_loss= 3832848.75000 reconstruction_loss= 7002.87158 proj_loss= 3825767.00000 pca_loss= 78.95738 accuracy= 0.64924 time= 0.13320
Epoch: 0031 train_loss= 3599723.00000 reconstruction_loss= 6656.52197 proj_loss= 3592990.00000 pca_loss= 76.53580 accuracy= 0.65005 time= 0.13358
Epoch: 0041 train_loss= 3383982.75000 reconstruction_loss= 6337.59473 proj_loss= 3377571.00000 pca_loss= 74.21200 accuracy= 0.65066 time= 0.13377
Epoch: 0051 train_loss= 3184621.25000 reconstruction_loss= 6027.80859 proj_loss= 3178521.50000 pca_loss= 71.98575 accuracy= 0.65116 time= 0.13383
Epoch: 0061 train_loss= 3000385.50000 reconstruction_loss= 5729.90723 proj_loss= 2994585.75000 pca_loss= 69.85729 accuracy= 0.65137 time= 0.13434
Epoch: 0071 train_loss= 2829957.50000 reconstruction_loss= 5428.10205 proj_loss= 2824461.75000 pca_loss= 67.82863 accuracy= 0.65238 time= 0.13337
Epoch: 0081 train_loss= 2672090.00000 reconstruction_loss= 5116.60303 proj_loss= 2666907.50000 pca_loss= 65.89048 accuracy= 0.65198 time= 0.13340
Epoch: 0091 train_loss= 2525648.50000 reconstruction_loss= 4797.70020 proj_loss= 2520786.75000 pca_loss= 64.04022 accuracy= 0.65258 time= 0.13360
Epoch: 0101 train_loss= 2389595.75000 reconstruction_loss= 4458.28467 proj_loss= 2385075.25000 pca_loss= 62.27352 accuracy= 0.65198 time= 0.13425
Epoch: 0111 train_loss= 2263000.75000 reconstruction_loss= 4084.88062 proj_loss= 2258855.25000 pca_loss= 60.58485 accuracy= 0.65106 time= 0.13449
Epoch: 0121 train_loss= 2145020.25000 reconstruction_loss= 3655.74048 proj_loss= 2141305.50000 pca_loss= 58.97041 accuracy= 0.64974 time= 0.13473
Epoch: 0131 train_loss= 2034884.50000 reconstruction_loss= 3137.38965 proj_loss= 2031689.75000 pca_loss= 57.42555 accuracy= 0.65137 time= 0.13431
Epoch: 0141 train_loss= 1931914.25000 reconstruction_loss= 2511.62646 proj_loss= 1929346.62500 pca_loss= 55.94803 accuracy= 0.65005 time= 0.13402
Epoch: 0151 train_loss= 1835612.50000 reconstruction_loss= 1876.85205 proj_loss= 1833681.12500 pca_loss= 54.53623 accuracy= 0.65045 time= 0.13401
Epoch: 0161 train_loss= 1745498.12500 reconstruction_loss= 1289.89001 proj_loss= 1744155.12500 pca_loss= 53.18676 accuracy= 0.65005 time= 0.13348
Epoch: 0171 train_loss= 1661102.75000 reconstruction_loss= 766.25525 proj_loss= 1660284.62500 pca_loss= 51.89454 accuracy= 0.65106 time= 0.13342
Epoch: 0181 train_loss= 1582066.50000 reconstruction_loss= 388.38776 proj_loss= 1581627.50000 pca_loss= 50.65434 accuracy= 0.64934 time= 0.13374
Epoch: 0191 train_loss= 1508016.25000 reconstruction_loss= 182.16658 proj_loss= 1507784.62500 pca_loss= 49.46409 accuracy= 0.65137 time= 0.13340
Epoch: 0201 train_loss= 1438530.75000 reconstruction_loss= 86.44283 proj_loss= 1438396.00000 pca_loss= 48.30202 accuracy= 0.64477 time= 0.13349
Epoch: 0211 train_loss= 1373218.37500 reconstruction_loss= 38.12532 proj_loss= 1373133.12500 pca_loss= 47.17698 accuracy= 0.65400 time= 0.13270
Epoch: 0221 train_loss= 1311763.25000 reconstruction_loss= 23.09113 proj_loss= 1311694.00000 pca_loss= 46.08706 accuracy= 0.64528 time= 0.13358
Epoch: 0231 train_loss= 1253862.37500 reconstruction_loss= 13.71393 proj_loss= 1253803.62500 pca_loss= 45.03621 accuracy= 0.65147 time= 0.13401
Epoch: 0241 train_loss= 1199267.75000 reconstruction_loss= 14.00670 proj_loss= 1199209.75000 pca_loss= 44.02668 accuracy= 0.65502 time= 0.13334
Epoch: 0251 train_loss= 1147736.87500 reconstruction_loss= 11.42584 proj_loss= 1147682.50000 pca_loss= 43.05490 accuracy= 0.64325 time= 0.13329
Epoch: 0261 train_loss= 1099056.75000 reconstruction_loss= 4.75957 proj_loss= 1099009.87500 pca_loss= 42.11580 accuracy= 0.64285 time= 0.13327
Epoch: 0271 train_loss= 1053043.00000 reconstruction_loss= 3.42720 proj_loss= 1052998.37500 pca_loss= 41.20688 accuracy= 0.64021 time= 0.13377
Epoch: 0281 train_loss= 1009512.50000 reconstruction_loss= 2.77955 proj_loss= 1009469.43750 pca_loss= 40.33117 accuracy= 0.64416 time= 0.13390
Epoch: 0291 train_loss= 968300.18750 reconstruction_loss= 2.13912 proj_loss= 968258.56250 pca_loss= 39.48384 accuracy= 0.64315 time= 0.13415

accuracy 0.64366
auc 0.25900
f1_score 0.12175
Job finished!
pubmed job finished!
